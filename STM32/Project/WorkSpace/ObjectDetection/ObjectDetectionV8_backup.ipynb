{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:20:56.613869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 22198 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-16 18:20:56.614339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:1 with 22198 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-16 18:20:56.614773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:2 with 22198 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-16 18:20:56.615206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:3 with 22198 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-16 18:20:56.615639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:4 with 22198 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-16 18:20:56.616071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:5 with 22198 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-16 18:20:56.616498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:6 with 22198 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3021775048129732359\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16530650906689989959\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9349711154832757174\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 2144165316,\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12595687310688396898\n",
       " physical_device_desc: \"device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1651660799,\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3569138750993077303\n",
       " physical_device_desc: \"device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 878896533,\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 6633488693572862546\n",
       " physical_device_desc: \"device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 615190153,\n",
       " name: \"/device:GPU:5\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16759384291236733256\n",
       " physical_device_desc: \"device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1769886423,\n",
       " name: \"/device:GPU:6\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 10748979264998924464\n",
       " physical_device_desc: \"device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 893286608]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17820, 24, 32, 1) (17820,) (17820, 4, 4) 17820\n",
      "255 0\n",
      "(16824, 24, 32, 1)\n",
      "(16824, 4, 4)\n",
      "16824\n",
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 0)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "24\n",
      "32\n",
      "bbox:  tf.Tensor(\n",
      "[[11  0 20  4]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]], shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SIZE_WIDTH:   32\n",
      "IMG_SIZE_HEIGHT:  24\n",
      "N_DATA:           16824\n",
      "N_TRAIN:          15142\n",
      "N_VAL:            1682\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.1)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16824, 24, 32, 1)\n",
      "(16824, 4, 4)\n",
      "(16824, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "    \n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    \n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[[0.75       0.45833334 0.96875    0.7916667 ]\n",
      "  [0.34375    0.6666667  0.59375    0.9166667 ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 4, 4), dtype=float32)\n",
      "tf.Tensor([[1 1 0 0]], shape=(1, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "15142\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "for _, _, _ in val_dataset:\n",
    "    val += 1\n",
    "print(val)\n",
    "\n",
    "\n",
    "train = 0\n",
    "for _, _, _ in train_dataset:\n",
    "    train += 1\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor([1 0 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.3125  0.      0.53125 0.125  ]\n",
      " [0.      0.      0.      0.     ]\n",
      " [0.      0.      0.      0.     ]\n",
      " [0.      0.      0.      0.     ]], shape=(4, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0] * RES_WIDTH,\n",
    "    \t bbox[:,1] * RES_HEIGHT,\n",
    "    \t bbox[:,2] * RES_WIDTH,\n",
    "    \t bbox[:,3] * RES_HEIGHT\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.875      0.6875     0.25       0.20833337]\n",
      " [0.890625   0.875      0.21875    0.25      ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(249.0, shape=(), dtype=float32) tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.75       0.5833333  0.25       0.20833337]\n",
      " [0.78125    0.75       0.21875    0.25      ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.75       0.5833333  0.25       0.20833337], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.78125 0.75    0.21875 0.25   ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.125      0.35416666 0.25       0.2916667 ]\n",
      " [0.40625    0.125      0.25       0.25      ]\n",
      " [0.8125     0.5208334  0.3125     0.2916667 ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(243.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.         0.20833331 0.25       0.2916667 ]\n",
      " [0.28125    0.         0.25       0.25      ]\n",
      " [0.65625    0.37500003 0.3125     0.2916667 ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.         0.20833331 0.25       0.2916667 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.28125 0.      0.25    0.25   ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.65625    0.37500003 0.3125     0.2916667 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_sizes (pixels):  [[ 6.580208  11.333333 ]\n",
      " [ 9.3529415 13.736694 ]\n",
      " [ 5.637681   7.1980696]\n",
      " [ 9.490911   8.79394  ]]\n",
      "anchor_ratios:  [0.5866308  0.6884182  0.81043565 1.1138276 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def compute_anchor_boxes(bboxes, img_width, img_height):\n",
    "    all_bboxes = []\n",
    "    for image_bboxes in bboxes:\n",
    "        # 정규화된 좌표를 픽셀 단위 좌표로 변환\n",
    "        pixel_bboxes = np.copy(image_bboxes)\n",
    "        pixel_bboxes[:, 0] *= img_width\n",
    "        pixel_bboxes[:, 1] *= img_height\n",
    "        pixel_bboxes[:, 2] *= img_width\n",
    "        pixel_bboxes[:, 3] *= img_height\n",
    "        all_bboxes.extend(pixel_bboxes)\n",
    "    \n",
    "    all_bboxes = np.array(all_bboxes)\n",
    "    \n",
    "    # 높이가 0인 바운딩 박스 제거\n",
    "    valid_bboxes = all_bboxes[np.logical_and(all_bboxes[:, 2] > all_bboxes[:, 0], all_bboxes[:, 3] > all_bboxes[:, 1])]\n",
    "    \n",
    "    box_sizes = valid_bboxes[:, 2:] - valid_bboxes[:, :2]\n",
    "    box_ratios = box_sizes[:, 0] / box_sizes[:, 1]\n",
    "    \n",
    "    data = np.column_stack((box_sizes[:, 0], box_sizes[:, 1], box_ratios))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(data)\n",
    "    \n",
    "    anchor_sizes = kmeans.cluster_centers_[:, :2]\n",
    "    anchor_ratios = kmeans.cluster_centers_[:, 2]\n",
    "    \n",
    "    return anchor_sizes, anchor_ratios\n",
    "\n",
    "bboxes = []\n",
    "for image, image_bboxes, label in train_dataset:\n",
    "    bboxes.append(image_bboxes.numpy())\n",
    "\n",
    "# 이미지 너비와 높이 설정\n",
    "img_width = 32\n",
    "img_height = 24\n",
    "\n",
    "anchor_sizes, anchor_ratios = compute_anchor_boxes(bboxes, img_width, img_height)\n",
    "print(\"anchor_sizes (pixels): \", anchor_sizes)\n",
    "print(\"anchor_ratios: \", anchor_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.7, 1.0]        \n",
    "        self.scales = [2** x for x in [1, 1.5]]\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [3.5, 4.5, 5.5, 6.5, 7.5]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1),\n",
    "                    [1, 1, 2]\n",
    "                )\n",
    "                dims = tf.cast(dims, tf.float32)  # 데이터 타입을 float32로 변환\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor 음수 값: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0] / RES_WIDTH\n",
    "ymin = anchor[:, 1] / RES_HEIGHT\n",
    "xmax = anchor[:, 2] / RES_WIDTH\n",
    "ymax = anchor[:, 3] / RES_HEIGHT\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x * RES_WIDTH, top_left_y * RES_HEIGHT), width * RES_WIDTH, height * RES_HEIGHT, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelEncoder:\n",
    "#     def __init__(self):\n",
    "#         self._anchor_box = AnchorBox()\n",
    "#         self._box_variance = tf.convert_to_tensor(\n",
    "#             [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "#     def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "#         iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "#         max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "\n",
    "#         matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "#         positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "#         negative_mask = tf.less(max_iou, ignore_iou)\n",
    "\n",
    "#         ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "#         return (\n",
    "#             matched_gt_idx,\n",
    "#             tf.cast(positive_mask, dtype = tf.float32),\n",
    "#             tf.cast(ignore_mask, dtype = tf.float32),\n",
    "#         )\n",
    "    \n",
    "#     def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "#         box_target = tf.concat(\n",
    "#             [\n",
    "#                 (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "#                 tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "#             ],\n",
    "#             axis = -1,\n",
    "#         )\n",
    "#         box_target = box_target / self._box_variance\n",
    "#         return box_target\n",
    "    \n",
    "\n",
    "#     def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "#         anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "#         # 앵커 박스 정규화\n",
    "#         xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "#         ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "#         xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "#         ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "\n",
    "#         # 정규화된 좌표를 스택으로 결합\n",
    "#         normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "#         cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "#         matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "#             normalized_anchor, gt_boxes\n",
    "#         )\n",
    "\n",
    "#         matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "\n",
    "        \n",
    "#         box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "\n",
    "#         matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "\n",
    "#         cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "#         cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "\n",
    "#         cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "#         num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "#         print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "#         label = tf.concat([box_target, cls_target], axis=-1)\n",
    "#         return label\n",
    "\n",
    "#     def encode_batch(self, batch_images, gt_boxes, cls_ids):       \n",
    "#         images_shape = tf.shape(batch_images)\n",
    "#         batch_size = images_shape[0]\n",
    "\n",
    "#         labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "#         for i in range(batch_size):\n",
    "#             label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "#             labels = labels.write(i, label)\n",
    "#         return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou=0.5):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
    "        return matched_gt_idx, max_iou\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        box_target = box_target / self._box_variance\n",
    "        return box_target\n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # Normalize anchor boxes\n",
    "        xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "        ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "        xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "        ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        matched_gt_idx, iou_scores = self._match_anchor_boxes(normalized_anchor, gt_boxes)\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        \n",
    "        # Use IoU scores as labels for classification\n",
    "        cls_target = iou_scores\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            labels = labels.write(i, label)\n",
    "        return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "# val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")\n",
    "\n",
    "# val_dataset = val_dataset.map(\n",
    "#     label_encoder.encode_batch, num_parallel_calls=autotune\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.0 0.0\n",
      "(1, 4032, 5)\n",
      "Positive 개수: 0\n",
      "Negative 개수: 0\n",
      "Ignore 개수: 0\n",
      "255.0 0.0\n",
      "(1, 4032, 5)\n",
      "Positive 개수: 0\n",
      "Negative 개수: 0\n",
      "Ignore 개수: 0\n",
      "235.0 0.0\n",
      "(1, 4032, 5)\n",
      "Positive 개수: 0\n",
      "Negative 개수: 0\n",
      "Ignore 개수: 0\n"
     ]
    }
   ],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, labels = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(labels.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 0\n",
      "Negative 개수: 3869\n",
      "Ignore 개수: 0\n",
      "Positive 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGdCAYAAABZ+qqcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoxUlEQVR4nO3de5DV9X3/8df3XPd+Y2Evsty8gBegvxKlOxqjgQr84U+j01Gb+Q2mGZ0Y6MTQNA2dqontb0jsTJqmQ/WPtlJnqkY7VX/JNLYJBpw0oAElxFwIkFVA2EVW98JezvXz+8O6zSronvdnPzln8fmYOTOwe968P+dzPt/vvvbLOecTOeecAAAAAoqVewAAAODcR+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEFyi3AN4t2KxqOPHj6u+vl5RFJV7OAAA4CyccxoeHlZnZ6disfe/hlFxgeP48ePq6uoq9zAAAMAUHT16VHPnzn3f+1Rc4Kivr5ckXfx/7lE8VVVy/Xir31WRWa/kzbU1x0e9escG7fVRNufR2PNKUtY+Z4XOFr/eHnL1aXNt1aE+r96uyt7bnTzl1TvW6jHnmay51DXW2/tKks8uDJ5XS4vV9lNloSbp1buQjptrncfDjgp+u14kh+xrZeiCWq/ekf2UpJo37OMenZ2yN5aUr7Y/YeMtfmt8zr5xU10+n9GuH31t4mf3+6m4wPHOf6PEU1WmwBFP+016ImlfqYl4wat3zKM++oBLWe/f2DNwePSO4qU/x9PFJew/9BMxe60kubhH4Ij8Tmoxn7F7rBWfx/z2P1DGwBG3h4Yo4Rc4okSZAkfkFzgSCft5wXLu/00+pzSfcSeSfsemS9kH7v2zzzMNTOUlEMFeNLp161YtWLBAVVVVWrlypV588cVQrQAAQIULEji+9a1vadOmTbrvvvv00ksvafny5VqzZo1OnjwZoh0AAKhwQQLH17/+dd1xxx361Kc+pUsuuUQPPfSQampq9E//9E8h2gEAgAo37YEjm81q7969Wr169f80icW0evVq7dq16z33z2QyGhoamnQDAADnlmkPHKdOnVKhUFBbW9ukr7e1tam3t/c999+yZYsaGxsnbrwlFgCAc0/ZP2l08+bNGhwcnLgdPXq03EMCAADTbNrfFtva2qp4PK6+vsmfU9DX16f29vb33D+dTiud9ny7HAAAqGjTfoUjlUppxYoV2r59+8TXisWitm/fru7u7uluBwAAZoAgH/y1adMmrV+/Xh/5yEd0xRVX6Bvf+IZGRkb0qU99KkQ7AABQ4YIEjltuuUVvvPGG7r33XvX29up3fud39Oyzz77nhaQAAODDIdhHm2/cuFEbN24M9c8DAIAZpOL2UnlHtjEyfTZ8rs7v8//l8XH0I/PrvFrXvmavLdTYP8M/9fpb9saS5PMZ/j77Y0iKjdv3vqk65fGZL57jVp99A7Yo7vnSq2LRXJqbN9ve1mMTMm+e2wUVUvY5L1T5PV8u7nN82Utjeb81PjbbvgFbVb/fvlQ+c3a6034uzTT5PdcNR+zns3jWr/fgAtubNwrZqa+Tsr8tFgAAnPsIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACC5R7gGcTXrAKZ5yJdelBvz65tP2DFbVn/PqPTq31lxbc2TEXFuYVW+ulaRozONxxzwz78k3zaVuTou979ET9lpJ6uowlxZ+dsCrdaK62lyb7Bs0145d0Gqu9VWMR171zqfer7VU+mnwf1oXPYo9OY9D2yX8Jm28OW6ujWftcxbL+813psE+aS7mudCs5SXUcYUDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBVez29C5m29442+C3RW/VgH174Tf+V9qrd9uecXPtmMfW9rWHB8y1kpSdU+dV7yN20Xnm2uTr9q3ts8vPN9dKUurIKXNt/JKLvHq7433m2qjKvsZ9t4gvJ59t3qOcX++ix1naZ8tyn76SVDVQMNf6brWerbPXN76WN9cWkn6TNj7Lfg0gedq+RiUpNVw01eVzU6/jCgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAS5R7A2Yx/bFjxmlzpdb21Xn1H59lrk285r96vf6zKXNvwa3vv/KXN5lpJSo4UzbVRwW/OEiOlr5F35Drtjzv5iyPmWkkqzm0z18beGPDrPa/DXBu9ddpcW/vT4+Zab4WCV7nLe9Q7+/EhSVE6bW9dV2OvrU6ZayVp7Dz7ubimZ8irt4s1mGsLKfvv4Xn7dEuS0h4/Q6re8lvj+erIq34quMIBAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgKnZ7+tn1I0rU5kuue23YvpWzJFW9aq8fn5/16p3sTZpr+9eMm2ur9lebayUpnomba2t7/bbuHrjQvoV29Sl778zSi8y1ktT6kxFz7fhlnV69a/YfM9e6XM7eeHaLvdZXrvRzyW+KfOqL9i3HJcnV2Y/PfLN9v/Rso9/29D4i5zdn6Tft6zRXZ/+xmBj1+x2++pR9ncWzfudSl7Cdx11u6s8VVzgAAEBwBA4AABAcgQMAAAQ37YHjy1/+sqIomnRbsmTJdLcBAAAzSJAXjV566aX6/ve//z9NEhX72lQAAPBbECQJJBIJtbe3h/inAQDADBTkNRwHDx5UZ2enFi1apE9+8pM6cuTIWe+byWQ0NDQ06QYAAM4t0x44Vq5cqW3btunZZ5/Vgw8+qJ6eHn30ox/V8PDwGe+/ZcsWNTY2Tty6urqme0gAAKDMpj1wrFu3Tn/wB3+gZcuWac2aNfr3f/93DQwM6Iknnjjj/Tdv3qzBwcGJ29GjR6d7SAAAoMyCv5qzqalJF110kQ4dOnTG76fTaaXTfp8OCgAAKlvwz+E4ffq0Dh8+rI6OjtCtAABAhZr2wPGFL3xBO3fu1Kuvvqof/ehH+sQnPqF4PK7bbrttulsBAIAZYtr/S+XYsWO67bbb1N/fr9mzZ+uqq67S7t27NXv27OluBQAAZohpDxyPP/74dP+TAABghqvYjwB9/WSTYjVVJdfV/MrzBaiRvbTqNb/tnMfb7FsT19VkzLVjy8ylkqRiv/1xD13it6VybeuZ3249FV2z+s21/WP2bb8l6eCl9it+s3/s9z+h6fNazbXxvgF74+FRe60kGbfPliTFPP/3OG7v7VJ+vYt1pZ8H35Ftth+b400e8y0pOWrfYn54cZNX71gJW6a/W7rffi6N5fzOZ/Hxgrl2tMPvZ19izDZnUQk/tti8DQAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcIlyD+Bsirm4lI2XXJevcV59I4/yXL1f78RQ6Y/3HdXzc+baXM7eV5JcW8Fce/6cU169r5p12FzbmXrLXNsSP22ulaTPnbjNXJurTXn1jnL25yvf0Wyujf/yNXOtJEU11fZin1pJrso+58XqpFfvbKO993iz/dgeb/H7fTRfbT8fFlKRV++aU0VzbTJln7N4zt5XkhID4+bawvwqr97FpG3OC7mprxOucAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAILiK3Z4+NpxQLFf68FJDftsa1x+1by9ce8y+tbAkvfq/7Vto9x+cZa5dtPR1c60kxSP7nG1d9IRX74XJOnPtI0Ot5trjOfs27ZLU8JO0ubb+9bxX79jwmL22P2euHb/8QnOtJCWHsubaYsLvd6tCjf1U2X+p/bmWpIbX7M/3SKf9ccfty0SSNNpuPxdnm/22eR+43L5O61+xb/Pe/Cu/Y3O8JWWurXnDr3euNm4sdFO+K1c4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAElyj3AM6m5aeR4qmo5Lqo6Lz61r02Zq596+Iar941r5f+eN8xfFHRXNs7VG+ulaRruw6aa3+db/TqndOQuXZWospc++iRleZaSZL9qVZNj/0xS1KhudZcW6xKmmvHZttrJenUsrS5drzV77yQa7IfX8m3/Hqf7oqba6OCvXd+Vt5cK0npE/YfL87zV+GG5lFz7dBF9uaJEb8fqTWn7OssX+M3aZlGW30hO/U6rnAAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACC4it2evqq/oESyUHJd3c9PevUdXzDLXDv7+V6v3r2/326u7dhp3++8+bNvmWsl6bLa1821BzP2xyxJr2Znm2v/7/YbzLVR3mN/eUnnv2jfPjvfXO3VO/nLY+baqLPVXFt31Fz6NldlLh1a6rfVemzAfqrMtpR+Hps2Cfv29NXNY16tx9Mpc20sbh+3JK3uOmCufaOtzlz7wqlLzbWSVPOGvTaW8Zuz1HDRVJfPTb2OKxwAACA4AgcAAAiOwAEAAIIrOXA8//zzuv7669XZ2akoivT0009P+r5zTvfee686OjpUXV2t1atX6+DBg9M1XgAAMAOVHDhGRka0fPlybd269Yzff+CBB/TNb35TDz30kF544QXV1tZqzZo1Gh8f9x4sAACYmUp+6fW6deu0bt26M37POadvfOMb+ou/+AvdcMPb7wB45JFH1NbWpqefflq33nqr32gBAMCMNK2v4ejp6VFvb69Wr1498bXGxkatXLlSu3btOmNNJpPR0NDQpBsAADi3TGvg6O19+3Mo2traJn29ra1t4nvvtmXLFjU2Nk7curq6pnNIAACgApT9XSqbN2/W4ODgxO3oUd9PBwIAAJVmWgNHe/vbnxrZ19c36et9fX0T33u3dDqthoaGSTcAAHBumdbAsXDhQrW3t2v79u0TXxsaGtILL7yg7u7u6WwFAABmkJLfpXL69GkdOnRo4u89PT3at2+fWlpaNG/ePN199936q7/6K1144YVauHCh7rnnHnV2durGG2+cznEDAIAZpOTAsWfPHl177bUTf9+0aZMkaf369dq2bZu++MUvamRkRHfeeacGBgZ01VVX6dlnn1VVlX3jJQAAMLOVHDiuueYaOXf2XemiKNL999+v+++/32tgAADg3FH2d6kAAIBzX8lXOH5bsg0xFVKl56HUec1efaP3uXrzQYr1NV69G3+dM9eOz7I/lfmiX+5siI2Za4/n/J6v/3d8mbm28edxe+2r9udKknJ19ucrOezXW7Ptcx6N2LcoSOSL5lpJasjkzbWDB/3e/ZawL3ENLfd8vlxkLu3sfNNcW5fMmmsl6VjUaK7NjKe8evdl7M93bSJjrs3X2H9+SNJ4s/1cHK/xO4+nRmzHZ1TCQ+YKBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgqvY7elre7NKJErPQ4lBj32kJRVr7Nsix0+c8uqdjs821yaH7VutH/7xPHOtJN2zx14fs+8ELUlKDdm37u74yai5NnnE77lWwv58FU/ZtxyXJKWS5tKoqsred9xvu/NYxn5sLnh82Kt3/5Ud5tr8r9JevcfmFsy12bz9FN9cP2CulaQFXf3m2j19XV69f36qzVw7MmZ/vqre8Psdvpiwb29ftB/WkqSak8Z1lp96HVc4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQXMVuT1+MRyrGS996fHR+g1ff2l8PmmvzC+xbIktS/JR9C+3xxa3m2tkv2bdElqR41l5ffdJvf/pMs33L8uQx+/bZ2QWzzbWSlPp1n7k2mtfp1TsasK+z4iz78RUV/NaZlzG/dZYc9Rh76aexSRJD9t8Lz6u3n88uqz9urpWki6vs9YO5aq/eLx5aYK5NHrFvT193zHONe5RnmvwWWjFlW2fFaOp1XOEAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABBcotwDOJtY3ikmV3Jd6viIV18Xj+zFL/7Mq3fhI5eYa2t2HzbXVi06z1wrSfHet+zFMY/5lhTf96a9uL7OXJr8iX2+Jam4aK69+FevevXWwi577eGj9tp43F4rqTA0ZG+9+AKv3g0vHjPXZhrmefWOZ0s/D75jf8MCe22txxqVVF0/bq4dG67y6/2rtL32pH2+U8NFc60kFVL282Guzu9c+uYSWxwoZBLSd6d2X65wAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAguIrdnj51alSJeKHkuuycWq++iR/Zt5h33Uu9eieP27d5L3a12xvvO2CvlaQ5rebSYnODV+tYZN+S2Q2ftjee6zHfkqLXTtiLa/3WuDJZc2lUU2PvWyz9eP5Nsfp6r3ofriplrm3+5YhX74GL7M932w/tfXN19scsSbla+xbxNX6706u6z77FfHLUY3v6oby5VpLi4/ZjJNNU7dU72+C3vf1UcIUDAAAER+AAAADBETgAAEBwJQeO559/Xtdff706OzsVRZGefvrpSd+//fbbFUXRpNvatWuna7wAAGAGKjlwjIyMaPny5dq6detZ77N27VqdOHFi4vbYY495DRIAAMxsJb9LZd26dVq3bt373iedTqu93e9V/AAA4NwR5DUcO3bs0Jw5c7R48WLddddd6u/vP+t9M5mMhoaGJt0AAMC5ZdoDx9q1a/XII49o+/bt+trXvqadO3dq3bp1KhTO/P7iLVu2qLGxceLW1dU13UMCAABlNu0f/HXrrbdO/Hnp0qVatmyZzj//fO3YsUOrVq16z/03b96sTZs2Tfx9aGiI0AEAwDkm+NtiFy1apNbWVh06dOiM30+n02poaJh0AwAA55bggePYsWPq7+9XR0dH6FYAAKBClfxfKqdPn550taKnp0f79u1TS0uLWlpa9JWvfEU333yz2tvbdfjwYX3xi1/UBRdcoDVr1kzrwAEAwMxRcuDYs2ePrr322om/v/P6i/Xr1+vBBx/U/v379c///M8aGBhQZ2enrrvuOv3lX/6l0mn7Rj4AAGBmKzlwXHPNNXLu7Lvp/cd//IfXgAAAwLmHvVQAAEBw0/622OkyOq9eiWRVyXXVr4/4Nb5wobk0MTDm1dqlkuba2BsD9r4L5pprJens17s+WHTkhFdvVZW+RibE4vba97nKNyWdc8yl0ZuDfr3HMuZSl7HXRs2N5lpJinyKR8e9ehdn2d89Fzud9eo968f280q2rd5cG8ue+bOTpsrF7M9YLF8sW++xdvs5Jfmm3zobusj+fFWf8puzfJXtfOhKWN5c4QAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAVuz29iv99K7Us5bHluKTEoH17+0KrfQtrSYod6bMXV9u3VI5Oj9r7SnJ1Nfbi1ha/3j7F/QPm0uitIZ/Och7b27sxvy2wo1nN9lrP56tsYl4rRS7usdV6zq93NG7f3j5x2l4bG8uZayVpZFGjudZ5/iqcPF0w1+arPJ5rj+dKkmIF+1pJD+S9emfrbJNeyE59zFzhAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcBW7PX22Oa5CsvSt5tNv2bcWlqTMglnm2uQbftu8F+a3mWvjB4+Za9159r6SFBWL9uK+U3696+vsxQ322mKTR19JUc6+fbZO9nv1dqNj9uJMxlwatTTb+5abxxKXz/EhSTn7tuPRuEftiMc6kVRztPTz9ztigyNevccunG2ubf7xSXOtq0mbayWp4RcD5tpMu985qbY3Z6rL56dexxUOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBJco9gLMqSJEhDmWa015tq18fNteOzav36l3z41fNtVFTg73x6332WklqbzWXRo0e45bkqlL23sOj5trY8Ji5VpKUyZpLi2PjXq1jzU324uoqe20ub6/15ZxXeZQr2It9H7fn2M1ifr+Pxt4YMNe6uhqv3skh+/GVndtkrk312n9+SNLpxc1e9T4yDXFTXSE79WODKxwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiuYrenz9VHKqaikuuq+otefYeWNJlra/oyXr0zy+aZa9M/PmhvPLfdXuur4LHtt+S3dXfcnrddOmnvKykq2tdplPQ8bKPSj6sJPvOdsG1/PcFjzpT12yI+8thi3qdWkt/jTnis8aqUva+kaGzcXFt89ahX78wFy8y1tS/Ze49ffJ65VpLqfjVgrh1Y2uLVOzlqW2dRbup1XOEAAADBETgAAEBwBA4AABBcSYFjy5Ytuvzyy1VfX685c+boxhtv1IEDBybdZ3x8XBs2bNCsWbNUV1enm2++WX19fdM6aAAAMLOUFDh27typDRs2aPfu3fre976nXC6n6667TiMjIxP3+fznP69vf/vbevLJJ7Vz504dP35cN91007QPHAAAzBwlvdz92WefnfT3bdu2ac6cOdq7d6+uvvpqDQ4O6h//8R/16KOP6uMf/7gk6eGHH9bFF1+s3bt36/d+7/emb+QAAGDG8HoNx+DgoCSppeXtt+Ps3btXuVxOq1evnrjPkiVLNG/ePO3ateuM/0Ymk9HQ0NCkGwAAOLeYA0exWNTdd9+tK6+8Updddpkkqbe3V6lUSk1NTZPu29bWpt7e3jP+O1u2bFFjY+PErauryzokAABQocyBY8OGDXrllVf0+OOPew1g8+bNGhwcnLgdPer3gS8AAKDymD6ycOPGjfrOd76j559/XnPnzp34ent7u7LZrAYGBiZd5ejr61N7+5k/zTKdTiudTluGAQAAZoiSrnA457Rx40Y99dRTeu6557Rw4cJJ31+xYoWSyaS2b98+8bUDBw7oyJEj6u7unp4RAwCAGaekKxwbNmzQo48+qmeeeUb19fUTr8tobGxUdXW1Ghsb9elPf1qbNm1SS0uLGhoa9Md//Mfq7u7mHSoAAHyIlRQ4HnzwQUnSNddcM+nrDz/8sG6//XZJ0t/8zd8oFovp5ptvViaT0Zo1a/T3f//30zJYAAAwM5UUONwUdoqsqqrS1q1btXXrVvOgAADAuYW9VAAAQHCmd6n8NkSFt2+lGpud9OqbOl001/ZfUuXVu3X/mLm2uHi+uTb21mlzrSTl2xrNtYljZ/58lqmKoshc65L25Z9vqjHXSlKszr5W4nnDgfGbivY17oZHPvhOZ9PZZq+VpFzeXBoVP/jq7PuK2dfZjOVxbElScU6zvfWsJq/eiRH7MTK6bO4H3+ks0m9mzLWSNHJ+k7nWeV4+GDovbqorZKZexxUOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAEV7Hb06cHikokS99Gu/qk3/bAox1pc23NG/ZtvyUp05Iy19a9/Lq51jXUmmslKTaasxd3zPHq7bXp+MCQuTSZ9XjMkt/W33n7Nu2S5Dy2/nbNDfbGnr/eRD6nq4LfselSHr1zfqfZyGPszmOd+W1OL8nZj87oyHGv1vGa+eba9JFhc21hVr25VpKqj4+Ya8eWehybkvI1trpCCbvac4UDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwiXIP4Gwi5xQ5V3JdvrZ8D2mkLe5VX9tbMNfm584y10Y5e19JyjVVmWurTr7l1VtJj+c7Zs/brq7G3leSS9h7x6LIq7cMx9VE75Exe9sa+zp5+x+wj9vF/X63ckn7sR2lU169VbQ/bnmsM1fwW2e5Fvsxkhq1n88kKZbJm2vzcxrsfU9nzbWSlG2rNdcWk16tNd5m+zlQHJt6HVc4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcBW3W6z77x0h87lx2z+QL3r1z+fsu0IWsn67xeY9dm3N543zJSkqeM6ZfWNG5YsZr94qeux0W8yZS13Bb9wu8tgt1nPOnMeURR69fXcf9dktVgW/HZGLBY/nq+BxgMhvzgsF+xaikee483mfOfNd4/a1Vszb10qsYD+nSFI+7/Pzx+88Xhyz1RfH3/7Z46ZwfEZuKvf6LTp27Ji6urrKPQwAADBFR48e1dy5c9/3PhUXOIrFoo4fP676+npF0XtT6tDQkLq6unT06FE1NDSUYYQzD3NWOuasdMxZ6Ziz0jFnpQs5Z845DQ8Pq7OzU7HY+1/Vqrj/UonFYh+YkiSpoaGBxVYi5qx0zFnpmLPSMWelY85KF2rOGhsbp3Q/XjQKAACCI3AAAIDgZlzgSKfTuu+++5ROp8s9lBmDOSsdc1Y65qx0zFnpmLPSVcqcVdyLRgEAwLlnxl3hAAAAMw+BAwAABEfgAAAAwRE4AABAcDMucGzdulULFixQVVWVVq5cqRdffLHcQ6pYX/7ylxVF0aTbkiVLyj2sivL888/r+uuvV2dnp6Io0tNPPz3p+8453Xvvvero6FB1dbVWr16tgwcPlmewFeKD5uz2229/z7pbu3ZteQZbAbZs2aLLL79c9fX1mjNnjm688UYdOHBg0n3Gx8e1YcMGzZo1S3V1dbr55pvV19dXphGX31Tm7JprrnnPOvvMZz5TphGX34MPPqhly5ZNfLhXd3e3vvvd7058vxLW2IwKHN/61re0adMm3XfffXrppZe0fPlyrVmzRidPniz30CrWpZdeqhMnTkzcfvjDH5Z7SBVlZGREy5cv19atW8/4/QceeEDf/OY39dBDD+mFF15QbW2t1qxZo/Fx+2Z5M90HzZkkrV27dtK6e+yxx36LI6wsO3fu1IYNG7R7925973vfUy6X03XXXaeRkZGJ+3z+85/Xt7/9bT355JPauXOnjh8/rptuuqmMoy6vqcyZJN1xxx2T1tkDDzxQphGX39y5c/XVr35Ve/fu1Z49e/Txj39cN9xwg372s59JqpA15maQK664wm3YsGHi74VCwXV2drotW7aUcVSV67777nPLly8v9zBmDEnuqaeemvh7sVh07e3t7q//+q8nvjYwMODS6bR77LHHyjDCyvPuOXPOufXr17sbbrihLOOZCU6ePOkkuZ07dzrn3l5TyWTSPfnkkxP3+cUvfuEkuV27dpVrmBXl3XPmnHMf+9jH3Oc+97nyDWoGaG5udv/wD/9QMWtsxlzhyGaz2rt3r1avXj3xtVgsptWrV2vXrl1lHFllO3jwoDo7O7Vo0SJ98pOf1JEjR8o9pBmjp6dHvb29k9ZcY2OjVq5cyZr7ADt27NCcOXO0ePFi3XXXXerv7y/3kCrG4OCgJKmlpUWStHfvXuVyuUnrbMmSJZo3bx7r7L+9e87e8S//8i9qbW3VZZddps2bN2t0dLQcw6s4hUJBjz/+uEZGRtTd3V0xa6ziNm87m1OnTqlQKKitrW3S19va2vTLX/6yTKOqbCtXrtS2bdu0ePFinThxQl/5ylf00Y9+VK+88orq6+vLPbyK19vbK0lnXHPvfA/vtXbtWt10001auHChDh8+rD//8z/XunXrtGvXLsXj8XIPr6yKxaLuvvtuXXnllbrsssskvb3OUqmUmpqaJt2Xdfa2M82ZJP3hH/6h5s+fr87OTu3fv19/9md/pgMHDujf/u3fyjja8vrpT3+q7u5ujY+Pq66uTk899ZQuueQS7du3ryLW2IwJHCjdunXrJv68bNkyrVy5UvPnz9cTTzyhT3/602UcGc5lt95668Sfly5dqmXLlun888/Xjh07tGrVqjKOrPw2bNigV155hddSleBsc3bnnXdO/Hnp0qXq6OjQqlWrdPjwYZ1//vm/7WFWhMWLF2vfvn0aHBzUv/7rv2r9+vXauXNnuYc1Ycb8l0pra6vi8fh7XlXb19en9vb2Mo1qZmlqatJFF12kQ4cOlXsoM8I764o152fRokVqbW390K+7jRs36jvf+Y5+8IMfaO7cuRNfb29vVzab1cDAwKT7s87OPmdnsnLlSkn6UK+zVCqlCy64QCtWrNCWLVu0fPly/e3f/m3FrLEZEzhSqZRWrFih7du3T3ytWCxq+/bt6u7uLuPIZo7Tp0/r8OHD6ujoKPdQZoSFCxeqvb190pobGhrSCy+8wJorwbFjx9Tf3/+hXXfOOW3cuFFPPfWUnnvuOS1cuHDS91esWKFkMjlpnR04cEBHjhz50K6zD5qzM9m3b58kfWjX2ZkUi0VlMpnKWWO/tZenToPHH3/cpdNpt23bNvfzn//c3Xnnna6pqcn19vaWe2gV6U/+5E/cjh07XE9Pj/uv//ovt3r1atfa2upOnjxZ7qFVjOHhYffyyy+7l19+2UlyX//6193LL7/sXnvtNeecc1/96lddU1OTe+aZZ9z+/fvdDTfc4BYuXOjGxsbKPPLyeb85Gx4edl/4whfcrl27XE9Pj/v+97/vfvd3f9ddeOGFbnx8vNxDL4u77rrLNTY2uh07drgTJ05M3EZHRyfu85nPfMbNmzfPPffcc27Pnj2uu7vbdXd3l3HU5fVBc3bo0CF3//33uz179rienh73zDPPuEWLFrmrr766zCMvny996Utu586drqenx+3fv9996UtfclEUuf/8z/90zlXGGptRgcM55/7u7/7OzZs3z6VSKXfFFVe43bt3l3tIFeuWW25xHR0dLpVKufPOO8/dcsst7tChQ+UeVkX5wQ9+4CS957Z+/Xrn3Ntvjb3nnntcW1ubS6fTbtWqVe7AgQPlHXSZvd+cjY6Ouuuuu87Nnj3bJZNJN3/+fHfHHXd8qH8pONNcSXIPP/zwxH3GxsbcZz/7Wdfc3OxqamrcJz7xCXfixInyDbrMPmjOjhw54q6++mrX0tLi0um0u+CCC9yf/umfusHBwfIOvIz+6I/+yM2fP9+lUik3e/Zst2rVqomw4VxlrDG2pwcAAMHNmNdwAACAmYvAAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAILj/DxxVh0kw+2VCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    label_idx = 0\n",
    "    for label in labels:\n",
    "        # if label[4] == 1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        # elif label[4] == -1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        dx, dy, dw, dh = label[:4]\n",
    "        anchor = anchors[label_idx]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, width, height]\n",
    "        # print(np.array(decoded_box))\n",
    "        if label[4] == 1.0:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "        label_idx += 1\n",
    "        # if len(np.array(decoded_boxes)) > 1: \n",
    "            # break\n",
    "    print(\"Positive\",len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes    \n",
    "    # print(np.array(decoded_boxes))\n",
    "    \n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    # print(len(decoded_boxes))\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i+=1\n",
    "        # print(box)\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    # print(i)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(1):\n",
    "    image = batch[0][0].numpy()\n",
    "    labels = batch[1][0].numpy()  # 여기서 labels는 [오프셋x, 오프셋y, 스케일w, 스케일h, 클래스, 앵커 박스 인덱스]를 포함한다고 가정\n",
    "    # print(labels)\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(labels, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = layers.DepthwiseConv2D(kernel_size=kernel_size, padding='same' if padding else 'valid', depth_multiplier=1, strides=stride, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.pointwise = layers.Conv2D(out_channels, kernel_size=1, strides=1, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class DepthwiseConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv, self).__init__()\n",
    "        self.depthwise = DepthwiseSeparableConv(out_channels, kernel_size, stride, padding)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=2, padding='SAME'):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding=padding, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "        self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.conv_1(out)\n",
    "        out += identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "class SPPFast(layers.Layer):\n",
    "    def __init__(self, filters: int, pool_kernel_sizes: List[int] = [1, 2, 3], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pool_kernel_sizes = pool_kernel_sizes\n",
    "        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "        self.conv = layers.Conv2D(filters, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        height, width = tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "        # 글로벌 평균 풀링과 업샘플링\n",
    "        global_features = self.global_pool(inputs)\n",
    "        global_features = tf.expand_dims(tf.expand_dims(global_features, 1), 1)\n",
    "        global_features = tf.image.resize(global_features, [height, width])\n",
    "        # 다양한 크기의 MaxPooling\n",
    "        pooled_outputs = [\n",
    "            layers.MaxPooling2D(pool_size=kernel_size, strides=1, padding='SAME')(inputs)\n",
    "            for kernel_size in self.pool_kernel_sizes\n",
    "        ]\n",
    "        # 업샘플링 및 컨캐터네이션\n",
    "        pooled_outputs = [\n",
    "            tf.image.resize(pooled, [height, width])\n",
    "            for pooled in pooled_outputs\n",
    "        ]\n",
    "        pooled_outputs.append(global_features)\n",
    "        pooled_outputs.append(inputs)\n",
    "        spp_output = tf.concat(pooled_outputs, axis=-1)\n",
    "        # 컨볼루션 적용\n",
    "        spp_output = self.conv(spp_output)\n",
    "        return spp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiStageFeatureExtractionLayer\n",
    "class MSFELayer(layers.Layer):\n",
    "    def __init__(self, sperate_input_channel, out_channel):\n",
    "        super(MSFELayer, self).__init__()\n",
    "        self.sppf = SPPFast(sperate_input_channel)\n",
    "        self.cbam = CBAM()\n",
    "        self.bottleneck = Bottleneck(sperate_input_channel // 3)\n",
    "        self.conv = Conv(out_channel, kernel_size=3, stride=1, padding='SAME')\n",
    "\n",
    "    def call(self, x):\n",
    "        sppf, cbam, bottle = tf.split(x, num_or_size_splits=3, axis=-1)\n",
    "        sppf = self.sppf(sppf)\n",
    "        cbam = self.cbam(cbam)\n",
    "        bottle = self.bottleneck(bottle)\n",
    "\n",
    "        out = tf.concat([sppf, cbam, bottle], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, out_channel, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "        self.conv = layers.Conv2D(out_channel, kernel_size = 1, strides = 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    def call(self, inputs):\n",
    "        out = self.upsample(inputs)\n",
    "        out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose(layers.Layer):\n",
    "    def __init__(self, out_channel, size):\n",
    "        super(Conv2DTranspose, self).__init__()\n",
    "        self.transpose = layers.Conv2DTranspose(filters=out_channel, kernel_size=1, strides=size, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.transpose(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSUpsample(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size, size, interpolation = 'bilinear'):\n",
    "        super(CSUpsample, self).__init__()\n",
    "        self.upsample = Upsample(out_channel * 2, size=size, interpolation = interpolation)\n",
    "        self.transpose = Conv2DTranspose(out_channel * 2, size=size)\n",
    "        self.conv = Conv(out_channel, kernel_size = kernel_size, stride=1, padding='SAME')\n",
    "    \n",
    "    def call(self, x):\n",
    "        upsample, transpose = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        upsample = self.upsample(upsample)\n",
    "        transpose = self.transpose(transpose)\n",
    "\n",
    "        out = tf.concat([upsample, transpose], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(out_channels=12, kernel_size=3, stride=1)\n",
    "        self.msfe1 = MSFELayer(12, 18)\n",
    "\n",
    "        self.conv2 = Conv(out_channels=15, kernel_size=3, stride=2)\n",
    "        self.msfe2 = MSFELayer(15, 18)\n",
    "\n",
    "        self.conv3 = Conv(out_channels=18, kernel_size=3, stride=2)\n",
    "        self.msfe3 = MSFELayer(18, 24)\n",
    "\n",
    "        self.conv4 = Conv(out_channels=21, kernel_size=3, stride=2)\n",
    "        self.msfe4 = MSFELayer(21, 27)\n",
    "        # self.sppf = SPPFast(24)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1 = self.conv1(inputs) \n",
    "        p1_out = self.msfe1(p1) # 24, 32, 18\n",
    "\n",
    "        p2 = self.conv2(p1_out)\n",
    "        p2_out = self.msfe2(p2) # 12, 16, 21\n",
    "\n",
    "        p3 = self.conv3(p2_out) \n",
    "        p3_out = self.msfe3(p3) # 6, 8, 24\n",
    "\n",
    "        p4 = self.conv4(p3_out)\n",
    "        p4_out = self.msfe4(p4) # 3, 4, 27\n",
    "\n",
    "        return p1_out, p2_out, p3_out, p4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Neck, self).__init__()\n",
    "        self.conv1 = Conv(24, kernel_size=1, stride=1)\n",
    "        self.csupsample_c1 = CSUpsample(12, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c1 = MSFELayer(36, 18)\n",
    "\n",
    "        self.csupsample_c2 = CSUpsample(18, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c2 = MSFELayer(36, 16)\n",
    "\n",
    "        self.csupsample_c3 = CSUpsample(12, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c3 = MSFELayer(30, 12)\n",
    "\n",
    "\n",
    "#   • p1=tf.Tensor(shape=(None, 24, 32, 18), dtype=float32)\n",
    "#   • p2=tf.Tensor(shape=(None, 12, 16, 18), dtype=float32)\n",
    "#   • p3=tf.Tensor(shape=(None, 6, 8, 24), dtype=float32)\n",
    "#   • p4=tf.Tensor(shape=(None, 3, 4, 27), dtype=float32)\n",
    "\n",
    "    def call(self, p1, p2, p3, p4):\n",
    "        c3 = self.conv1(p4)          # 3, 4, 24   \n",
    "        c3 = self.csupsample_c1(c3)  # 6, 8, 12\n",
    "        c3 = layers.concatenate([c3, p3]) # 6, 8, 36\n",
    "        c3_out = self.msfe_c1(c3)    # 6, 8, 18\n",
    "\n",
    "        c2 = self.csupsample_c2(c3_out) # 12, 16, 18\n",
    "        c2 = layers.concatenate([c2, p2])  # 12, 16, 36\n",
    "        c2_out = self.msfe_c2(c2)       # 12, 16, 16\n",
    "\n",
    "        c1 = self.csupsample_c3(c2_out) # 24, 32, 12\n",
    "        c1 = layers.concatenate([c1, p1]) # 24, 32, 30\n",
    "        c1_out = self.msfe_c3(c1)  # 24, 32, 12\n",
    "\n",
    "        return c1_out, c2_out, c3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Head, self).__init__()\n",
    "        \n",
    "        self.csupsample1 = CSUpsample(20, kernel_size = 1, size = 2)\n",
    "        self.csupsample2 = CSUpsample(20, kernel_size = 1, size = 2)\n",
    "        # FPN layers\n",
    "        self.lateral_conv1 = layers.Conv2D(20, 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.lateral_conv2 = layers.Conv2D(20, 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.lateral_conv3 = layers.Conv2D(20, 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "        self.smooth_conv1 = layers.Conv2D(24, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv2 = layers.Conv2D(24, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv3 = layers.Conv2D(24, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "#   • c1=tf.Tensor(shape=(None, 24, 32, 12), dtype=float32)\n",
    "#   • c2=tf.Tensor(shape=(None, 12, 16, 12), dtype=float32)\n",
    "#   • c3=tf.Tensor(shape=(None, 6, 8, 20), dtype=float32)\n",
    "\n",
    "    def call(self, c1, c2, c3):\n",
    "        lateral_conv1 = self.lateral_conv1(c1)\n",
    "        lateral_conv2 = self.lateral_conv2(c2)\n",
    "        lateral_conv3 = self.lateral_conv3(c3)\n",
    "\n",
    "        fpn_out3 = lateral_conv3\n",
    "        fpn_out2 = layers.Add()([self.csupsample1(fpn_out3), lateral_conv2])\n",
    "        fpn_out1 = layers.Add()([self.csupsample2(fpn_out2), lateral_conv1])\n",
    "\n",
    "        fpn_out1 = self.smooth_conv1(fpn_out1)\n",
    "        fpn_out2 = self.smooth_conv2(fpn_out2)\n",
    "        fpn_out3 = self.smooth_conv3(fpn_out3)\n",
    "        \n",
    "        return fpn_out1, fpn_out2, fpn_out3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 1, num_anchors_per_location = 4):\n",
    "        super(DetectionModel, self).__init__()\n",
    "\n",
    "        self.backbone = BackBone()\n",
    "        self.neck = Neck()\n",
    "        self.head = Head()\n",
    "\n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(24, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(24, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.Conv2D(num_anchors_per_location * 4, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1, p2, p3, p4 = self.backbone(inputs)\n",
    "        c1, c2, c3 = self.neck(p1, p2, p3, p4)\n",
    "        fpn_out1, fpn_out2, fpn_out3 = self.head(c1, c2, c3)\n",
    "\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        N = tf.shape(inputs)[0]\n",
    "        \n",
    "        for _, feature in enumerate([fpn_out1, fpn_out2, fpn_out3]):\n",
    "            cls_output = self.classification_head(feature)\n",
    "            reg_output = self.regression_head(feature)\n",
    "            \n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "\n",
    "            cls_outputs.append(cls_output)\n",
    "            reg_outputs.append(reg_output)\n",
    "\n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"detection_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " back_bone_2 (BackBone)      multiple                  36868     \n",
      "                                                                 \n",
      " neck (Neck)                 multiple                  39898     \n",
      "                                                                 \n",
      " head (Head)                 multiple                  19040     \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, None, 4)     1696      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, None, 16)    1856      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99358 (388.12 KB)\n",
      "Trainable params: 98412 (384.42 KB)\n",
      "Non-trainable params: 946 (3.70 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DetectionModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CIoULoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta=2.0, anchors=None, name=\"CIoULoss\"):\n",
    "#         super(CIoULoss, self).__init__(reduction=\"none\", name=name)\n",
    "#         self._delta = delta\n",
    "#         self.anchors = anchors\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         # Decode true and predicted boxes\n",
    "#         true_boxes = self.decode_predictions(y_true, self.anchors)\n",
    "#         pred_boxes = self.decode_predictions(y_pred, self.anchors)\n",
    "\n",
    "#         # Calculate IoU\n",
    "#         iou = self.iou(true_boxes, pred_boxes)\n",
    "\n",
    "#         # Calculate center distances\n",
    "#         center_true = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) / 2\n",
    "#         center_pred = (pred_boxes[..., 0:2] + pred_boxes[..., 2:4]) / 2\n",
    "#         center_distance = tf.reduce_sum(tf.square(center_true - center_pred), axis=-1)\n",
    "\n",
    "#         # Calculate diagonal lengths\n",
    "#         diag_true = tf.square(true_boxes[..., 2:4] - true_boxes[..., 0:2])\n",
    "#         diag_pred = tf.square(pred_boxes[..., 2:4] - pred_boxes[..., 0:2])\n",
    "#         diag_sum = diag_true + diag_pred\n",
    "\n",
    "#         # Calculate aspect ratio\n",
    "#         aspect_ratio_true = diag_true[..., 0] / diag_true[..., 1]\n",
    "#         aspect_ratio_pred = diag_pred[..., 0] / diag_pred[..., 1]\n",
    "#         aspect_ratio = tf.square(tf.maximum(aspect_ratio_true / aspect_ratio_pred, aspect_ratio_pred / aspect_ratio_true))\n",
    "\n",
    "#         # Calculate CIOU\n",
    "#         ciou = iou - (center_distance / tf.reduce_sum(diag_sum, axis=-1)) - (aspect_ratio / tf.reduce_sum(diag_sum, axis=-1))\n",
    "#         ciou_loss = 1 - tf.clip_by_value(ciou, 0.0, 1.0 - self._delta)\n",
    "\n",
    "#         return ciou_loss\n",
    "\n",
    "#     @staticmethod\n",
    "#     def iou(y_true, y_pred):\n",
    "#         # Calculate intersection\n",
    "#         x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "#         y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "#         x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "#         y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "        \n",
    "#         intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        \n",
    "#         # Calculate union\n",
    "#         area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "#         area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "#         union = area_true + area_pred - intersection\n",
    "        \n",
    "#         # Calculate IoU\n",
    "#         iou = intersection / (union + 1e-6)\n",
    "        \n",
    "#         return iou\n",
    "\n",
    "#     def decode_predictions(self, labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "#         anchor_x = anchors[..., 0]\n",
    "#         anchor_y = anchors[..., 1]\n",
    "#         anchor_w = anchors[..., 2]\n",
    "#         anchor_h = anchors[..., 3]\n",
    "\n",
    "#         cx = labels[..., 0] * box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = labels[..., 1] * box_variance[1] * anchor_h + anchor_y\n",
    "#         width = tf.exp(labels[..., 2] * box_variance[2]) * anchor_w\n",
    "#         height = tf.exp(labels[..., 3] * box_variance[3]) * anchor_h\n",
    "\n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         x_max = x_min + width\n",
    "#         y_max = y_min + height\n",
    "\n",
    "#         decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "#         return decoded_boxes\n",
    "    \n",
    "# class BoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true_box, y_pred_box):\n",
    "#         difference = y_true_box - y_pred_box\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less_equal(absolute_difference, self._delta),\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5 * self._delta\n",
    "#         )\n",
    "#         return tf.reduce_mean(loss, axis=-1)  # 각 앵커에 대한 평균을 반환\n",
    "\n",
    "\n",
    "# class CombinedCIoUBoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta=2.0, anchors=None, weight_ciou=0.5, weight_box=0.5, name=\"CombinedCIoUBoxLoss\"):\n",
    "#         super(CombinedCIoUBoxLoss, self).__init__(reduction=\"none\", name=name)\n",
    "#         self.ciou_loss = CIoULoss(delta=delta, anchors=anchors)\n",
    "#         self.box_loss = BoxLoss(delta=delta)\n",
    "#         self.weight_ciou = weight_ciou\n",
    "#         self.weight_box = weight_box\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         # CIoU and Box loss calculations\n",
    "#         ciou_loss = self.ciou_loss(y_true, y_pred)\n",
    "#         box_loss = self.box_loss(y_true, y_pred)\n",
    "\n",
    "#         # combined_loss = self.weight_ciou * ciou_loss + self.weight_box * box_loss\n",
    "#         return tf.reduce_mean(box_loss, axis=-1)  # 각 앵커에 대한 평균을 반환\n",
    "\n",
    "\n",
    "\n",
    "# class ClassificationLoss(tf.losses.Loss):\n",
    "#     def __init__(self):\n",
    "#         super(ClassificationLoss, self).__init__(reduction=\"none\", name=\"ClassificationLoss\")\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         mae = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "#         loss = mae(y_true, tf.nn.sigmoid(y_pred))\n",
    "#         return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "\n",
    "# class BinaryCrossEntropyError(tf.losses.Loss):\n",
    "#     def __init__(self, reduction=\"auto\", name=\"ClassificationLoss\"):\n",
    "#         super(BinaryCrossEntropyError, self).__init__(reduction=reduction, name=name)\n",
    "    \n",
    "#     def call(self, y_true_cls, y_pred_cls):\n",
    "#         labels = tf.where(y_true_cls == 1, 1, 0)\n",
    "#         bce_loss = tf.keras.losses.binary_crossentropy(\n",
    "#             y_true=tf.cast(labels, dtype=tf.float32),\n",
    "#             y_pred=y_pred_cls,\n",
    "#             from_logits=True\n",
    "#         )\n",
    "#         return tf.reduce_mean(bce_loss, axis=-1)\n",
    "\n",
    "\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, alpha=0.75, gamma=5.0, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.nn.sigmoid(y_pred)\n",
    "#         alpha_t = tf.where(y_true == 1, self.alpha, 1 - self.alpha)\n",
    "#         p_t = tf.where(y_true == 1, y_pred, 1 - y_pred)\n",
    "#         focal_loss = -alpha_t * tf.pow(1 - p_t, self.gamma) * tf.math.log(p_t + tf.keras.backend.epsilon())\n",
    "#         return tf.reduce_mean(focal_loss, axis=-1)\n",
    "\n",
    "\n",
    "# class RecallLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, threshold=0.5, epsilon=1e-7, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.threshold = threshold\n",
    "#         self.epsilon = epsilon\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.nn.sigmoid(y_pred)\n",
    "#         y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "#         tp = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "#         fn = tf.reduce_sum(y_true * (1 - y_pred), axis=-1)\n",
    "#         recall = tp / (tp + fn + self.epsilon)\n",
    "#         return 1 - recall\n",
    "\n",
    "\n",
    "\n",
    "# class ClassBalancedLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, beta=0.9999, name=\"ClassBalancedLoss\"):\n",
    "#         super().__init__(reduction=\"none\", name=name)\n",
    "#         self.beta = beta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         # 레이블 값을 정수 인덱스로 변환\n",
    "#         cls_labels = tf.cast(y_true, tf.int32)\n",
    "#         cls_labels = tf.where(cls_labels == -2, 0, cls_labels)\n",
    "#         cls_labels = tf.where(cls_labels == -1, 1, cls_labels)\n",
    "#         cls_labels = tf.where(cls_labels == 1, 2, cls_labels)\n",
    "\n",
    "#         # 클래스별 샘플 수 계산\n",
    "#         num_classes = y_pred.shape[-1]\n",
    "#         samples_per_cls = tf.math.bincount(cls_labels, minlength=num_classes)\n",
    "\n",
    "#         # 유효한 클래스만 선택\n",
    "#         valid_classes = tf.where(samples_per_cls > 0)[:, 0]\n",
    "#         valid_samples_per_cls = tf.gather(samples_per_cls, valid_classes)\n",
    "\n",
    "#         # 크로스 엔트로피 손실 계산\n",
    "#         cls_labels_one_hot = tf.one_hot(cls_labels, depth=num_classes)\n",
    "#         cls_labels_valid = tf.gather(cls_labels_one_hot, valid_classes, axis=1)\n",
    "#         cls_labels_valid = tf.squeeze(cls_labels_valid, axis=[-2, -1])\n",
    "#         cls_predictions_valid = tf.gather(y_pred, valid_classes, axis=1)\n",
    "#         cls_predictions_valid = tf.squeeze(cls_predictions_valid, axis=-1)\n",
    "\n",
    "#         loss = tf.keras.losses.categorical_crossentropy(cls_labels_valid, cls_predictions_valid, from_logits=True)\n",
    "\n",
    "#         # 클래스 가중치 계산\n",
    "#         effective_num = 1.0 - tf.pow(self.beta, tf.cast(valid_samples_per_cls, tf.float32))\n",
    "#         class_weights = (1.0 - self.beta) / effective_num\n",
    "#         class_weights = tf.expand_dims(class_weights, axis=0)  # 배치 차원 추가\n",
    "#         class_weights = tf.broadcast_to(class_weights, tf.shape(loss)[1:])  # loss의 형상과 일치시킴 (배치 차원 제외)\n",
    "\n",
    "#         # 가중 손실 계산\n",
    "#         weighted_loss = tf.reduce_sum(loss * class_weights, axis=-1)\n",
    "\n",
    "#         return weighted_loss\n",
    "\n",
    "\n",
    "# class CombinedLoss(tf.losses.Loss):\n",
    "#     def __init__(self, alpha=0.75, gamma=5.0, focal_loss_weight=0.5, recall_loss_weight=0.0, name=\"CombinedLoss\"):\n",
    "#         super(CombinedLoss, self).__init__(name=name)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.focal_loss_weight = focal_loss_weight\n",
    "#         self.recall_loss_weight = recall_loss_weight\n",
    "#         self.classification_loss = FocalLoss(alpha=self.alpha, gamma=self.gamma)\n",
    "#         self.mae = ClassificationLoss()\n",
    "#         self.recall_loss = RecallLoss()\n",
    "#         self.binary_error = BinaryCrossEntropyError()\n",
    "#         # self.class_balanced_loss = ClassBalancedLoss()\n",
    "\n",
    "#     def call(self, y_true_cls, y_pred_cls):\n",
    "#         focal_loss = self.classification_loss(y_true_cls, y_pred_cls)\n",
    "#         binary_loss = self.binary_error(y_true_cls, y_pred_cls)\n",
    "#         recall_loss = self.recall_loss(y_true_cls, y_pred_cls)\n",
    "#         mae = self.mae(y_true_cls, y_pred_cls)\n",
    "#         # class_balanced_loss = self.class_balanced_loss(y_true_cls, y_pred_cls)\n",
    "#         combined_loss = (\n",
    "#             self.focal_loss_weight * focal_loss +\n",
    "#             (1 - self.focal_loss_weight - self.recall_loss_weight) * mae\n",
    "#             # class_balanced_loss\n",
    "#         )\n",
    "#         return combined_loss\n",
    "\n",
    "\n",
    "# class Loss(tf.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, gamma=3.0, delta=3, anchors=None):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._cls_loss = CombinedLoss()\n",
    "#         self._box_loss = CombinedCIoUBoxLoss(delta, anchors)  # anchors 전달\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "#         # positive_mask = tf.cast(tf.math.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "#         # ignore_mask = tf.cast(tf.math.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "\n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "        \n",
    "#         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "#         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "\n",
    "#         # cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n",
    "#         # box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "\n",
    "\n",
    "#         cls_weight = 1.0\n",
    "#         box_weight = 1.0\n",
    "#         loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.75, gamma=5.0, threshold=0.525, **kwargs):\n",
    "        super(FocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true)\n",
    "        alpha_t = tf.where(tf.greater(y_true, self.threshold), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.greater(y_true, self.threshold), y_pred, 1 - y_pred)\n",
    "        fl = -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class IoUF1ScoreLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=0.5, beta=2, reduction='auto', **kwargs):\n",
    "        super().__init__(reduction=reduction, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= self.threshold, tf.float32)\n",
    "        y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true_binary * y_pred_binary, axis=-1)\n",
    "        fp = tf.reduce_sum((1 - y_true_binary) * y_pred_binary, axis=-1)\n",
    "        fn = tf.reduce_sum(y_true_binary * (1 - y_pred_binary), axis=-1)\n",
    "\n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "        beta_squared = self.beta ** 2\n",
    "        f1_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "        return 1 - f1_score\n",
    "\n",
    "\n",
    "class Loss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=1, alpha=0.75, gamma=5, delta=2):\n",
    "        super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "        self._box_loss = BoxLoss(delta=delta)\n",
    "        # self._cls_loss = HuberLoss(0.5)\n",
    "        self._cls_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self._f1_loss = IoUF1ScoreLoss()\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "\n",
    "        cls_labels = y_true[:, :, 4:]\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "        \n",
    "        cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "        f1_loss = self._f1_loss(cls_labels, cls_predictions)\n",
    "        box_loss = self._box_loss(box_labels, box_predictions)\n",
    "        \n",
    "        cls_loss = 0.6 * cls_loss + 0.4 * f1_loss\n",
    "\n",
    "        cls_weight = 0.7\n",
    "        box_weight = 0.3\n",
    "        loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mAP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, iou_threshold=0.5, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "        super(mAP, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.anchors = anchors\n",
    "        self.box_variance = box_variance\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "        pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        \n",
    "        pred_probs = tf.nn.sigmoid(y_pred[..., 4:])\n",
    "        pred_labels = tf.argmax(pred_probs, axis=-1)\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            cls_true = tf.equal(y_true[..., cls + 4], 1)\n",
    "            cls_pred = tf.equal(pred_labels, cls)\n",
    "            \n",
    "            iou = self.iou(true_boxes, pred_boxes)\n",
    "            \n",
    "            cls_true_positives = tf.reduce_sum(tf.cast(tf.logical_and(cls_true, tf.logical_and(cls_pred, tf.greater_equal(iou, self.iou_threshold))), tf.float32))\n",
    "            cls_false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.logical_not(cls_true), tf.logical_and(cls_pred, tf.greater_equal(iou, self.iou_threshold))), tf.float32))  \n",
    "            cls_false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(cls_true, tf.logical_and(tf.logical_not(cls_pred), tf.less(iou, self.iou_threshold))), tf.float32))\n",
    "            \n",
    "            self.true_positives.assign(self.true_positives + tf.one_hot(cls, depth=self.num_classes) * cls_true_positives)\n",
    "            self.false_positives.assign(self.false_positives + tf.one_hot(cls, depth=self.num_classes) * cls_false_positives)\n",
    "            self.false_negatives.assign(self.false_negatives + tf.one_hot(cls, depth=self.num_classes) * cls_false_negatives)\n",
    "\n",
    "    def result(self):\n",
    "        per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros_like(self.true_positives)) \n",
    "        self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "        self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "    def decode_predictions(self, labels, anchors):\n",
    "        anchor_x = anchors[..., 0]\n",
    "        anchor_y = anchors[..., 1] \n",
    "        anchor_w = anchors[..., 2]\n",
    "        anchor_h = anchors[..., 3]\n",
    "\n",
    "        cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "        cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "        height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return decoded_boxes\n",
    "\n",
    "    def iou(self, y_true, y_pred):\n",
    "        x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "        y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "        x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "        y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "\n",
    "        intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "        area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "        union = area_true + area_pred - intersection\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recall(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Recall', threshold=0.5, **kwargs):\n",
    "        super(Recall, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.actual_positives = self.add_weight(name='actual_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        \n",
    "        actual_positives = tf.cast(labels, self.dtype)\n",
    "        self.actual_positives.assign_add(tf.reduce_sum(actual_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.actual_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class Precision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Precision', threshold=0.5, **kwargs):\n",
    "        super(Precision, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.predicted_positives = self.add_weight(name='predicted_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        self.predicted_positives.assign_add(tf.reduce_sum(pred_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.predicted_positives + tf.keras.backend.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0002\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 10\n",
    "decay_rate = 0.5\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import Precision, Recall\n",
    "# import tfr\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "model = DetectionModel(num_classes)\n",
    "loss_fn = Loss(num_classes=1)\n",
    "# optimizer = tf.optimizers.Adam(clipnorm = 1.0)\n",
    "\n",
    "\n",
    "# map_metric = MeanAveragePrecision(num_classes=num_classes, anchors=anchors)\n",
    "# iou_metric = IntersectionOverUnion(num_classes=num_classes, anchors=anchors)\n",
    "\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)\n",
    "# iou_metric = MultiBoxIoUMetric(anchors=anchors)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer=optimizer, \n",
    "#               loss=[loss_fn],\n",
    "#               metrics=[Precision()])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=[loss_fn],\n",
    "              metrics=['accuracy', Precision(), Recall()]) #mAP(num_classes = num_classes, anchors = anchors), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (12, 24, 32, 1)\n",
      "Labels shape: (12, 4032, 5)\n",
      "Images max: 255.0\n",
      "Images min: 0.0\n",
      "1682\n",
      "1261\n"
     ]
    }
   ],
   "source": [
    "new_batch_size = 12\n",
    "\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "# val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "# for images, labels in val_dataset.take(1):\n",
    "#     print(f\"Images shape: {images.shape}\")\n",
    "#     print(f\"Labels shape: {labels.shape}\")\n",
    "#     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "#     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "\n",
    "val = 0\n",
    "for _, _, _ in val_dataset:\n",
    "    val += 1\n",
    "print(val)\n",
    "\n",
    "\n",
    "train = 0\n",
    "for _, _ in train_dataset:\n",
    "    train += 1\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:21:38.087859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-04-16 18:21:41.970898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f81589a75e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-16 18:21:41.970930: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.970936: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.970940: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.970944: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.970948: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.970952: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.970956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-16 18:21:41.975418: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-16 18:21:42.113640: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261/1261 [==============================] - 102s 54ms/step - loss: 28.8818 - accuracy: 0.5562 - Precision: 0.3376 - Recall: 0.5880 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/300\n",
      "1261/1261 [==============================] - 67s 53ms/step - loss: 14.8045 - accuracy: 0.7411 - Precision: 0.5940 - Recall: 0.6922 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/300\n",
      "1261/1261 [==============================] - 66s 52ms/step - loss: 13.8205 - accuracy: 0.7600 - Precision: 0.6116 - Recall: 0.7088 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/300\n",
      "1261/1261 [==============================] - 66s 52ms/step - loss: 13.3291 - accuracy: 0.7698 - Precision: 0.6200 - Recall: 0.7174 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/300\n",
      "1261/1261 [==============================] - 67s 53ms/step - loss: 13.0068 - accuracy: 0.7746 - Precision: 0.6280 - Recall: 0.7234 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/300\n",
      "1261/1261 [==============================] - 68s 53ms/step - loss: 12.6877 - accuracy: 0.7803 - Precision: 0.6341 - Recall: 0.7285 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/300\n",
      "1261/1261 [==============================] - 67s 53ms/step - loss: 12.4405 - accuracy: 0.7851 - Precision: 0.6391 - Recall: 0.7327 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/300\n",
      "1261/1261 [==============================] - 67s 53ms/step - loss: 12.1797 - accuracy: 0.7889 - Precision: 0.6446 - Recall: 0.7367 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/300\n",
      "1261/1261 [==============================] - 68s 54ms/step - loss: 11.9558 - accuracy: 0.7923 - Precision: 0.6490 - Recall: 0.7403 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/300\n",
      "1261/1261 [==============================] - 67s 53ms/step - loss: 11.7975 - accuracy: 0.7942 - Precision: 0.6532 - Recall: 0.7432 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 11/300\n",
      " 686/1261 [===============>..............] - ETA: 30s - loss: 11.3373 - accuracy: 0.7990 - Precision: 0.6647 - Recall: 0.7512"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    # validation_data = val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=lr_callback,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2): \n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.5, top_n=20):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "\n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "\n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i = scores.pop(0)\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "\n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(30):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
