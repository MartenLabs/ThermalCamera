{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 08:54:02.707434: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-19 08:54:02.744338: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-19 08:54:02.744367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-19 08:54:02.744387: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-19 08:54:02.751638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 08:54:03.433196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 08:54:05.056644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 22198 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-19 08:54:05.057567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:1 with 22198 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-19 08:54:05.058319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:2 with 22198 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-19 08:54:05.059067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:3 with 22198 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-19 08:54:05.059791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:4 with 22198 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-19 08:54:05.060514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:5 with 22198 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-19 08:54:05.061254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:6 with 22198 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4728393732847948197\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 17082429267726020379\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2067689850251347900\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 2144165316,\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3251932458770108299\n",
       " physical_device_desc: \"device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1651660799,\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 18242408491386553674\n",
       " physical_device_desc: \"device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 878896533,\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16928989771979221377\n",
       " physical_device_desc: \"device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 615190153,\n",
       " name: \"/device:GPU:5\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11628116297759578214\n",
       " physical_device_desc: \"device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1769886423,\n",
       " name: \"/device:GPU:6\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 12241660485752793514\n",
       " physical_device_desc: \"device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 893286608]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 사용할 GPU를 설정 (여기서는 GPU 0번만 사용)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # GPU 0만 TensorFlow에서 사용하도록 설정\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        # GPU 메모리 성장 허용 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # GPU가 이미 사용 중이라면 예외 발생\n",
    "        print(e)\n",
    "        \n",
    "# TensorFlow가 실제로 GPU를 사용하는지 확인하기 위한 간단한 테스트\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17820, 24, 32, 1) (17820,) (17820, 4, 4) 17820\n",
      "255 0\n",
      "(5156, 24, 32, 1)\n",
      "(5156, 4, 4)\n",
      "5156\n",
      "[[1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 2)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "24\n",
      "32\n",
      "bbox:  tf.Tensor(\n",
      "[[ 2  7 15 17]\n",
      " [21  1 29  9]\n",
      " [28  4 32 12]\n",
      " [ 0  0  0  0]], shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 08:54:05.217344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22198 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 1]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SIZE_WIDTH:   32\n",
      "IMG_SIZE_HEIGHT:  24\n",
      "N_DATA:           5156\n",
      "N_TRAIN:          4641\n",
      "N_VAL:            515\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.1)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5156, 24, 32, 1)\n",
      "(5156, 4, 4)\n",
      "(5156, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "    \n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    \n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[[0.3125     0.         0.53125    0.25      ]\n",
      "  [0.40625    0.29166666 0.59375    0.5416667 ]\n",
      "  [0.1875     0.20833333 0.40625    0.5       ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 4, 4), dtype=float32)\n",
      "tf.Tensor([[1 1 1 0]], shape=(1, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515\n",
      "4641\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "for _, _, _ in val_dataset:\n",
    "    val += 1\n",
    "print(val)\n",
    "\n",
    "\n",
    "train = 0\n",
    "for _, _, _ in train_dataset:\n",
    "    train += 1\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.46875    0.5        0.75       0.75      ]\n",
      " [0.4375     0.41666666 0.6875     0.7083333 ]\n",
      " [0.5        0.         0.71875    0.125     ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0] * RES_WIDTH,\n",
    "    \t bbox[:,1] * RES_HEIGHT,\n",
    "    \t bbox[:,2] * RES_WIDTH,\n",
    "    \t bbox[:,3] * RES_HEIGHT\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.515625   0.10416666 0.15625    0.20833333]\n",
      " [0.3125     0.16666666 0.3125     0.24999999]\n",
      " [0.296875   0.41666666 0.34375    0.3333333 ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(245.0, shape=(), dtype=float32) tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.4375     0.         0.15625    0.20833333]\n",
      " [0.15625    0.04166666 0.3125     0.24999999]\n",
      " [0.125      0.25       0.34375    0.3333333 ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.4375     0.         0.15625    0.20833333], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.15625    0.04166666 0.3125     0.24999999], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.125     0.25      0.34375   0.3333333], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.71875    0.6041666  0.25       0.4583333 ]\n",
      " [0.921875   0.875      0.15625    0.25      ]\n",
      " [0.921875   0.5625     0.15625    0.29166666]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(255.0, shape=(), dtype=float32) tf.Tensor(7.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.59375    0.37499997 0.25       0.4583333 ]\n",
      " [0.84375    0.75       0.15625    0.25      ]\n",
      " [0.84375    0.4166667  0.15625    0.29166666]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.59375    0.37499997 0.25       0.4583333 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.84375 0.75    0.15625 0.25   ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.84375    0.4166667  0.15625    0.29166666], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_sizes (pixels):  [[ 8.677325   8.149225 ]\n",
      " [ 6.5484915 11.511494 ]\n",
      " [ 9.916665  12.871796 ]\n",
      " [ 5.4739733  7.2365923]]\n",
      "anchor_ratios:  [1.1007769  0.5764195  0.79242164 0.78455573]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def compute_anchor_boxes(bboxes, img_width, img_height):\n",
    "    all_bboxes = []\n",
    "    for image_bboxes in bboxes:\n",
    "        # 정규화된 좌표를 픽셀 단위 좌표로 변환\n",
    "        pixel_bboxes = np.copy(image_bboxes)\n",
    "        pixel_bboxes[:, 0] *= img_width\n",
    "        pixel_bboxes[:, 1] *= img_height\n",
    "        pixel_bboxes[:, 2] *= img_width\n",
    "        pixel_bboxes[:, 3] *= img_height\n",
    "        all_bboxes.extend(pixel_bboxes)\n",
    "    \n",
    "    all_bboxes = np.array(all_bboxes)\n",
    "    \n",
    "    # 높이가 0인 바운딩 박스 제거\n",
    "    valid_bboxes = all_bboxes[np.logical_and(all_bboxes[:, 2] > all_bboxes[:, 0], all_bboxes[:, 3] > all_bboxes[:, 1])]\n",
    "    \n",
    "    box_sizes = valid_bboxes[:, 2:] - valid_bboxes[:, :2]\n",
    "    box_ratios = box_sizes[:, 0] / box_sizes[:, 1]\n",
    "    \n",
    "    data = np.column_stack((box_sizes[:, 0], box_sizes[:, 1], box_ratios))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(data)\n",
    "    \n",
    "    anchor_sizes = kmeans.cluster_centers_[:, :2]\n",
    "    anchor_ratios = kmeans.cluster_centers_[:, 2]\n",
    "    \n",
    "    return anchor_sizes, anchor_ratios\n",
    "\n",
    "bboxes = []\n",
    "for image, image_bboxes, label in train_dataset:\n",
    "    bboxes.append(image_bboxes.numpy())\n",
    "\n",
    "# 이미지 너비와 높이 설정\n",
    "img_width = 32\n",
    "img_height = 24\n",
    "\n",
    "anchor_sizes, anchor_ratios = compute_anchor_boxes(bboxes, img_width, img_height)\n",
    "print(\"anchor_sizes (pixels): \", anchor_sizes)\n",
    "print(\"anchor_ratios: \", anchor_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.6, 0.8, 1.1]        \n",
    "        self.scales = [2** x for x in [1/3, 2/3]]\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [4.5, 5.5, 3.5]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1),\n",
    "                    [1, 1, 2]\n",
    "                )\n",
    "                dims = tf.cast(dims, tf.float32)  # 데이터 타입을 float32로 변환\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor 음수 값: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0] / RES_WIDTH\n",
    "ymin = anchor[:, 1] / RES_HEIGHT\n",
    "xmax = anchor[:, 2] / RES_WIDTH\n",
    "ymax = anchor[:, 3] / RES_HEIGHT\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x * RES_WIDTH, top_left_y * RES_HEIGHT), width * RES_WIDTH, height * RES_HEIGHT, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelEncoder:\n",
    "#     def __init__(self):\n",
    "#         self._anchor_box = AnchorBox()\n",
    "#         self._box_variance = tf.convert_to_tensor(\n",
    "#             [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "#     def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "#         iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "#         max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "\n",
    "#         matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "#         positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "#         negative_mask = tf.less(max_iou, ignore_iou)\n",
    "\n",
    "#         ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "#         return (\n",
    "#             matched_gt_idx,\n",
    "#             tf.cast(positive_mask, dtype = tf.float32),\n",
    "#             tf.cast(ignore_mask, dtype = tf.float32),\n",
    "#         )\n",
    "    \n",
    "#     def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "#         box_target = tf.concat(\n",
    "#             [\n",
    "#                 (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "#                 tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "#             ],\n",
    "#             axis = -1,\n",
    "#         )\n",
    "#         box_target = box_target / self._box_variance\n",
    "#         return box_target\n",
    "    \n",
    "\n",
    "#     def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "#         anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "#         # 앵커 박스 정규화\n",
    "#         xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "#         ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "#         xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "#         ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "\n",
    "#         # 정규화된 좌표를 스택으로 결합\n",
    "#         normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "#         cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "#         matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "#             normalized_anchor, gt_boxes\n",
    "#         )\n",
    "\n",
    "#         matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "\n",
    "        \n",
    "#         box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "\n",
    "#         matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "\n",
    "#         cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "#         cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "\n",
    "#         cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "#         num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "#         print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "#         label = tf.concat([box_target, cls_target], axis=-1)\n",
    "#         return label\n",
    "\n",
    "#     def encode_batch(self, batch_images, gt_boxes, cls_ids):       \n",
    "#         images_shape = tf.shape(batch_images)\n",
    "#         batch_size = images_shape[0]\n",
    "\n",
    "#         labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "#         for i in range(batch_size):\n",
    "#             label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "#             labels = labels.write(i, label)\n",
    "#         return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou=0.5):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
    "        return matched_gt_idx, max_iou\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        box_target = box_target / self._box_variance\n",
    "        return box_target\n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # Normalize anchor boxes\n",
    "        xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "        ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "        xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "        ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        matched_gt_idx, iou_scores = self._match_anchor_boxes(normalized_anchor, gt_boxes)\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        \n",
    "        # Use IoU scores as labels for classification\n",
    "        cls_target = iou_scores\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            labels = labels.write(i, label)\n",
    "        return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0 0.0\n",
      "(1, 6048, 5)\n",
      "Positive 개수: 0\n",
      "Negative 개수: 0\n",
      "Ignore 개수: 0\n",
      "255.0 28.0\n",
      "(1, 6048, 5)\n",
      "Positive 개수: 0\n",
      "Negative 개수: 0\n",
      "Ignore 개수: 0\n",
      "243.0 22.0\n",
      "(1, 6048, 5)\n",
      "Positive 개수: 0\n",
      "Negative 개수: 0\n",
      "Ignore 개수: 0\n"
     ]
    }
   ],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, labels = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(labels.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 0\n",
      "Negative 개수: 5892\n",
      "Ignore 개수: 0\n",
      "Positive 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    label_idx = 0\n",
    "    for label in labels:\n",
    "        # if label[4] == 1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        # elif label[4] == -1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        dx, dy, dw, dh = label[:4]\n",
    "        anchor = anchors[label_idx]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, width, height]\n",
    "        # print(np.array(decoded_box))\n",
    "        if label[4] == 1.0:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "        label_idx += 1\n",
    "        # if len(np.array(decoded_boxes)) > 1: \n",
    "            # break\n",
    "    print(\"Positive\",len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes    \n",
    "    # print(np.array(decoded_boxes))\n",
    "    \n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    # print(len(decoded_boxes))\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i+=1\n",
    "        # print(box)\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    # print(i)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(1):\n",
    "    image = batch[0][0].numpy()\n",
    "    labels = batch[1][0].numpy()  # 여기서 labels는 [오프셋x, 오프셋y, 스케일w, 스케일h, 클래스, 앵커 박스 인덱스]를 포함한다고 가정\n",
    "    # print(labels)\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(labels, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bottleneck(layers.Layer):\n",
    "#     def __init__(self, out_channels, stride=1):\n",
    "#         super(Bottleneck, self).__init__()\n",
    "#         self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "#         self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         identity = x\n",
    "#         out = self.conv_0(x)\n",
    "#         out = self.conv_1(out)\n",
    "#         out += identity\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=2, padding='SAME'):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding=padding, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "        self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.conv_1(out)\n",
    "        out += identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding='SAME'):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv1 = Conv(out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.maxpool1 = layers.MaxPooling2D(pool_size=1, strides=1, padding='SAME')\n",
    "        self.maxpool2 = layers.MaxPooling2D(pool_size=3, strides=1, padding='SAME')\n",
    "        self.maxpool3 = layers.MaxPooling2D(pool_size=5, strides=1, padding='SAME')\n",
    "        self.conv2 = Conv(out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "    \n",
    "        pool1 = self.maxpool1(x)\n",
    "        pool2 = self.maxpool2(x)\n",
    "        pool3 = self.maxpool3(x)\n",
    "\n",
    "        concatenated = tf.concat([x, pool1, pool2, pool3], axis=-1)\n",
    "\n",
    "        out = self.conv2(concatenated)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiStageFeatureExtractionLayer\n",
    "class MSFELayer(layers.Layer):\n",
    "    def __init__(self, sperate_input_channel, out_channel):\n",
    "        super(MSFELayer, self).__init__()\n",
    "        self.cbam = CBAM()\n",
    "        self.bottleneck = Bottleneck(sperate_input_channel)\n",
    "        self.conv_out = Conv(out_channel, kernel_size=3, stride=1, padding='SAME')\n",
    "\n",
    "    def call(self, x):\n",
    "        cbam = self.cbam(x)\n",
    "        bottle = self.bottleneck(x)\n",
    "        out = tf.concat([bottle, cbam], axis = -1)\n",
    "        out = self.conv_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "        # self.conv = layers.Conv2D(out_channel, kernel_size = 1, strides = 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    def call(self, inputs):\n",
    "        out = self.upsample(inputs)\n",
    "        # out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose(layers.Layer):\n",
    "    def __init__(self, out_channel, size):\n",
    "        super(Conv2DTranspose, self).__init__()\n",
    "        self.transpose = layers.Conv2DTranspose(filters=out_channel, kernel_size=3, strides=size, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.transpose(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSUpsample(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size, size, interpolation = 'bilinear'):\n",
    "        super(CSUpsample, self).__init__()\n",
    "        self.upsample = Upsample(size=size, interpolation = interpolation)\n",
    "        self.transpose = Conv2DTranspose(out_channel * 2, size=size)\n",
    "        self.conv = Conv(out_channel, kernel_size = kernel_size, stride=1, padding='SAME')\n",
    "    \n",
    "    def call(self, x):\n",
    "        upsample, transpose = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        upsample = self.upsample(upsample)\n",
    "        transpose = self.transpose(transpose)\n",
    "\n",
    "        out = tf.concat([upsample, transpose], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, filters, reduction=2, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction = reduction\n",
    "        self.f = layers.Conv2D(filters // reduction, 1, use_bias=False)\n",
    "        self.g = layers.Conv2D(filters // reduction, 1, use_bias=False)\n",
    "        self.h = layers.Conv2D(filters, 1, use_bias=False)\n",
    "        self.softmax = layers.Softmax(axis=-1)\n",
    "\n",
    "    def call(self, x):\n",
    "        f = self.f(x)\n",
    "        g = self.g(x)\n",
    "        h = self.h(x)\n",
    "\n",
    "        s = tf.matmul(g, f, transpose_b=True)\n",
    "        beta = self.softmax(s)\n",
    "\n",
    "        o = tf.matmul(beta, h)\n",
    "        o = tf.add(o, x)\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(out_channels=8, kernel_size=3, stride=1) # 24, 32\n",
    "        self.msfe1 = MSFELayer(8, 12)\n",
    "\n",
    "        self.conv2 = Conv(out_channels=12, kernel_size=3, stride=2) # 12, 16\n",
    "        self.msfe2 = MSFELayer(12, 20)\n",
    "\n",
    "        self.conv3 = Conv(out_channels=20, kernel_size=3, stride=2) # 6, 8\n",
    "        self.msfe3 = MSFELayer(20, 28)\n",
    "\n",
    "        self.conv4 = Conv(out_channels=28, kernel_size=3, stride=2) # 3, 4\n",
    "        self.msfe4 = MSFELayer(28, 36)\n",
    "        # self.sppf = SPPFast(24)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1 = self.conv1(inputs) \n",
    "        p1_out = self.msfe1(p1) # 24, 32, 18\n",
    "\n",
    "        p2 = self.conv2(p1_out)\n",
    "        p2_out = self.msfe2(p2) # 12, 16, 21\n",
    "\n",
    "        p3 = self.conv3(p2_out) \n",
    "        p3_out = self.msfe3(p3) # 6, 8, 24\n",
    "\n",
    "        p4 = self.conv4(p3_out)\n",
    "        p4_out = self.msfe4(p4) # 3, 4, 27\n",
    "\n",
    "        # return p1_out, p2_out, p3_out, p4_out\n",
    "        return p1_out, p2_out, p3_out, p4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPPN(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FPPN, self).__init__()\n",
    "        self.csupsample1 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csupsample2 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csupsample3 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        # FPN layers\n",
    "        self.lateral_conv1 = MSFELayer(12, 36)\n",
    "        self.lateral_conv2 = MSFELayer(20, 36)\n",
    "        self.lateral_conv3 = MSFELayer(28, 36)\n",
    "        self.lateral_conv4 = MSFELayer(36, 36)\n",
    "        \n",
    "        self.smooth_conv1 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv2 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv3 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "#   • c1=tf.Tensor(shape=(None, 24, 32, 12), dtype=float32)\n",
    "#   • c2=tf.Tensor(shape=(None, 12, 16, 12), dtype=float32)\n",
    "#   • c3=tf.Tensor(shape=(None, 6, 8, 20), dtype=float32)\n",
    "\n",
    "    def call(self, p1_out, p2_out, p3_out, p4_out):\n",
    "        lateral_conv1 = self.lateral_conv1(p1_out)\n",
    "        lateral_conv2 = self.lateral_conv2(p2_out)\n",
    "        lateral_conv3 = self.lateral_conv3(p3_out)\n",
    "        lateral_conv4 = self.lateral_conv4(p4_out)\n",
    "\n",
    "        fpn_out4 = lateral_conv4\n",
    "        fpn_out3 = layers.Add()([self.csupsample1(fpn_out4), lateral_conv3])\n",
    "        fpn_out2 = layers.Add()([self.csupsample2(fpn_out3), lateral_conv2])\n",
    "        fpn_out1 = layers.Add()([self.csupsample3(fpn_out2), lateral_conv1])\n",
    "\n",
    "        fpn_out1 = self.smooth_conv1(fpn_out1)\n",
    "        fpn_out2 = self.smooth_conv2(fpn_out2)\n",
    "        fpn_out3 = self.smooth_conv3(fpn_out3)\n",
    "        \n",
    "        return fpn_out1, fpn_out2, fpn_out3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 1, num_anchors_per_location = 6):\n",
    "        super(DetectionModel, self).__init__()\n",
    "\n",
    "        self.backbone = BackBone()\n",
    "        # self.neck = Neck()\n",
    "        # self.head = Head()\n",
    "        self.fppn = FPPN()\n",
    "        self.msfe1 = MSFELayer(36, 72)\n",
    "        self.conv1 = Conv(72, kernel_size = 1, stride=1)\n",
    "        self.conv2 = Conv(72, kernel_size = 3, stride=1)\n",
    "        self.cbam = CBAM()\n",
    "        self.attention = SelfAttention(num_anchors_per_location * num_classes)\n",
    "        # self.msfe2 = MSFELayer(72, 72)\n",
    "        \n",
    "        \n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            self.msfe1,\n",
    "            self.conv1,\n",
    "            self.conv2,\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            self.cbam,\n",
    "            self.attention,\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(36, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            layers.Conv2D(36, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            # self.msfe2,\n",
    "            # self.conv2,\n",
    "            layers.Conv2D(num_anchors_per_location * 4, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1_out, p2_out, p3_out, p4_out = self.backbone(inputs)\n",
    "        # c1, c2, c3 = self.neck(p1, p2, p3, p4)\n",
    "        # h1_out, h2_out, h3_out = self.head(c1, c2, c3)\n",
    "        fpn_out1, fpn_out2, fpn_out3 = self.fppn(p1_out, p2_out, p3_out, p4_out)\n",
    "\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        N = tf.shape(inputs)[0]\n",
    "        \n",
    "        for _, feature in enumerate([fpn_out1, fpn_out2, fpn_out3]):\n",
    "            cls_output = self.classification_head(feature)\n",
    "            reg_output = self.regression_head(feature)\n",
    "            \n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "\n",
    "            cls_outputs.append(cls_output)\n",
    "            reg_outputs.append(reg_output)\n",
    "\n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "        # clipped_outputs = tf.clip_by_value(cls_outputs, -4, 4)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"detection_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " back_bone (BackBone)        multiple                  63012     \n",
      "                                                                 \n",
      " fppn (FPPN)                 multiple                  162020    \n",
      "                                                                 \n",
      " msfe_layer_8 (MSFELayer)    (None, None, None, 72)    61002     \n",
      "                                                                 \n",
      " conv_31 (Conv)              (None, None, None, 72)    5544      \n",
      "                                                                 \n",
      " conv_32 (Conv)              (None, None, None, 72)    47016     \n",
      "                                                                 \n",
      " cbam_9 (CBAM)               (None, None, None, 6)     126       \n",
      "                                                                 \n",
      " self_attention (SelfAttent  (None, None, None, 6)     72        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, None, 6)     117984    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, None, 24)    3552      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 346568 (1.32 MB)\n",
      "Trainable params: 344720 (1.32 MB)\n",
      "Non-trainable params: 1848 (7.22 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DetectionModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred, sample_weight=None):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "\n",
    "        # Positive 샘플에 대해서만 손실을 계산하고, 나머지는 0으로 설정\n",
    "        positive_mask = tf.cast(tf.greater(y_true, 0.0), tf.float32)\n",
    "        loss = loss * positive_mask\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            loss = tf.multiply(loss, sample_weight)\n",
    "\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class ConditionalFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, threshold=0.55, **kwargs):\n",
    "        super(ConditionalFocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= 0.5, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true_binary)\n",
    "        alpha_t = tf.where(tf.equal(y_true_binary, 1.0), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.equal(y_true_binary, 1.0), y_pred, 1 - y_pred)\n",
    "        \n",
    "        # Condition 1: y_true = 1\n",
    "        condition1 = tf.equal(y_true_binary, 1.0)\n",
    "        loss1 = tf.where(tf.less(p_t, self.threshold),\n",
    "                         -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "                         0.0)\n",
    "        \n",
    "        # Condition 2: y_true = 0\n",
    "        condition2 = tf.equal(y_true_binary, 0.0)\n",
    "        loss2 = tf.where(tf.greater_equal(p_t, self.threshold),\n",
    "                         -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "                         0.0)\n",
    "        \n",
    "        fl = tf.where(condition1, loss1, tf.where(condition2, loss2, 0.0))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):  # Precision (0.55 best)\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, threshold=0.55, **kwargs):\n",
    "        super(FocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true)\n",
    "        alpha_t = tf.where(tf.greater(y_true, self.threshold), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.greater(y_true, self.threshold), y_pred, 1 - y_pred)\n",
    "        fl = -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class IoUF1ScoreLoss(tf.keras.losses.Loss):  # Precision\n",
    "    def __init__(self, threshold=0.5, beta=3, reduction='auto', **kwargs):\n",
    "        super().__init__(reduction=reduction, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= self.threshold, tf.float32)\n",
    "        y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true_binary * y_pred_binary, axis=-1)\n",
    "        fp = tf.reduce_sum((1 - y_true_binary) * y_pred_binary, axis=-1)\n",
    "        fn = tf.reduce_sum(y_true_binary * (1 - y_pred_binary), axis=-1)\n",
    "\n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "        beta_squared = self.beta ** 2\n",
    "        f1_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "        return 1 - f1_score\n",
    "    \n",
    "\n",
    "    # # Hard Negative Mining \n",
    "class Loss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=1, alpha=0.25, gamma=2, delta=1, negative_ratio=2.0):\n",
    "        super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "        self._box_loss = BoxLoss(delta=delta)\n",
    "        self._focal_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self._num_classes = num_classes\n",
    "        self._negative_ratio = negative_ratio\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "        cls_labels = y_true[:, :, 4:]\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "        positive_mask = tf.cast(tf.greater_equal(cls_labels, 0.5), tf.bool)\n",
    "        negative_mask = tf.cast(tf.less(cls_labels, 0.5), tf.bool)\n",
    "\n",
    "        num_positives = tf.reduce_sum(tf.cast(positive_mask, tf.float32), axis=1)\n",
    "        num_negatives = tf.cast(self._negative_ratio * tf.reduce_max(num_positives), tf.int32)\n",
    "\n",
    "        negative_cls_loss = self._focal_loss(tf.boolean_mask(cls_labels, negative_mask),\n",
    "                                             tf.boolean_mask(cls_predictions, negative_mask))\n",
    "        negative_cls_loss = tf.reshape(negative_cls_loss, [-1])\n",
    "        _, top_k_indices = tf.math.top_k(negative_cls_loss, k=tf.minimum(num_negatives, tf.shape(negative_cls_loss)[0]), sorted=True)\n",
    "        negative_indices = tf.where(negative_mask)\n",
    "        hard_negative_indices = tf.gather(negative_indices, top_k_indices)\n",
    "        hard_negative_mask = tf.scatter_nd(hard_negative_indices, tf.ones(tf.shape(top_k_indices)[0], dtype=tf.int32),\n",
    "                                           tf.cast(tf.shape(negative_mask), tf.int64))\n",
    "        hard_negative_mask = tf.cast(hard_negative_mask, tf.bool)\n",
    "\n",
    "        focal_loss = self._focal_loss(tf.boolean_mask(cls_labels, tf.logical_or(positive_mask, hard_negative_mask)),\n",
    "                                      tf.boolean_mask(cls_predictions, tf.logical_or(positive_mask, hard_negative_mask)))\n",
    "        box_loss = self._box_loss(box_labels, box_predictions, sample_weight=tf.cast(positive_mask, tf.float32))\n",
    "\n",
    "        cls_weight = 0.7\n",
    "        box_weight = 0.3\n",
    "        loss = cls_weight * (focal_loss / (num_positives + 1e-6))+ box_weight * box_loss\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class mAP(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, num_classes, iou_threshold=0.5, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "#         super(mAP, self).__init__(name=name, **kwargs)\n",
    "#         self.num_classes = num_classes\n",
    "#         self.iou_threshold = iou_threshold\n",
    "#         self.anchors = anchors\n",
    "#         self.box_variance = box_variance\n",
    "#         self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "#         self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "#         self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "#         true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "#         pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        \n",
    "#         pred_probs = tf.nn.sigmoid(y_pred[..., 4])\n",
    "        \n",
    "#         iou = self.iou(true_boxes, pred_boxes)\n",
    "        \n",
    "#         true_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.greater_equal(pred_probs, self.iou_threshold), tf.greater_equal(iou, self.iou_threshold))), tf.float32))\n",
    "#         false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.less(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.greater_equal(pred_probs, self.iou_threshold), tf.greater_equal(iou, self.iou_threshold))), tf.float32))  \n",
    "#         false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.less(pred_probs, self.iou_threshold), tf.less(iou, self.iou_threshold))), tf.float32))\n",
    "        \n",
    "#         self.true_positives.assign(self.true_positives + true_positives)\n",
    "#         self.false_positives.assign(self.false_positives + false_positives)\n",
    "#         self.false_negatives.assign(self.false_negatives + false_negatives)\n",
    "\n",
    "#     def result(self):\n",
    "#         per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "#         return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "#     def reset_state(self):\n",
    "#         self.true_positives.assign(tf.zeros_like(self.true_positives)) \n",
    "#         self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "#         self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "#     def decode_predictions(self, labels, anchors):\n",
    "#         anchor_x = anchors[..., 0]\n",
    "#         anchor_y = anchors[..., 1] \n",
    "#         anchor_w = anchors[..., 2]\n",
    "#         anchor_h = anchors[..., 3]\n",
    "\n",
    "#         cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "#         width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "#         height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         x_max = x_min + width\n",
    "#         y_max = y_min + height\n",
    "\n",
    "#         decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "#         return decoded_boxes\n",
    "\n",
    "#     def iou(self, y_true, y_pred):\n",
    "#         x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "#         y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "#         x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "#         y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "\n",
    "#         intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "#         area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "#         area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "#         union = area_true + area_pred - intersection\n",
    "#         iou = intersection / (union + 1e-6)\n",
    "#         return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class Recall(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Recall', threshold=0.5, **kwargs):\n",
    "        super(Recall, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.actual_positives = self.add_weight(name='actual_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        \n",
    "        actual_positives = tf.cast(labels, self.dtype)\n",
    "        self.actual_positives.assign_add(tf.reduce_sum(actual_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.actual_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class Precision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Precision', threshold=0.5, **kwargs):\n",
    "        super(Precision, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.predicted_positives = self.add_weight(name='predicted_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        self.predicted_positives.assign_add(tf.reduce_sum(pred_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.predicted_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='F1Score', threshold=0.5, **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.precision = Precision(threshold=threshold)\n",
    "        self.recall = Recall(threshold=threshold)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "        return f1_score\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class mAP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, iou_threshold=0.5, score_threshold=0.5, max_detections_per_class=1, max_total_detections=20, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "        super(mAP, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.score_threshold = score_threshold\n",
    "        self.max_detections_per_class = max_detections_per_class\n",
    "        self.max_total_detections = max_total_detections\n",
    "        self.anchors = anchors\n",
    "        self.box_variance = box_variance\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Decode predictions and true boxes\n",
    "        true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "        true_labels = tf.cast(y_true[..., 4], tf.int32)\n",
    "        pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        pred_scores = y_pred[..., 4:]\n",
    "\n",
    "        # Batch size for dynamic handling\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "\n",
    "        # Initialize containers for updates\n",
    "        tp_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "        fp_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "        fn_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "\n",
    "        # Iterate through the batch\n",
    "        for i in range(batch_size):\n",
    "            single_true_boxes = true_boxes[i]\n",
    "            single_true_labels = true_labels[i]\n",
    "            single_pred_boxes = tf.expand_dims(pred_boxes[i], axis=2)  # NMS expects [N, num_boxes, 1, 4]\n",
    "            single_pred_scores = pred_scores[i]  # Scores from the model\n",
    "\n",
    "            # Perform NMS\n",
    "            selected_indices, selected_scores, num_detections = tf.image.combined_non_max_suppression(\n",
    "                boxes=single_pred_boxes,\n",
    "                scores=single_pred_scores,\n",
    "                max_output_size_per_class=self.max_detections_per_class,\n",
    "                max_total_size=self.max_total_detections,\n",
    "                iou_threshold=self.iou_threshold,\n",
    "                score_threshold=self.score_threshold,\n",
    "                pad_per_class=False,\n",
    "                clip_boxes=False\n",
    "            )\n",
    "\n",
    "            # Filter only detected indices\n",
    "            detected_boxes = tf.gather(single_pred_boxes[:, :, 0], selected_indices)\n",
    "            detected_scores = selected_scores\n",
    "            detected_classes = tf.cast(tf.argmax(detected_scores, axis=-1), tf.int32)\n",
    "\n",
    "            # Count true positives, false positives, and false negatives\n",
    "            for c in range(self.num_classes):\n",
    "                class_mask = tf.equal(single_true_labels, c)\n",
    "                class_true_boxes = tf.boolean_mask(single_true_boxes, class_mask)\n",
    "                class_detected_mask = tf.equal(detected_classes, c)\n",
    "                class_detected_boxes = tf.boolean_mask(detected_boxes, class_detected_mask)\n",
    "\n",
    "                # Compute IOU between true and detected boxes for this class\n",
    "                ious = self.iou(tf.expand_dims(class_true_boxes, axis=1), tf.expand_dims(class_detected_boxes, axis=0))\n",
    "                max_iou = tf.reduce_max(ious, axis=0)\n",
    "                iou_mask = max_iou > self.iou_threshold\n",
    "\n",
    "                # Update TP, FP based on IOU mask\n",
    "                tp_updates = tp_updates + tf.reduce_sum(tf.cast(iou_mask, tf.int32))\n",
    "                fp_updates = fp_updates + tf.reduce_sum(tf.cast(tf.logical_not(iou_mask), tf.int32))\n",
    "                fn_updates = fn_updates + (tf.shape(class_true_boxes)[0] - tf.reduce_sum(tf.cast(iou_mask, tf.int32)))\n",
    "\n",
    "        # Assign updated values to the metric variables\n",
    "        self.true_positives.assign_add(tf.cast(tp_updates, dtype=self.dtype))\n",
    "        self.false_positives.assign_add(tf.cast(fp_updates, dtype=self.dtype))\n",
    "        self.false_negatives.assign_add(tf.cast(fn_updates, dtype=self.dtype))\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros_like(self.true_positives))\n",
    "        self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "        self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "    def decode_predictions(self, labels, anchors, batch_size = 9):\n",
    "        anchors = tf.tile(anchors[None, ...], [batch_size, 1, 1])\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = tf.split(anchors, 4, axis=-1)\n",
    "        anchor_w = tf.squeeze(anchor_w, axis=-1)\n",
    "        anchor_h = tf.squeeze(anchor_h, axis=-1)\n",
    "        anchor_x = tf.squeeze(anchor_x, axis=-1)\n",
    "        anchor_y = tf.squeeze(anchor_y, axis=-1)\n",
    "\n",
    "        cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "        cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "        height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return decoded_boxes\n",
    "\n",
    "    def iou(self, y_true, y_pred):\n",
    "        y_true = tf.expand_dims(y_true, axis=0)\n",
    "        y_pred = tf.expand_dims(y_pred, axis=1)\n",
    "\n",
    "        x1 = tf.maximum(y_true[..., 0:1], y_pred[..., 0:1])\n",
    "        y1 = tf.maximum(y_true[..., 1:2], y_pred[..., 1:2])\n",
    "        x2 = tf.minimum(y_true[..., 2:3], y_pred[..., 2:3])\n",
    "        y2 = tf.minimum(y_true[..., 3:4], y_pred[..., 3:4])\n",
    "\n",
    "        intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        area_true = (y_true[..., 2:3] - y_true[..., 0:1]) * (y_true[..., 3:4] - y_true[..., 1:2])\n",
    "        area_pred = (y_pred[..., 2:3] - y_pred[..., 0:1]) * (y_pred[..., 3:4] - y_pred[..., 1:2])\n",
    "        union = area_true + area_pred - intersection\n",
    "\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0002\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "initial_learning_rate = 0.0005\n",
    "decay_steps = 5\n",
    "decay_rate = 0.5\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import Precision, Recall\n",
    "# import tfr\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "model = DetectionModel(num_classes)\n",
    "loss_fn = Loss(num_classes=1)\n",
    "# optimizer = tf.optimizers.Adam(clipnorm = 1.0)\n",
    "\n",
    "\n",
    "# map_metric = MeanAveragePrecision(num_classes=num_classes, anchors=anchors)\n",
    "# iou_metric = IntersectionOverUnion(num_classes=num_classes, anchors=anchors)\n",
    "\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)\n",
    "# iou_metric = MultiBoxIoUMetric(anchors=anchors)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer=optimizer, \n",
    "#               loss=[loss_fn],\n",
    "#               metrics=[Precision()])\n",
    "\n",
    "# mAP(num_classes = num_classes, anchors = anchors),  \n",
    "model.compile(optimizer='adam', \n",
    "              loss=[loss_fn],\n",
    "              metrics=['accuracy', F1Score(), Precision(), Recall()]) # Precision(), Recall()]) # # mAP(num_classes = num_classes, anchors = anchors), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 9\n",
    "\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     print(f\"Images shape: {images.shape}\")\n",
    "#     print(f\"Labels shape: {labels.shape}\")\n",
    "#     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "#     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "# # for images, labels in val_dataset.take(1):\n",
    "# #     print(f\"Images shape: {images.shape}\")\n",
    "# #     print(f\"Labels shape: {labels.shape}\")\n",
    "# #     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "# #     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "\n",
    "# val = 0\n",
    "# for _, _ in val_dataset:\n",
    "#     val += 1\n",
    "# print(val)\n",
    "\n",
    "\n",
    "# train = 0\n",
    "# for _, _ in train_dataset:\n",
    "#     train += 1\n",
    "# print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 08:54:40.445614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-04-19 08:54:44.742136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f87787ab270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-19 08:54:44.742172: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 08:54:44.746931: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-19 08:54:44.867687: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 68s 69ms/step - loss: 70.5574 - accuracy: 0.2739 - F1Score: 0.0734 - Precision: 0.0594 - Recall: 0.0960 - val_loss: 67.6257 - val_accuracy: 0.3266 - val_F1Score: 0.1129 - val_Precision: 0.2130 - val_Recall: 0.0768 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 2/10\n",
      "515/515 [==============================] - 33s 63ms/step - loss: 66.1522 - accuracy: 0.3801 - F1Score: 0.2867 - Precision: 0.4265 - Recall: 0.2159 - val_loss: 66.6331 - val_accuracy: 0.4050 - val_F1Score: 0.1862 - val_Precision: 0.4968 - val_Recall: 0.1146 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 3/10\n",
      "509/515 [============================>.] - ETA: 0s - loss: 63.8352 - accuracy: 0.4186 - F1Score: 0.3247 - Precision: 0.4477 - Recall: 0.2547"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=lr_callback,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 51: LearningRateScheduler setting learning rate to 3.125e-06.\n",
    "# Epoch 51/100\n",
    "# 249/473 [==============>...............] - ETA: 6s - loss: 6.8215 - accuracy: 0.7611 - F1Score: 0.6611 - Precision: 0.7209 - Recall: 0.6104\n",
    "\n",
    "\n",
    "# Epoch 17: LearningRateScheduler setting learning rate to 0.00025.\n",
    "# Epoch 17/100\n",
    "# 131/473 [=======>......................] - ETA: 10s - loss: 7.7444 - accuracy: 0.7838 - F1Score: 0.6975 - Precision: 0.7270 - Recall: 0.6702\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2): \n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.5, top_n=20):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "\n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "\n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i = scores.pop(0)\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "\n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, in val_dataset.take(30):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
