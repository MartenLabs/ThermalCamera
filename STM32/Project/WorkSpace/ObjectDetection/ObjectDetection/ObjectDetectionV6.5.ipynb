{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:10:48.390938: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-10 15:10:48.427557: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-10 15:10:48.427589: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-10 15:10:48.427611: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-10 15:10:48.435282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-10 15:10:49.124668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1\n",
    "N_BATCH = 3\n",
    "N_EPOCH = 200\n",
    "LR = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:10:50.783513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 22455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:50.784357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:1 with 22455 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:50.785034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:2 with 22455 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:50.785723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:3 with 22455 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:50.786359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:4 with 22455 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:50.787003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:5 with 22455 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:50.787644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:6 with 22455 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 15252045788612929531\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11599484103953697574\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1431250031683734524\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 2144165316,\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15479206572978740168\n",
       " physical_device_desc: \"device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1651660799,\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 101565857917148206\n",
       " physical_device_desc: \"device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 878896533,\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16862119808511614890\n",
       " physical_device_desc: \"device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 615190153,\n",
       " name: \"/device:GPU:5\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 998650327748600472\n",
       " physical_device_desc: \"device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1769886423,\n",
       " name: \"/device:GPU:6\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23546626048\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 13839493583636750789\n",
       " physical_device_desc: \"device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 893286608]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현제 바운딩박스는 xmin, ymin, xmax, ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17820, 24, 32, 1) (17820,) (17820, 4, 4) 17820\n",
      "255 0\n",
      "(13544, 24, 32, 1)\n",
      "(13544, 4, 4)\n",
      "13544\n",
      "[[1 1 0 0]\n",
      " [1 1 0 0]\n",
      " [1 1 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 1)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0]\n",
      " [1 1 0 0]\n",
      " [1 1 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  3 14 14]\n",
      " [24  0 32  6]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n",
      "255 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset['images'][0])\n",
    "print(dataset['bboxes'][0])\n",
    "print(dataset['images'].max(), dataset['images'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "24\n",
      "32\n",
      "bbox:  tf.Tensor(\n",
      "[[ 3  3 14 14]\n",
      " [24  0 32  6]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]], shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:10:51.051842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22455 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:51.052055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22455 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:51.052242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22455 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:51.052428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22455 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:51.052613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 22455 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:51.052797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 22455 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-10 15:10:51.054484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 22455 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0]\n",
      " [1 1 0 0]\n",
      " [1 1 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.max(), images.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SIZE_WIDTH:   32\n",
      "IMG_SIZE_HEIGHT:  24\n",
      "N_DATA:           13544\n",
      "N_TRAIN:          10836\n",
      "N_VAL:            2708\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.2)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13544, 24, 32, 1)\n",
      "(13544, 4, 4)\n",
      "(13544, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0], bbox[:, 1], bbox[:, 2], bbox[:, 3]\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "\n",
    "    number = numbers[idx]\n",
    "    class_id = cls[idx]\n",
    "    # print(len(cls))\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0], bbox[:, 1], bbox[:, 2], bbox[:, 3]\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "\n",
    "    number = numbers[idx]\n",
    "    class_id = cls[idx]\n",
    "    # print(len(cls))\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "# LR = 0.0005\n",
    "\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        # 'number': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    # image = image / tf.reduce_max(image)\n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    # num_boxes = tf.shape(bbox)[0] // 4\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    # number = tf.cast(parsed_features['number'], tf.int64)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "# LR = 0.0005\n",
    "\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        # 'number': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    # image = image / tf.reduce_max(image)\n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    # num_boxes = tf.shape(bbox)[0] // 4\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    # number = tf.cast(parsed_features['number'], tf.int64)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[[14.  2. 22. 11.]\n",
      "  [21.  4. 30.  8.]\n",
      "  [ 0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.]]], shape=(1, 4, 4), dtype=float32)\n",
      "tf.Tensor([[1 1 0 0]], shape=(1, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 8.  5. 17. 12.]\n",
      " [ 1. 18.  9. 24.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]], shape=(4, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0],\n",
    "    \t bbox[:,1],\n",
    "    \t bbox[:,2],\n",
    "    \t bbox[:,3]\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(252.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    anchor_img = np.zeros((*image.shape[:3], 3), dtype=np.uint8)\n",
    "    anchor_img = anchor_img[idx]\n",
    "\n",
    "    strides = [2, 4, 8]\n",
    "    colors = {\n",
    "        2: [0, 255, 0],  # 초록색\n",
    "        4: [0, 0, 255],  # 파란색\n",
    "        8: [255, 0, 0],   # 빨간색\n",
    "    }\n",
    "\n",
    "    for stride in strides:\n",
    "        color = colors[stride]\n",
    "        for y in range(0, anchor_img.shape[0], stride):\n",
    "            for x in range(0, anchor_img.shape[1], stride):\n",
    "                anchor_img[y, x, :] = color\n",
    "\n",
    "    # 이미지 표시\n",
    "    plt.imshow(image[idx], alpha=1)  \n",
    "    plt.imshow(anchor_img, alpha=0.5) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[19.  21.   8.   6. ]\n",
      " [ 4.  14.5  8.   7. ]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0. ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(235.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[15. 18.  8.  6.]\n",
      " [ 0. 11.  8.  7.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([15. 18.  8.  6.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([ 0. 11.  8.  7.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[ 8.5  2.5  5.   5. ]\n",
      " [28.5 11.   7.   6. ]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0. ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(252.0, shape=(), dtype=float32) tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[ 6.  0.  5.  5.]\n",
      " [25.  8.  7.  6.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([6. 0. 5. 5.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([25.  8.  7.  6.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.6, 1.1, 1.6]         # 이거랑 2268\n",
    "        self.scales = [2** x for x in [0, 1/3, 2/3]] # 이걸로 바운딩박스 갯수 조절가능\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [5.5, 6.2, 6.8]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios: \n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis = -1), [1, 1, 2]\n",
    "                )\n",
    "                for scale in self.scales: \n",
    "                    anchor_dims.append(scale * dims) \n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis = -2))\n",
    "        return anchor_dims_all \n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor 음수 값: False\n",
      "tf.Tensor(\n",
      "[[ 0.5        0.5        4.2602816  7.1004696]\n",
      " [ 0.5        0.5        5.3676186  8.946032 ]\n",
      " [ 0.5        0.5        6.7627754 11.271293 ]\n",
      " ...\n",
      " [30.        22.         8.601397   5.3758717]\n",
      " [30.        22.        10.837081   6.773174 ]\n",
      " [30.        22.        13.653866   8.533664 ]], shape=(9072, 4), dtype=float32)\n",
      "(9072, 4)\n",
      "(24, 32, 1)\n",
      "[[17.5       20.5        7.267791   6.6070814]\n",
      " [20.5       20.5       11.043567   6.902229 ]\n",
      " [18.        18.        10.837081   6.773174 ]\n",
      " [20.5       20.5        4.2602816  7.1004696]\n",
      " [ 0.5       20.5        6.7627754 11.271293 ]\n",
      " [ 9.        15.         8.192781   7.4479833]\n",
      " [29.5       12.5       11.043567   6.902229 ]\n",
      " [30.5       22.5       11.043567   6.902229 ]\n",
      " [ 5.        21.         7.8424487  4.9015303]\n",
      " [15.5       17.5        4.2602816  7.1004696]\n",
      " [ 5.5        5.5        4.2602816  7.1004696]\n",
      " [ 5.5       20.5        7.267791   6.6070814]\n",
      " [10.5        1.5        6.7627754 11.271293 ]\n",
      " [19.5        7.5        6.7627754 11.271293 ]\n",
      " [24.5       18.5        7.267791   6.6070814]\n",
      " [ 1.5       21.5        6.7627754 11.271293 ]\n",
      " [17.5        4.5        5.3676186  8.946032 ]\n",
      " [ 5.         3.        12.449111   7.780694 ]\n",
      " [ 6.5        9.5        9.156842   8.324401 ]\n",
      " [ 6.5        7.5        8.7652855  5.4783025]\n",
      " [16.5       22.5        6.957011   4.3481317]\n",
      " [31.5        7.5        7.267791   6.6070814]\n",
      " [ 7.         9.         8.192781   7.4479833]\n",
      " [12.5       11.5        5.3676186  8.946032 ]\n",
      " [ 3.5       21.5        6.957011   4.3481317]\n",
      " [ 7.5        2.5        9.156842   8.324401 ]\n",
      " [ 1.5        8.5        8.7652855  5.4783025]\n",
      " [17.5        3.5        9.156842   8.324401 ]\n",
      " [31.5       21.5        5.7684493  5.244044 ]\n",
      " [29.5       20.5        8.7652855  5.4783025]\n",
      " [29.         5.         7.6234922 12.705821 ]\n",
      " [25.         1.         6.5026145  5.911468 ]\n",
      " [26.5       19.5        9.156842   8.324401 ]\n",
      " [ 6.5       17.5        9.156842   8.324401 ]\n",
      " [23.5       20.5        8.7652855  5.4783025]\n",
      " [25.5       10.5        5.3676186  8.946032 ]\n",
      " [ 0.5       17.5        4.2602816  7.1004696]\n",
      " [15.5       10.5        7.267791   6.6070814]\n",
      " [30.5        7.5        5.7684493  5.244044 ]\n",
      " [15.5       13.5        7.267791   6.6070814]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0]\n",
    "ymin = anchor[:, 1]\n",
    "xmax = anchor[:, 2]\n",
    "ymax = anchor[:, 3]\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "print(anchor)\n",
    "print(anchor.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    print(img.shape)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    print(sample_data)\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x, top_left_y), width, height, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    print(boxes1_corners.shape)\n",
    "    print(boxes2_corners.shape)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA.shape: (2, 4)\n",
      "GT.shape: (2, 4)\n",
      "GA (XYWH): tf.Tensor(\n",
      "[[60. 45. 20. 30.]\n",
      " [60. 45. 20. 30.]], shape=(2, 4), dtype=float64)\n",
      "GT (XYWH): tf.Tensor(\n",
      "[[60. 45. 20. 30.]\n",
      " [45. 60. 20. 30.]], shape=(2, 4), dtype=float64)\n",
      "(2, 4)\n",
      "(2, 4)\n",
      "IoU: tf.Tensor(\n",
      "[[1.         0.06666667]\n",
      " [1.         0.06666667]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "GA = np.array([[50, 30, 70, 60], [50, 30, 70, 60]])  # 예: [xmin, ymin, xmax, ymax]\n",
    "GT = np.array([[50, 30, 70, 60], [35, 45, 55, 75]])  # 예: [xmin, ymin, xmax, ymax]\n",
    "\n",
    "print(\"GA.shape:\", GA.shape)\n",
    "print(\"GT.shape:\", GT.shape)\n",
    "\n",
    "GA_xywh = convert_to_xywh(GA)\n",
    "print(\"GA (XYWH):\", GA_xywh)\n",
    "\n",
    "GT_xywh = convert_to_xywh(GT)\n",
    "print(\"GT (XYWH):\", GT_xywh)\n",
    "\n",
    "iou = compute_iou(GA_xywh, GT_xywh)\n",
    "print(\"IoU:\", iou)\n",
    "# GA = convert_to_corners(GA)\n",
    "# print(GA)\n",
    "# GT = convert_to_corners(GT)\n",
    "# print(GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 주어진 바운딩 박스 데이터\n",
    "box1 = [50, 30, 70, 60]  # [x_min, y_min, x_max, y_max]\n",
    "box2 = [35, 45, 55, 75]\n",
    "\n",
    "# 그림 생성\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 첫 번째 바운딩 박스 추가\n",
    "rect1 = patches.Rectangle((box1[0], box1[1]), box1[2] - box1[0], box1[3] - box1[1], \n",
    "                          linewidth=2, edgecolor='blue', facecolor='none')\n",
    "ax.add_patch(rect1)\n",
    "\n",
    "# 두 번째 바운딩 박스 추가\n",
    "rect2 = patches.Rectangle((box2[0], box2[1]), box2[2] - box2[0], box2[3] - box2[1], \n",
    "                          linewidth=2, edgecolor='red', facecolor='none')\n",
    "ax.add_patch(rect2)\n",
    "\n",
    "# 축 범위 설정\n",
    "ax.set_xlim(0, 90)\n",
    "ax.set_ylim(0, 90)\n",
    "\n",
    "# 그림 표시\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_anchor_boxes(anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        print(\"iou_matrix:  \", iou_matrix)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        print(\"max_iou:  \", max_iou)\n",
    "\n",
    "\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "    \n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        print(\"negative_mask:  \", negative_mask)\n",
    "\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        print(\"ignore_mask:  \", ignore_mask)\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype = tf.float32),\n",
    "            tf.cast(ignore_mask, dtype = tf.float32),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(4, 4)\n",
      "iou_matrix:   tf.Tensor(\n",
      "[[1.         0.03100775 0.         0.        ]\n",
      " [0.03100775 1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.06003535 0.        ]\n",
      " [0.         0.         0.09293901 0.        ]\n",
      " [0.         0.         0.11408175 0.        ]\n",
      " [0.16311106 0.         0.         0.        ]], shape=(8, 4), dtype=float32)\n",
      "max_iou:   tf.Tensor(\n",
      "[1.         1.         1.         0.         0.06003535 0.09293901\n",
      " 0.11408175 0.16311106], shape=(8,), dtype=float32)\n",
      "matched_gt_idx:   tf.Tensor([0 1 2 0 2 2 2 0], shape=(8,), dtype=int64)\n",
      "positive_mask:   tf.Tensor([ True  True  True False False False False False], shape=(8,), dtype=bool)\n",
      "negative_mask:   tf.Tensor([False False False  True  True  True  True  True], shape=(8,), dtype=bool)\n",
      "ignore_mask:   tf.Tensor([False False False False False False False False], shape=(8,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "anchor = np.array([\n",
    "                    [27.,  18.5,  8.,   7.],\n",
    "                    [18.5, 15.5, 11.,   7.],\n",
    "                    [ 6.,   4.,   8.,   6.],\n",
    "                    [ 0.,   0.,   0.,   0.],\n",
    "                    [ 1., 1., 4.242641, 8.485281 ],\n",
    "                    [ 1.,         1.,         5.3453927, 10.690784 ],\n",
    "                    [ 1.,         1.,         6.7347727, 13.469543 ],\n",
    "                    [30.,        22.,         9.899496,   4.949747 ]])\n",
    "\n",
    "gt_boxes = np.array([[27.,  18.5,  8.,   7., ],\n",
    "                     [18.5, 15.5, 11.,   7. ],\n",
    "                     [ 6.,   4.,   8.,   6. ],\n",
    "                     [ 0.,   0.,   0.,   0. ]])\n",
    "# print(gt_boxes.shape)\n",
    "a, b, c = match_anchor_boxes(tf.cast(anchor, tf.float32), tf.cast(gt_boxes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        print(\"iou_matrix:  \", iou_matrix.shape)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        print(\"max_iou:  \", max_iou.shape)\n",
    "\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "        print(\"max_iou:\", max_iou)\n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        print(\"negative_mask:  \", negative_mask.shape)\n",
    "\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        print(\"ignore_mask:  \", ignore_mask.shape)\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype = tf.float32),\n",
    "            tf.cast(ignore_mask, dtype = tf.float32),\n",
    "        )\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        print(\"_compute_box_target anchor_boxes: \", anchor_boxes)\n",
    "        print(\"_compute_box_target matched_gt_boxes : \", matched_gt_boxes)\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis = -1,\n",
    "        )\n",
    "        print(\"box_target:  \", box_target)\n",
    "        box_target = box_target / self._box_variance\n",
    "        print(\"box_target:  \", box_target)\n",
    "        return box_target\n",
    "    \n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):\n",
    "        print(\"image_shape:\", image_shape.shape)\n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # 앵커 박스 정규화\n",
    "        xmin = anchor_boxes[:, 0]\n",
    "        ymin = anchor_boxes[:, 1]\n",
    "        xmax = anchor_boxes[:, 2]\n",
    "        ymax = anchor_boxes[:, 3]\n",
    "        # 정규화된 좌표를 스택으로 결합\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        print(\"anchor_boxes : \", normalized_anchor)\n",
    "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "        print(\"cls_ids\", cls_ids)\n",
    "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "            normalized_anchor, gt_boxes)\n",
    "        print(\"matched_gt_idx: \", matched_gt_idx)\n",
    "        print(\"positive_mask: \", positive_mask)\n",
    "        print(\"ignore_mask: \", ignore_mask)\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        print(\"matched_gt_boxes: \", matched_gt_boxes)\n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        print(\"box_target: \", box_target)\n",
    "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "        print(\"matched_gt_cls_ids: \", matched_gt_cls_ids)\n",
    "        cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "        cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "        print(\"cls_target: \", cls_target)\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        print(\"cls_target: \", cls_target)\n",
    "        num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "        print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "        return box_target, cls_target\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        print(\"images_shape: \", images_shape)\n",
    "        batch_size = images_shape[0]\n",
    "        print(\"batch_size: \", batch_size)\n",
    "        print(\"gt_boxes: \", gt_boxes)\n",
    "        box_targets = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        cls_targets = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        print(\"box_targets: \", box_targets)\n",
    "        print(\"cls_targets: \", cls_targets)\n",
    "        # batch_size_val = batch_size.numpy()\n",
    "        for i in range(batch_size):\n",
    "            box_target, cls_target = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            print(\"box_target: \", box_target)\n",
    "            print(\"cls_target: \", cls_target)\n",
    "            box_targets = box_targets.write(i, box_target)\n",
    "            cls_targets = cls_targets.write(i, cls_target)\n",
    "        return batch_images, box_targets.stack(), cls_targets.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution: \", tf.executing_eagerly())\n",
    "if not tf.executing_eagerly():\n",
    "    tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1) (1, 4, 4) (1, 4)\n",
      "images_shape:  tf.Tensor([ 1 24 32  1], shape=(4,), dtype=int32)\n",
      "batch_size:  tf.Tensor(1, shape=(), dtype=int32)\n",
      "gt_boxes:  tf.Tensor(\n",
      "[[[20.  14.5  8.   9. ]\n",
      "  [22.5 22.   7.   4. ]\n",
      "  [ 0.   0.   0.   0. ]\n",
      "  [ 0.   0.   0.   0. ]]], shape=(1, 4, 4), dtype=float32)\n",
      "box_targets:  <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe2fc7f1a90>\n",
      "cls_targets:  <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe2fc7cce20>\n",
      "image_shape: (4,)\n",
      "anchor_boxes :  tf.Tensor(\n",
      "[[ 0.5        0.5        4.2602816  7.1004696]\n",
      " [ 0.5        0.5        5.3676186  8.946032 ]\n",
      " [ 0.5        0.5        6.7627754 11.271293 ]\n",
      " ...\n",
      " [30.        22.         8.601397   5.3758717]\n",
      " [30.        22.        10.837081   6.773174 ]\n",
      " [30.        22.        13.653866   8.533664 ]], shape=(9072, 4), dtype=float32)\n",
      "cls_ids tf.Tensor([1. 1. 0. 0.], shape=(4,), dtype=float32)\n",
      "(9072, 4)\n",
      "(4, 4)\n",
      "iou_matrix:   (9072, 4)\n",
      "max_iou:   (9072,)\n",
      "matched_gt_idx:   tf.Tensor([0 0 0 ... 1 1 1], shape=(9072,), dtype=int64)\n",
      "max_iou: tf.Tensor([0.         0.         0.         ... 0.01646818 0.05927426 0.08488663], shape=(9072,), dtype=float32)\n",
      "positive_mask:   tf.Tensor([False False False ... False False False], shape=(9072,), dtype=bool)\n",
      "negative_mask:   (9072,)\n",
      "ignore_mask:   (9072,)\n",
      "matched_gt_idx:  tf.Tensor([0 0 0 ... 1 1 1], shape=(9072,), dtype=int64)\n",
      "positive_mask:  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(9072,), dtype=float32)\n",
      "ignore_mask:  tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(9072,), dtype=float32)\n",
      "matched_gt_boxes:  tf.Tensor(\n",
      "[[20.  14.5  8.   9. ]\n",
      " [20.  14.5  8.   9. ]\n",
      " [20.  14.5  8.   9. ]\n",
      " ...\n",
      " [22.5 22.   7.   4. ]\n",
      " [22.5 22.   7.   4. ]\n",
      " [22.5 22.   7.   4. ]], shape=(9072, 4), dtype=float32)\n",
      "_compute_box_target anchor_boxes:  tf.Tensor(\n",
      "[[ 0.5        0.5        4.2602816  7.1004696]\n",
      " [ 0.5        0.5        5.3676186  8.946032 ]\n",
      " [ 0.5        0.5        6.7627754 11.271293 ]\n",
      " ...\n",
      " [30.        22.         8.601397   5.3758717]\n",
      " [30.        22.        10.837081   6.773174 ]\n",
      " [30.        22.        13.653866   8.533664 ]], shape=(9072, 4), dtype=float32)\n",
      "_compute_box_target matched_gt_boxes :  tf.Tensor(\n",
      "[[20.  14.5  8.   9. ]\n",
      " [20.  14.5  8.   9. ]\n",
      " [20.  14.5  8.   9. ]\n",
      " ...\n",
      " [22.5 22.   7.   4. ]\n",
      " [22.5 22.   7.   4. ]\n",
      " [22.5 22.   7.   4. ]], shape=(9072, 4), dtype=float32)\n",
      "box_target:   tf.Tensor(\n",
      "[[ 4.5771623   1.9717005   0.6301063   0.2370637 ]\n",
      " [ 3.632896    1.5649397   0.39905724  0.00601458]\n",
      " [ 2.8834314   1.2420936   0.16800821 -0.22503442]\n",
      " ...\n",
      " [-0.8719514   0.         -0.20601445 -0.29562634]\n",
      " [-0.6920683   0.         -0.43706352 -0.52667546]\n",
      " [-0.549295    0.         -0.6681125  -0.7577244 ]], shape=(9072, 4), dtype=float32)\n",
      "box_target:   tf.Tensor(\n",
      "[[ 4.5771622e+01  1.9717005e+01  3.1505313e+00  1.1853185e+00]\n",
      " [ 3.6328960e+01  1.5649397e+01  1.9952862e+00  3.0072907e-02]\n",
      " [ 2.8834314e+01  1.2420936e+01  8.4004104e-01 -1.1251720e+00]\n",
      " ...\n",
      " [-8.7195139e+00  0.0000000e+00 -1.0300722e+00 -1.4781317e+00]\n",
      " [-6.9206829e+00  0.0000000e+00 -2.1853175e+00 -2.6333773e+00]\n",
      " [-5.4929500e+00  0.0000000e+00 -3.3405626e+00 -3.7886219e+00]], shape=(9072, 4), dtype=float32)\n",
      "box_target:  tf.Tensor(\n",
      "[[ 4.5771622e+01  1.9717005e+01  3.1505313e+00  1.1853185e+00]\n",
      " [ 3.6328960e+01  1.5649397e+01  1.9952862e+00  3.0072907e-02]\n",
      " [ 2.8834314e+01  1.2420936e+01  8.4004104e-01 -1.1251720e+00]\n",
      " ...\n",
      " [-8.7195139e+00  0.0000000e+00 -1.0300722e+00 -1.4781317e+00]\n",
      " [-6.9206829e+00  0.0000000e+00 -2.1853175e+00 -2.6333773e+00]\n",
      " [-5.4929500e+00  0.0000000e+00 -3.3405626e+00 -3.7886219e+00]], shape=(9072, 4), dtype=float32)\n",
      "matched_gt_cls_ids:  tf.Tensor([1. 1. 1. ... 1. 1. 1.], shape=(9072,), dtype=float32)\n",
      "cls_target:  tf.Tensor([-1. -1. -1. ... -1. -1. -1.], shape=(9072,), dtype=float32)\n",
      "cls_target:  tf.Tensor(\n",
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]], shape=(9072, 1), dtype=float32)\n",
      "Number of 1.0 values in cls_target: tf.Tensor(150, shape=(), dtype=int64)\n",
      "box_target:  tf.Tensor(\n",
      "[[ 4.5771622e+01  1.9717005e+01  3.1505313e+00  1.1853185e+00]\n",
      " [ 3.6328960e+01  1.5649397e+01  1.9952862e+00  3.0072907e-02]\n",
      " [ 2.8834314e+01  1.2420936e+01  8.4004104e-01 -1.1251720e+00]\n",
      " ...\n",
      " [-8.7195139e+00  0.0000000e+00 -1.0300722e+00 -1.4781317e+00]\n",
      " [-6.9206829e+00  0.0000000e+00 -2.1853175e+00 -2.6333773e+00]\n",
      " [-5.4929500e+00  0.0000000e+00 -3.3405626e+00 -3.7886219e+00]], shape=(9072, 4), dtype=float32)\n",
      "cls_target:  tf.Tensor(\n",
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]], shape=(9072, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    img, box, label = preprocess_data(image, bbox, label)\n",
    "    print(img.shape, box.shape, label.shape)\n",
    "\n",
    "    label_encoder.encode_batch(img, box, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in train_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_shape:  Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "batch_size:  Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "gt_boxes:  Tensor(\"args_1:0\", shape=(1, None, 4), dtype=float32)\n",
      "box_targets:  <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe32c12dcd0>\n",
      "cls_targets:  <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fe32c12d970>\n",
      "image_shape: (4,)\n",
      "anchor_boxes :  Tensor(\"while/stack_3:0\", shape=(None, 4), dtype=float32)\n",
      "cls_ids Tensor(\"while/Cast:0\", dtype=float32)\n",
      "(None, 4)\n",
      "(None, 4)\n",
      "iou_matrix:   (None, None)\n",
      "max_iou:   (None,)\n",
      "matched_gt_idx:   Tensor(\"while/ArgMax:0\", shape=(None,), dtype=int64)\n",
      "max_iou: Tensor(\"while/Max:0\", shape=(None,), dtype=float32)\n",
      "positive_mask:   Tensor(\"while/GreaterEqual:0\", shape=(None,), dtype=bool)\n",
      "negative_mask:   (None,)\n",
      "ignore_mask:   (None,)\n",
      "matched_gt_idx:  Tensor(\"while/ArgMax:0\", shape=(None,), dtype=int64)\n",
      "positive_mask:  Tensor(\"while/Cast_1:0\", shape=(None,), dtype=float32)\n",
      "ignore_mask:  Tensor(\"while/Cast_2:0\", shape=(None,), dtype=float32)\n",
      "matched_gt_boxes:  Tensor(\"while/GatherV2:0\", shape=(None, 4), dtype=float32)\n",
      "_compute_box_target anchor_boxes:  Tensor(\"while/stack_3:0\", shape=(None, 4), dtype=float32)\n",
      "_compute_box_target matched_gt_boxes :  Tensor(\"while/GatherV2:0\", shape=(None, 4), dtype=float32)\n",
      "box_target:   Tensor(\"while/concat_6:0\", shape=(None, 4), dtype=float32)\n",
      "box_target:   Tensor(\"while/truediv_13:0\", shape=(None, 4), dtype=float32)\n",
      "box_target:  Tensor(\"while/truediv_13:0\", shape=(None, 4), dtype=float32)\n",
      "matched_gt_cls_ids:  Tensor(\"while/GatherV2_1:0\", dtype=float32)\n",
      "cls_target:  Tensor(\"while/SelectV2_1:0\", dtype=float32)\n",
      "cls_target:  Tensor(\"while/ExpandDims_3:0\", dtype=float32)\n",
      "Number of 1.0 values in cls_target: Tensor(\"while/count_nonzero/Sum:0\", shape=(), dtype=int64)\n",
      "box_target:  Tensor(\"while/truediv_13:0\", shape=(None, 4), dtype=float32)\n",
      "cls_target:  Tensor(\"while/ExpandDims_3:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0 1.0\n",
      "(1, 9072, 4)\n",
      "(1, 9072, 1)\n",
      "Positive 개수: 170\n",
      "Negative 개수: 8642\n",
      "Ignore 개수: 260\n",
      "241.0 0.0\n",
      "(1, 9072, 4)\n",
      "(1, 9072, 1)\n",
      "Positive 개수: 186\n",
      "Negative 개수: 8628\n",
      "Ignore 개수: 258\n",
      "249.0 8.0\n",
      "(1, 9072, 4)\n",
      "(1, 9072, 1)\n",
      "Positive 개수: 241\n",
      "Negative 개수: 8473\n",
      "Ignore 개수: 358\n"
     ]
    }
   ],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, target, label = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(target.shape)\n",
    "    print(label.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(label[0, :, 0], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(label[0, :, 0], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(label[0, :, 0], -2.0), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 255\n",
      "Negative 개수: 8375\n",
      "Ignore 개수: 442\n",
      "Positive 255\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 166\n",
      "Negative 개수: 8636\n",
      "Ignore 개수: 270\n",
      "Positive 166\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 123\n",
      "Negative 개수: 8748\n",
      "Ignore 개수: 201\n",
      "Positive 123\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_predictions(box_targets, cls_targets, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    for i in range(len(box_targets)):\n",
    "        label = box_targets[i]\n",
    "        cls_label = cls_targets[i]\n",
    "        if cls_label[0] == 1.0:\n",
    "            dx, dy, dw, dh = label[:4]\n",
    "            anchor = anchors[i]\n",
    "            anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "            cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "            cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "            width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "            height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "            x_min = cx - width / 2\n",
    "            y_min = cy - height / 2\n",
    "            decoded_box = [x_min, y_min, width, height]\n",
    "            decoded_boxes.append(decoded_box)\n",
    "    print(\"Positive\", len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes\n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i += 1\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(3):\n",
    "    image = batch[0][0].numpy()\n",
    "    box_targets = batch[1][0].numpy()\n",
    "    cls_targets = batch[2][0].numpy()\n",
    "\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(cls_targets[:, 0], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(cls_targets[:, 0], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(cls_targets[:, 0], -2.0), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(box_targets, cls_targets, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = layers.DepthwiseConv2D(kernel_size=kernel_size, padding='same' if padding else 'valid', depth_multiplier=1, strides=stride, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.pointwise = layers.Conv2D(out_channels, kernel_size=1, strides=1, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class DepthwiseConv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv, self).__init__()\n",
    "        self.depthwise = DepthwiseSeparableConv(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.silu = layers.Activation('silu')\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.silu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.silu = layers.Activation('silu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.silu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, in_out_channels, mid_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = Conv(in_out_channels, mid_channels, kernel_size=1, stride=stride, padding=0)\n",
    "        self.conv_1 = Conv(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv_3 = Conv(mid_channels, in_out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.conv_1(out)\n",
    "        out = self.conv_3(out)\n",
    "        out += identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDenseLayer(layers.Layer):\n",
    "    def __init__(self, in_out_channels, bottleneck_mid_channels, out_channels):\n",
    "        super(CSPDenseLayer, self).__init__()\n",
    "        self.conv_0 = Conv(in_out_channels // 2, in_out_channels, kernel_size=3, stride=1)\n",
    "        self.conv_1 = Conv(in_out_channels // 2, in_out_channels, kernel_size=3, stride=1)\n",
    "        self.bottleneck = Bottleneck(in_out_channels, bottleneck_mid_channels)\n",
    "        self.conv_3 = Conv(in_out_channels * 2, out_channels, kernel_size=3, stride=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        x1 = self.conv_0(x1)\n",
    "        x2 = self.conv_1(x2)\n",
    "        out = self.bottleneck(x1)\n",
    "        out = tf.concat([out, x2], axis=-1)\n",
    "        out = self.conv_3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction_ratio, pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "class SPPFast(layers.Layer):\n",
    "    def __init__(self, filters: int, pool_kernel_sizes: List[int] = [1, 2, 4], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pool_kernel_sizes = pool_kernel_sizes\n",
    "        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "        self.conv = layers.Conv2D(filters, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        height, width = tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "\n",
    "        # 글로벌 평균 풀링과 업샘플링\n",
    "        global_features = self.global_pool(inputs)\n",
    "        global_features = tf.expand_dims(tf.expand_dims(global_features, 1), 1)\n",
    "        global_features = tf.image.resize(global_features, [height, width])\n",
    "\n",
    "        # 다양한 크기의 MaxPooling\n",
    "        pooled_outputs = [\n",
    "            layers.MaxPooling2D(pool_size=kernel_size, strides=1, padding='SAME')(inputs)\n",
    "            for kernel_size in self.pool_kernel_sizes\n",
    "        ]\n",
    "\n",
    "        # 업샘플링 및 컨캐터네이션\n",
    "        pooled_outputs = [\n",
    "            tf.image.resize(pooled, [height, width])\n",
    "            for pooled in pooled_outputs\n",
    "        ]\n",
    "        pooled_outputs.append(global_features)\n",
    "        pooled_outputs.append(inputs)\n",
    "        spp_output = tf.concat(pooled_outputs, axis=-1)\n",
    "\n",
    "        # 컨볼루션 적용\n",
    "        spp_output = self.conv(spp_output)\n",
    "\n",
    "        return spp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.upsample(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# class BackBone(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(BackBone, self).__init__()\n",
    "#         self.upsample = Upsample(size=(4, 4), interpolation='bilinear')\n",
    "\n",
    "#         self.conv1 = Conv(in_channels=1, out_channels=4, kernel_size=6, stride=2, padding=2)\n",
    "        \n",
    "#         self.conv2 = Conv(in_channels=4, out_channels=8, kernel_size=3, stride=2)\n",
    "#         self.csp1 = CSPDenseLayer(8, 4, 8)\n",
    "#         self.cbam1 = CBAM(16)\n",
    "        \n",
    "#         self.conv3 = Conv(in_channels=8, out_channels=16, kernel_size=3, stride=2)\n",
    "#         self.csp2 = CSPDenseLayer(16, 8, 16)\n",
    "#         self.cbam2 = CBAM(32)\n",
    "        \n",
    "#         self.conv4 = Conv(in_channels=16, out_channels=32, kernel_size=3, stride=2)\n",
    "#         self.csp3 = CSPDenseLayer(32, 16, 32)\n",
    "#         self.cbam3 = CBAM(32)\n",
    "#         self.sppf = SPPF(out_channels=32, kernel_size=3, stride=1)\n",
    "#         self.conv5 = Conv(in_channels = 32, out_channels = 32, kernel_size=3, stride=1)\n",
    "\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         x = self.upsample(inputs)\n",
    "#         x = self.conv1(x)   \n",
    "#         x = self.conv2(x)   # 24, 32\n",
    "#         p3 = self.csp1(x)   # 24, 32\n",
    "#         p3 = self.cbam1(p3) # 24, 32\n",
    "\n",
    "#         x = self.conv3(p3) # 6, 8\n",
    "#         p4 = self.csp2(x)  # 12, 16\n",
    "#         p4 = self.cbam2(p4)\n",
    "\n",
    "#         x = self.conv4(p4) \n",
    "#         p5 = self.csp3(x)  \n",
    "#         p5 = self.cbam3(p5)\n",
    "#         p5 = self.sppf(p5)\n",
    "#         p5 = self.conv5(p5) # 6, 8\n",
    "        \n",
    "#         return p3, p4, p5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeckLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(NeckLayer, self).__init__()\n",
    "#         self.conv_c10 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "#         self.upsample1 = layers.Conv2DTranspose(filters = 32, kernel_size = 1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "#         self.csp = CSPDenseLayer(32, 16, 32)\n",
    "#         self.conv_c14 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "#         self.upsample2 = layers.Conv2DTranspose(filters = 32, kernel_size = 1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "#     def call(self, p3, p4, p5):\n",
    "#         c10 = self.conv_c10(p5) # 15, 20 \n",
    "#         x = self.upsample1(c10) # 30, 40\n",
    "#         x = layers.concatenate([x, p4])\n",
    "#         x = self.csp(x) \n",
    "#         c14 = self.conv_c14(x) \n",
    "#         x = self.upsample2(c14) # 60, 80\n",
    "#         x = layers.concatenate([x, p3])\n",
    "#         return x, c14, c10\n",
    "    \n",
    "# # • x=tf.Tensor(shape=(None, 48, 64, 16), dtype=float32)\n",
    "# # • c14=tf.Tensor(shape=(None, 24, 32, 25), dtype=float32)\n",
    "# # • c10=tf.Tensor(shape=(None, 12, 16, 128), dtype=float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HeadLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(HeadLayer, self).__init__()\n",
    "#         self.csp_dense1 = CSPDenseLayer(64, 32, 64)\n",
    "#         self.conv1 = layers.Conv2D(64, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "#         self.cbam1 = CBAM(64)\n",
    "#         self.csp_dense2 = CSPDenseLayer(64, 32, 64)\n",
    "#         self.conv2 = layers.Conv2D(64, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "#         self.cbam2 = CBAM(64)\n",
    "#         self.csp_dense3 = CSPDenseLayer(64, 32, 64)\n",
    "\n",
    "#         # self.channel_adjust1 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False) \n",
    "#         # self.channel_adjust2 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False) \n",
    "#         # self.channel_adjust3 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False) \n",
    "        \n",
    "#     def call(self, x, c14, c10):\n",
    "#         x = self.cbam1(x)\n",
    "#         out1 = self.csp_dense1(x)\n",
    "#         # out1_adj = self.channel_adjust1(out1)\n",
    "#         x = self.conv1(out1)\n",
    "#         x = layers.concatenate([x, c14])\n",
    "#         x = self.cbam2(x)\n",
    "#         out2 = self.csp_dense2(x)\n",
    "#         # out2_adj = self.channel_adjust2(out2)\n",
    "#         x = self.conv2(out2)\n",
    "#         x = layers.concatenate([x, c10])\n",
    "#         out3 = self.csp_dense3(x)\n",
    "#         # out3_adj = self.channel_adjust3(out3)\n",
    "#         return out1, out2, out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomModel(tf.keras.Model):\n",
    "#     def __init__(self, num_classes=1, num_anchors_per_location=9):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.backbone = BackBone()\n",
    "#         self.neck = NeckLayer()\n",
    "#         self.head = HeadLayer()\n",
    "#         self.backbone.trainable = True\n",
    "#         self.neck.trainable = True\n",
    "#         self.head.trainable = True\n",
    "\n",
    "#         self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#         # 각 위치(픽셀)에서 예측해야 하는 앵커 박스의 수\n",
    "#         self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "#         self.classification_conv1 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         self.classification_conv2 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "     \n",
    "#         self.regression_conv1 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         self.regression_conv2 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "    \n",
    "    \n",
    "#         # 분류 헤드\n",
    "#         self.classification_head = tf.keras.Sequential([\n",
    "#             self.classification_conv1,\n",
    "#             self.classification_conv2,\n",
    "#             layers.Conv2D(self.num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         ])\n",
    "\n",
    "#         # 회귀 헤드\n",
    "#         self.regression_head = tf.keras.Sequential([\n",
    "#             self.regression_conv1,\n",
    "#             self.regression_conv2,\n",
    "#             layers.Conv2D(self.num_anchors_per_location * 4, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         ])\n",
    "\n",
    "#         self.classification_head.trainable = True\n",
    "#         self.regression_head.trainable = True\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         p3, p4, p5 = self.backbone(inputs)\n",
    "#         x, c14, c10 = self.neck(p3, p4, p5)\n",
    "#         out1, out2, out3 = self.head(x, c14, c10)\n",
    "\n",
    "#         cls_outputs = []\n",
    "#         reg_outputs = []\n",
    "#         N = tf.shape(inputs)[0]\n",
    "#         for feature in [out1, out2, out3]:\n",
    "#             # print(feature.shape)\n",
    "#             # 첫 번째 feature 맵 (None, 12, 16, 32)의 경우: 12x16 위치 각각에 9개의 앵커 박스 = 12x16x9 = 1728\n",
    "#             # 두 번째 feature 맵 (None, 6, 8, 32)의 경우: 6x8 위치 각각에 9개의 앵커 박스 = 6x8x9 = 432\n",
    "#             # 세 번째 feature 맵 (None, 3, 4, 32)의 경우: 3x4 위치 각각에 9개의 앵커 박스 = 3x4x9 = 108\n",
    "#             cls_output = self.classification_head(feature)\n",
    "#             reg_output = self.regression_head(feature)\n",
    "#             reg_output = tf.reshape(reg_output, [N, -1, 4])\n",
    "            \n",
    "#             cls_output = tf.reshape(cls_output, [N, -1, self.num_classes])\n",
    "#             cls_outputs.append(cls_output)\n",
    "#             reg_outputs.append(reg_output)\n",
    "\n",
    "#         # 결과 결합\n",
    "#         reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "#         cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "#         # 최종 출력\n",
    "#         final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "#         # print(final_output.shape)\n",
    "#         return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.cbam1 = CBAM(8)\n",
    "        self.csp1 = CSPDenseLayer(8, 4, 8)\n",
    "        \n",
    "        self.conv2 = Conv(in_channels=8, out_channels=16, kernel_size=3, stride=2)\n",
    "        self.cbam2 = CBAM(16)\n",
    "        self.csp2 = CSPDenseLayer(16, 8, 16)\n",
    "        self.sppf = SPPFast(32)\n",
    "\n",
    "        self.conv3 = Conv(in_channels=32, out_channels=32, kernel_size=3, stride=2)\n",
    "        self.cbam3 = CBAM(32)\n",
    "        self.csp3 = CSPDenseLayer(32, 16, 32)\n",
    "        \n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        p1 = self.csp1(x)  # 24, 32\n",
    "        p1 = self.cbam1(p1)\n",
    "        \n",
    "        x = self.conv2(p1)  # 12, 16\n",
    "        p2 = self.csp2(x)\n",
    "        p2 = self.cbam2(p2)\n",
    "        p2 = self.sppf(p2)\n",
    "        \n",
    "        x = self.conv3(p2)  # 6, 8\n",
    "        p3 = self.csp3(x)\n",
    "        p3 = self.cbam3(p3)\n",
    "        # p3 = self.sppf(p3)\n",
    "        return p1, p2, p3\n",
    "\n",
    "class NeckLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(NeckLayer, self).__init__()\n",
    "        self.conv_c3 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.upsample1 = layers.Conv2DTranspose(filters=32, kernel_size=1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csp = CSPDenseLayer(32, 16, 32)\n",
    "        self.conv_c2 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.upsample2 = layers.Conv2DTranspose(filters=16, kernel_size=1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, p1, p2, p3):\n",
    "        c3 = self.conv_c3(p3)  #6, 8\n",
    "        x = self.upsample1(c3) #12, 16\n",
    "        x = layers.concatenate([x, p2])\n",
    "        x = self.csp(x)\n",
    "        c2 = self.conv_c2(x)\n",
    "        x = self.upsample2(c2) # 24, 32\n",
    "        x = layers.concatenate([x, p1])\n",
    "        return x, c2, c3\n",
    "\n",
    "class HeadLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(HeadLayer, self).__init__()\n",
    "        self.csp_dense1 = CSPDenseLayer(16, 8, 32)\n",
    "        self.conv1 = layers.Conv2D(16, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.cbam1 = CBAM(32)\n",
    "        self.csp_dense2 = CSPDenseLayer(32, 16, 32)\n",
    "        self.conv2 = layers.Conv2D(32, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.cbam2 = CBAM(64)\n",
    "        self.csp_dense3 = CSPDenseLayer(64, 32, 32)\n",
    "\n",
    "    def call(self, x, c2, c3):\n",
    "        out1 = self.csp_dense1(x) # 24, 32\n",
    "        x = self.conv1(out1)  \n",
    "        x = layers.concatenate([x, c2]) \n",
    "        x = self.cbam1(x)\n",
    "        out2 = self.csp_dense2(x)\n",
    "        x = self.conv2(out2)\n",
    "        x = layers.concatenate([x, c3])\n",
    "        x = self.cbam2(x)\n",
    "        out3 = self.csp_dense3(x)\n",
    "        return out1, out2, out3\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=1, num_anchors_per_location=9):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.backbone = BackBone()\n",
    "        self.neck = NeckLayer()\n",
    "        self.head = HeadLayer()\n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "            # layers.BatchNormalization(),\n",
    "            # layers.Activation('selu'),\n",
    "            # layers.Dropout(0.3),\n",
    "            layers.Conv2D(64, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "            layers.Conv2D(self.num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "            # layers.BatchNormalization(),\n",
    "            # layers.Dropout(0.3),\n",
    "        ])\n",
    "\n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "            layers.Conv2D(64, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "            # layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "            layers.Conv2D(self.num_anchors_per_location * 4, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=self.prior_probability),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1, p2, p3 = self.backbone(inputs)\n",
    "        x, c2, c3 = self.neck(p1, p2, p3)\n",
    "        out1, out2, out3 = self.head(x, c2, c3)\n",
    "        \n",
    "        N = tf.shape(inputs)[0]\n",
    "        reg_outputs = []\n",
    "        cls_outputs = []\n",
    "        for _, feature in enumerate([out1, out2, out3]):\n",
    "            reg_output = self.regression_head(feature)\n",
    "            cls_output = self.classification_head(feature)\n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "            reg_outputs.append(reg_output)\n",
    "            cls_outputs.append(cls_output)\n",
    "        \n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        # print(\"Model output shape:\", cls_outputs.shape)\n",
    "        return {'regression': reg_outputs, 'classification': cls_outputs}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " back_bone (BackBone)        multiple                  56398     \n",
      "                                                                 \n",
      " neck_layer (NeckLayer)      multiple                  48848     \n",
      "                                                                 \n",
      " head_layer (HeadLayer)      multiple                  171284    \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, None, 9)     8361      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, None, 36)    5508      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290399 (1.11 MB)\n",
      "Trainable params: 288063 (1.10 MB)\n",
      "Non-trainable params: 2336 (9.12 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (1, 24, 32, 1)\n",
      "Box Targets shape: (1, 9072, 4)\n",
      "Class Targets shape: (1, 9072, 1)\n"
     ]
    }
   ],
   "source": [
    "for images, box_targets, cls_targets in train_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Box Targets shape: {box_targets.shape}\")\n",
    "    print(f\"Class Targets shape: {cls_targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BoxLoss(tf.losses.Loss):  \n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(\n",
    "#             reduction=\"none\", name=\"BoxLoss\"\n",
    "#         )\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         difference = y_true - y_pred\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less_equal(absolute_difference, self._delta),  # 여기를 수정\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5\n",
    "#         )\n",
    "\n",
    "#         return tf.reduce_sum(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CIoULoss(tf.losses.Loss):\n",
    "    def __init__(self, delta=2.0, anchors=None, name=\"CIoULoss\"):\n",
    "        super(CIoULoss, self).__init__(reduction=\"none\", name=name)\n",
    "        self._delta = delta\n",
    "        self.anchors = anchors\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Decode true and predicted boxes\n",
    "        true_boxes = self.decode_predictions(y_true, self.anchors)\n",
    "        pred_boxes = self.decode_predictions(y_pred, self.anchors)\n",
    "\n",
    "        # Calculate IoU\n",
    "        iou = self.iou(true_boxes, pred_boxes)\n",
    "\n",
    "        # Calculate center distances\n",
    "        center_true = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) / 2\n",
    "        center_pred = (pred_boxes[..., 0:2] + pred_boxes[..., 2:4]) / 2\n",
    "        center_distance = tf.reduce_sum(tf.square(center_true - center_pred), axis=-1)\n",
    "\n",
    "        # Calculate diagonal lengths\n",
    "        diag_true = tf.square(true_boxes[..., 2:4] - true_boxes[..., 0:2])\n",
    "        diag_pred = tf.square(pred_boxes[..., 2:4] - pred_boxes[..., 0:2])\n",
    "        diag_sum = diag_true + diag_pred\n",
    "\n",
    "        # Calculate aspect ratio\n",
    "        aspect_ratio_true = diag_true[..., 0] / diag_true[..., 1]\n",
    "        aspect_ratio_pred = diag_pred[..., 0] / diag_pred[..., 1]\n",
    "        aspect_ratio = tf.square(tf.maximum(aspect_ratio_true / aspect_ratio_pred, aspect_ratio_pred / aspect_ratio_true))\n",
    "\n",
    "        # Calculate CIOU\n",
    "        ciou = iou - (center_distance / tf.reduce_sum(diag_sum, axis=-1)) - (aspect_ratio / tf.reduce_sum(diag_sum, axis=-1))\n",
    "        ciou_loss = 1 - tf.clip_by_value(ciou, 0.0, 1.0 - self._delta)\n",
    "\n",
    "        return ciou_loss\n",
    "\n",
    "    @staticmethod\n",
    "    def iou(y_true, y_pred):\n",
    "        # Calculate intersection\n",
    "        x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "        y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "        x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "        y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "        \n",
    "        intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        \n",
    "        # Calculate union\n",
    "        area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "        area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "        union = area_true + area_pred - intersection\n",
    "        \n",
    "        # Calculate IoU\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        \n",
    "        return iou\n",
    "\n",
    "    def decode_predictions(self, labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "        anchor_x = anchors[..., 0]\n",
    "        anchor_y = anchors[..., 1]\n",
    "        anchor_w = anchors[..., 2]\n",
    "        anchor_h = anchors[..., 3]\n",
    "\n",
    "        cx = labels[..., 0] * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = labels[..., 1] * box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(labels[..., 2] * box_variance[2]) * anchor_w\n",
    "        height = tf.exp(labels[..., 3] * box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return decoded_boxes\n",
    "    \n",
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true_box, y_pred_box):\n",
    "        difference = y_true_box - y_pred_box\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "        return tf.reduce_mean(loss)  # 배치에 대한 평균을 반환\n",
    "\n",
    "\n",
    "class CombinedCIoUBoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta=2.0, anchors=None, weight_ciou=0.5, weight_box=0.5, name=\"CombinedCIoUBoxLoss\"):\n",
    "        super(CombinedCIoUBoxLoss, self).__init__(reduction=\"none\", name=name)\n",
    "        self.ciou_loss = CIoULoss(delta=delta, anchors=anchors)\n",
    "        self.box_loss = BoxLoss(delta=delta)\n",
    "        self.weight_ciou = weight_ciou\n",
    "        self.weight_box = weight_box\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # CIoU and Box loss calculations\n",
    "        ciou_loss = self.ciou_loss(y_true, y_pred)\n",
    "        box_loss = self.box_loss(y_true, y_pred)\n",
    "\n",
    "        combined_loss = self.weight_ciou * ciou_loss + self.weight_box * box_loss\n",
    "        return tf.reduce_mean(combined_loss)  # Compute the mean loss over the batch\n",
    "\n",
    "\n",
    "\n",
    "class ClassificationLoss(tf.losses.Loss):\n",
    "    def __init__(self, reduction=\"auto\", name=\"ClassificationLoss\"):\n",
    "        super(ClassificationLoss, self).__init__(reduction=reduction, name=name)\n",
    "\n",
    "    def call(self, y_true_cls, y_pred_cls):\n",
    "        # 레이블 매핑: -2 또는 -1 -> 0, 1 -> 1\n",
    "        labels = tf.where(y_true_cls == 1, 1, 0)\n",
    "\n",
    "        # 로짓 값을 확률로 변환\n",
    "        probabilities = tf.sigmoid(y_pred_cls)\n",
    "\n",
    "        # 절대 오차 제곱 계산 (Mean Squared Error)\n",
    "        mse_loss = tf.square(tf.cast(labels, dtype=tf.float32) - probabilities)\n",
    "        return tf.reduce_mean(mse_loss)  # 배치에 대한 평균 손실 반환\n",
    "\n",
    "\n",
    "class F1ScoreLoss(tf.keras.losses.Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        # 레이블 매핑과 확률 계산\n",
    "        labels = tf.where(y_true == 1, 1, 0)\n",
    "        probabilities = tf.nn.sigmoid(y_pred)\n",
    "        pred_positives = tf.cast(probabilities > 0.5, tf.float32)\n",
    "        \n",
    "        # True positives 계산\n",
    "        true_positives = tf.logical_and(tf.equal(labels, 1), tf.equal(pred_positives, 1))\n",
    "        true_positives = tf.cast(true_positives, tf.float32)\n",
    "        \n",
    "        # 변수를 float32로 캐스팅 후 합계 계산\n",
    "        tp = tf.reduce_sum(true_positives)\n",
    "        predicted_positives = tf.reduce_sum(pred_positives)\n",
    "        possible_positives = tf.reduce_sum(tf.cast(labels, tf.float32))  # 여기서 캐스팅을 수행\n",
    "        \n",
    "        # Precision and Recall 계산\n",
    "        precision = tp / (predicted_positives + tf.keras.backend.epsilon())\n",
    "        recall = tp / (possible_positives + tf.keras.backend.epsilon())\n",
    "        \n",
    "        # F1-Score and F1 Loss 계산\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "        return 1 - f1_score\n",
    "\n",
    "\n",
    "\n",
    "class CombinedLoss(tf.losses.Loss):\n",
    "    def __init__(self, alpha=0.7, name=\"CombinedLoss\"):\n",
    "        super(CombinedLoss, self).__init__(name=name)\n",
    "        self.alpha = alpha\n",
    "        self.classification_loss = ClassificationLoss()\n",
    "        self.f1_loss = F1ScoreLoss()\n",
    "\n",
    "    def call(self, y_true_cls, y_pred_cls):\n",
    "        # 기존 분류 손실 계산\n",
    "        cls_loss = self.classification_loss(y_true_cls, y_pred_cls)\n",
    "        \n",
    "        # F1 손실 계산\n",
    "        f1_loss = self.f1_loss(y_true_cls, y_pred_cls)\n",
    "\n",
    "        # 손실을 조합하여 최종 손실 반환\n",
    "        return self.alpha * cls_loss + (1 - self.alpha) * f1_loss\n",
    "\n",
    "\n",
    "# class CustomLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, alpha=0.75, gamma=5.0, delta=3.5):\n",
    "#         super(CustomLoss, self).__init__(reduction=\"auto\", name=\"CustomLoss\")\n",
    "#         self._cls_loss = ClassificationLoss(alpha, gamma)\n",
    "#         self._box_loss = BoxLoss(delta)\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true_box, y_true_cls, y_pred_box, y_pred_cls):\n",
    "#         y_pred_box = tf.cast(y_pred_box, dtype=tf.float32)\n",
    "#         y_pred_cls = tf.cast(y_pred_cls, dtype=tf.float32)\n",
    "\n",
    "#         box_labels = y_true_box\n",
    "#         box_predictions = y_pred_box\n",
    "#         cls_labels = y_true_cls\n",
    "#         cls_predictions = y_pred_cls\n",
    "\n",
    "#         positive_mask = tf.cast(tf.math.greater(cls_labels, 0.0), dtype=tf.float32)\n",
    "#         ignore_mask = tf.cast(tf.math.equal(cls_labels, -2.0), dtype=tf.float32)\n",
    "\n",
    "#         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "#         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "\n",
    "#         cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n",
    "#         box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "\n",
    "#         normalizer = tf.reduce_sum(positive_mask, axis=-1) + 1e-6\n",
    "#         cls_loss = tf.math.divide_no_nan(tf.reduce_sum(cls_loss, axis=-1), normalizer)\n",
    "#         box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
    "\n",
    "#         return cls_loss, box_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recall(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Recall', **kwargs):\n",
    "        super(Recall, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.possible_positives = self.add_weight(name='tp_fp', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # 레이블 매핑: -2 또는 -1 -> 0, 1 -> 1 \n",
    "        labels = tf.where(y_true == 1, 1, 0)\n",
    "        # 확률 계산 (sigmoid를 통해 로짓을 확률로 변환)\n",
    "        probabilities = tf.nn.sigmoid(y_pred)\n",
    "        pred_positives = tf.cast(probabilities > 0.5, self.dtype)  # self.dtype으로 캐스팅\n",
    "        # True positives 계산\n",
    "        true_positives = tf.logical_and(tf.equal(labels, 1), tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        self.possible_positives.assign_add(tf.reduce_sum(pred_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.possible_positives + tf.keras.backend.epsilon())\n",
    "    \n",
    "\n",
    "\n",
    "class Precision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Precision', **kwargs):\n",
    "        super(Precision, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.predicted_positives = self.add_weight(name='tp_fp', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # 레이블 매핑: -2 또는 -1 -> 0, 1 -> 1 \n",
    "        labels = tf.where(y_true == 1, 1, 0)\n",
    "        # 확률 계산 (sigmoid를 통해 로짓을 확률로 변환)\n",
    "        probabilities = tf.nn.sigmoid(y_pred)\n",
    "        pred_positives = tf.cast(probabilities > 0.5, self.dtype)  # self.dtype으로 캐스팅\n",
    "        # True positives 계산\n",
    "        true_positives = tf.logical_and(tf.equal(labels, 1), tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        self.predicted_positives.assign_add(tf.reduce_sum(pred_positives))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.true_positives / (self.predicted_positives + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "decay_steps = 30\n",
    "decay_rate = 0.96\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import Precision, Recall\n",
    "\n",
    "num_classes = 1\n",
    "model = CustomModel(num_classes)\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "box_loss_fn = CombinedCIoUBoxLoss(anchors = anchors)\n",
    "cls_loss_fn = CombinedLoss()\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'regression': box_loss_fn, 'classification': cls_loss_fn},\n",
    "              metrics={'classification': [Precision(), Recall()]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (9, 24, 32, 1)\n",
      "Box Targets shape: (9, 9072, 4)\n",
      "Class Targets shape: (9, 9072, 1)\n",
      "Images max: 255.0\n",
      "Images min: 0.0\n",
      "Box Targets shape: (9, 9072, 4)\n",
      "Class Targets shape: (9, 9072, 1)\n"
     ]
    }
   ],
   "source": [
    "new_batch_size = 9\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, box_targets, cls_targets in train_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Box Targets shape: {box_targets.shape}\")\n",
    "    print(f\"Class Targets shape: {cls_targets.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "    print(\"Box Targets shape:\", box_targets.shape)\n",
    "    print(\"Class Targets shape:\", cls_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(lambda x, y_box, y_cls: (x, {'regression': y_box, 'classification': y_cls}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 15:11:25.448787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-04-10 15:11:28.177468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfa95dc5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-10 15:11:28.177514: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.177526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.177531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.177541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.177545: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.177551: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.177554: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-10 15:11:28.182792: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-10 15:11:28.309624: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 105s 58ms/step - loss: 1.8686 - classification_loss: 0.1930 - regression_loss: 1.6756 - classification_Precision: 0.5512 - classification_Recall: 0.5512 - lr: 0.0010\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.6094 - classification_loss: 0.1569 - regression_loss: 1.4525 - classification_Precision: 0.6681 - classification_Recall: 0.6681 - lr: 0.0010\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.5232 - classification_loss: 0.1502 - regression_loss: 1.3730 - classification_Precision: 0.6767 - classification_Recall: 0.6767 - lr: 0.0010\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.4470 - classification_loss: 0.1474 - regression_loss: 1.2996 - classification_Precision: 0.6811 - classification_Recall: 0.6811 - lr: 0.0010\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.3839 - classification_loss: 0.1451 - regression_loss: 1.2388 - classification_Precision: 0.6840 - classification_Recall: 0.6840 - lr: 0.0010\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.3407 - classification_loss: 0.1429 - regression_loss: 1.1978 - classification_Precision: 0.6867 - classification_Recall: 0.6867 - lr: 0.0010\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.3111 - classification_loss: 0.1414 - regression_loss: 1.1696 - classification_Precision: 0.6892 - classification_Recall: 0.6892 - lr: 0.0010\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.2885 - classification_loss: 0.1395 - regression_loss: 1.1491 - classification_Precision: 0.6916 - classification_Recall: 0.6916 - lr: 0.0010\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.2700 - classification_loss: 0.1382 - regression_loss: 1.1319 - classification_Precision: 0.6937 - classification_Recall: 0.6937 - lr: 0.0010\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.2622 - classification_loss: 0.1372 - regression_loss: 1.1250 - classification_Precision: 0.6949 - classification_Recall: 0.6949 - lr: 0.0010\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 11/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.2503 - classification_loss: 0.1362 - regression_loss: 1.1141 - classification_Precision: 0.6968 - classification_Recall: 0.6968 - lr: 0.0010\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 12/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.2357 - classification_loss: 0.1354 - regression_loss: 1.1003 - classification_Precision: 0.6976 - classification_Recall: 0.6976 - lr: 0.0010\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 13/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.2193 - classification_loss: 0.1343 - regression_loss: 1.0850 - classification_Precision: 0.6988 - classification_Recall: 0.6988 - lr: 0.0010\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 14/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.2185 - classification_loss: 0.1337 - regression_loss: 1.0847 - classification_Precision: 0.6995 - classification_Recall: 0.6995 - lr: 0.0010\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 15/300\n",
      "1204/1204 [==============================] - 69s 58ms/step - loss: 1.2037 - classification_loss: 0.1331 - regression_loss: 1.0706 - classification_Precision: 0.7012 - classification_Recall: 0.7012 - lr: 0.0010\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 16/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 1.1939 - classification_loss: 0.1320 - regression_loss: 1.0619 - classification_Precision: 0.7021 - classification_Recall: 0.7021 - lr: 0.0010\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 17/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1924 - classification_loss: 0.1321 - regression_loss: 1.0604 - classification_Precision: 0.7020 - classification_Recall: 0.7020 - lr: 0.0010\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 18/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1769 - classification_loss: 0.1309 - regression_loss: 1.0460 - classification_Precision: 0.7034 - classification_Recall: 0.7034 - lr: 0.0010\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 19/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.1743 - classification_loss: 0.1309 - regression_loss: 1.0434 - classification_Precision: 0.7029 - classification_Recall: 0.7029 - lr: 0.0010\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 20/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 1.1681 - classification_loss: 0.1301 - regression_loss: 1.0380 - classification_Precision: 0.7044 - classification_Recall: 0.7044 - lr: 0.0010\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 21/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1616 - classification_loss: 0.1294 - regression_loss: 1.0322 - classification_Precision: 0.7054 - classification_Recall: 0.7054 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 22/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.1527 - classification_loss: 0.1290 - regression_loss: 1.0237 - classification_Precision: 0.7059 - classification_Recall: 0.7059 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 23/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1508 - classification_loss: 0.1285 - regression_loss: 1.0223 - classification_Precision: 0.7070 - classification_Recall: 0.7070 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 24/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1469 - classification_loss: 0.1286 - regression_loss: 1.0183 - classification_Precision: 0.7064 - classification_Recall: 0.7064 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 25/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1412 - classification_loss: 0.1284 - regression_loss: 1.0128 - classification_Precision: 0.7065 - classification_Recall: 0.7065 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 26/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1340 - classification_loss: 0.1281 - regression_loss: 1.0059 - classification_Precision: 0.7078 - classification_Recall: 0.7078 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 27/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1305 - classification_loss: 0.1273 - regression_loss: 1.0032 - classification_Precision: 0.7087 - classification_Recall: 0.7087 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 28/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1260 - classification_loss: 0.1274 - regression_loss: 0.9986 - classification_Precision: 0.7083 - classification_Recall: 0.7083 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 29/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1210 - classification_loss: 0.1270 - regression_loss: 0.9939 - classification_Precision: 0.7086 - classification_Recall: 0.7086 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 30/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1182 - classification_loss: 0.1270 - regression_loss: 0.9912 - classification_Precision: 0.7090 - classification_Recall: 0.7090 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 31/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1131 - classification_loss: 0.1265 - regression_loss: 0.9866 - classification_Precision: 0.7100 - classification_Recall: 0.7100 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 32/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1054 - classification_loss: 0.1265 - regression_loss: 0.9790 - classification_Precision: 0.7099 - classification_Recall: 0.7099 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 33/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.1033 - classification_loss: 0.1263 - regression_loss: 0.9769 - classification_Precision: 0.7099 - classification_Recall: 0.7099 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 34/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.1058 - classification_loss: 0.1257 - regression_loss: 0.9801 - classification_Precision: 0.7113 - classification_Recall: 0.7113 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 35/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0976 - classification_loss: 0.1257 - regression_loss: 0.9718 - classification_Precision: 0.7111 - classification_Recall: 0.7111 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 36/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0945 - classification_loss: 0.1256 - regression_loss: 0.9688 - classification_Precision: 0.7121 - classification_Recall: 0.7121 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 37/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0971 - classification_loss: 0.1257 - regression_loss: 0.9715 - classification_Precision: 0.7108 - classification_Recall: 0.7108 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 38/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0900 - classification_loss: 0.1253 - regression_loss: 0.9648 - classification_Precision: 0.7123 - classification_Recall: 0.7123 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 39/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 1.0871 - classification_loss: 0.1254 - regression_loss: 0.9617 - classification_Precision: 0.7118 - classification_Recall: 0.7118 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00096.\n",
      "Epoch 40/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0841 - classification_loss: 0.1249 - regression_loss: 0.9592 - classification_Precision: 0.7125 - classification_Recall: 0.7125 - lr: 9.6000e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 41/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0768 - classification_loss: 0.1244 - regression_loss: 0.9524 - classification_Precision: 0.7134 - classification_Recall: 0.7134 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 42/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0734 - classification_loss: 0.1243 - regression_loss: 0.9491 - classification_Precision: 0.7131 - classification_Recall: 0.7131 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 43/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0731 - classification_loss: 0.1243 - regression_loss: 0.9488 - classification_Precision: 0.7140 - classification_Recall: 0.7140 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 44/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0695 - classification_loss: 0.1238 - regression_loss: 0.9457 - classification_Precision: 0.7144 - classification_Recall: 0.7144 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 45/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0645 - classification_loss: 0.1241 - regression_loss: 0.9404 - classification_Precision: 0.7145 - classification_Recall: 0.7145 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 46/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.0672 - classification_loss: 0.1239 - regression_loss: 0.9433 - classification_Precision: 0.7138 - classification_Recall: 0.7138 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 47/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.0576 - classification_loss: 0.1235 - regression_loss: 0.9341 - classification_Precision: 0.7152 - classification_Recall: 0.7152 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 48/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0600 - classification_loss: 0.1233 - regression_loss: 0.9367 - classification_Precision: 0.7151 - classification_Recall: 0.7151 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 49/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0562 - classification_loss: 0.1236 - regression_loss: 0.9326 - classification_Precision: 0.7150 - classification_Recall: 0.7150 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 50/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0539 - classification_loss: 0.1232 - regression_loss: 0.9308 - classification_Precision: 0.7155 - classification_Recall: 0.7155 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 51/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0574 - classification_loss: 0.1230 - regression_loss: 0.9344 - classification_Precision: 0.7156 - classification_Recall: 0.7156 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 52/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.0443 - classification_loss: 0.1226 - regression_loss: 0.9217 - classification_Precision: 0.7165 - classification_Recall: 0.7165 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 53/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.0510 - classification_loss: 0.1227 - regression_loss: 0.9283 - classification_Precision: 0.7161 - classification_Recall: 0.7161 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 54/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0476 - classification_loss: 0.1226 - regression_loss: 0.9250 - classification_Precision: 0.7164 - classification_Recall: 0.7164 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 55/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0443 - classification_loss: 0.1222 - regression_loss: 0.9221 - classification_Precision: 0.7171 - classification_Recall: 0.7171 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 56/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0398 - classification_loss: 0.1221 - regression_loss: 0.9177 - classification_Precision: 0.7173 - classification_Recall: 0.7173 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 57/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0379 - classification_loss: 0.1220 - regression_loss: 0.9159 - classification_Precision: 0.7173 - classification_Recall: 0.7173 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 58/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0426 - classification_loss: 0.1220 - regression_loss: 0.9206 - classification_Precision: 0.7170 - classification_Recall: 0.7170 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 59/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0353 - classification_loss: 0.1217 - regression_loss: 0.9135 - classification_Precision: 0.7171 - classification_Recall: 0.7171 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 0.0009216.\n",
      "Epoch 60/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0316 - classification_loss: 0.1215 - regression_loss: 0.9101 - classification_Precision: 0.7179 - classification_Recall: 0.7179 - lr: 9.2160e-04\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 61/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0263 - classification_loss: 0.1211 - regression_loss: 0.9052 - classification_Precision: 0.7185 - classification_Recall: 0.7185 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 62/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0287 - classification_loss: 0.1213 - regression_loss: 0.9074 - classification_Precision: 0.7180 - classification_Recall: 0.7180 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 63/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0220 - classification_loss: 0.1208 - regression_loss: 0.9013 - classification_Precision: 0.7193 - classification_Recall: 0.7193 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 64/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0301 - classification_loss: 0.1213 - regression_loss: 0.9088 - classification_Precision: 0.7185 - classification_Recall: 0.7185 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 65/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.0276 - classification_loss: 0.1211 - regression_loss: 0.9066 - classification_Precision: 0.7190 - classification_Recall: 0.7190 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 66/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0185 - classification_loss: 0.1205 - regression_loss: 0.8980 - classification_Precision: 0.7200 - classification_Recall: 0.7200 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 67/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0218 - classification_loss: 0.1207 - regression_loss: 0.9011 - classification_Precision: 0.7193 - classification_Recall: 0.7193 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 68/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.0182 - classification_loss: 0.1205 - regression_loss: 0.8977 - classification_Precision: 0.7197 - classification_Recall: 0.7197 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 69/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 1.0165 - classification_loss: 0.1206 - regression_loss: 0.8959 - classification_Precision: 0.7193 - classification_Recall: 0.7193 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 70/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0090 - classification_loss: 0.1196 - regression_loss: 0.8894 - classification_Precision: 0.7219 - classification_Recall: 0.7219 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 71/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0183 - classification_loss: 0.1196 - regression_loss: 0.8987 - classification_Precision: 0.7212 - classification_Recall: 0.7212 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 72/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0190 - classification_loss: 0.1200 - regression_loss: 0.8989 - classification_Precision: 0.7211 - classification_Recall: 0.7211 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 73/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.0072 - classification_loss: 0.1198 - regression_loss: 0.8874 - classification_Precision: 0.7211 - classification_Recall: 0.7211 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 74/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.0181 - classification_loss: 0.1199 - regression_loss: 0.8981 - classification_Precision: 0.7209 - classification_Recall: 0.7209 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 75/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 1.0128 - classification_loss: 0.1195 - regression_loss: 0.8933 - classification_Precision: 0.7216 - classification_Recall: 0.7216 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 76/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0100 - classification_loss: 0.1197 - regression_loss: 0.8903 - classification_Precision: 0.7212 - classification_Recall: 0.7212 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 77/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0091 - classification_loss: 0.1193 - regression_loss: 0.8898 - classification_Precision: 0.7221 - classification_Recall: 0.7221 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 78/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0009 - classification_loss: 0.1191 - regression_loss: 0.8818 - classification_Precision: 0.7224 - classification_Recall: 0.7224 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 79/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0079 - classification_loss: 0.1195 - regression_loss: 0.8884 - classification_Precision: 0.7219 - classification_Recall: 0.7219 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 0.0008847359999999999.\n",
      "Epoch 80/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0066 - classification_loss: 0.1192 - regression_loss: 0.8874 - classification_Precision: 0.7220 - classification_Recall: 0.7220 - lr: 8.8474e-04\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 81/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0014 - classification_loss: 0.1186 - regression_loss: 0.8828 - classification_Precision: 0.7230 - classification_Recall: 0.7230 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 82/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9914 - classification_loss: 0.1185 - regression_loss: 0.8730 - classification_Precision: 0.7235 - classification_Recall: 0.7235 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 83/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 1.0023 - classification_loss: 0.1189 - regression_loss: 0.8834 - classification_Precision: 0.7236 - classification_Recall: 0.7236 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 84/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9980 - classification_loss: 0.1186 - regression_loss: 0.8794 - classification_Precision: 0.7234 - classification_Recall: 0.7234 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 85/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9934 - classification_loss: 0.1182 - regression_loss: 0.8752 - classification_Precision: 0.7238 - classification_Recall: 0.7238 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 86/300\n",
      "1204/1204 [==============================] - 69s 58ms/step - loss: 0.9978 - classification_loss: 0.1181 - regression_loss: 0.8797 - classification_Precision: 0.7245 - classification_Recall: 0.7245 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 87/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9946 - classification_loss: 0.1183 - regression_loss: 0.8762 - classification_Precision: 0.7240 - classification_Recall: 0.7240 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 88/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9928 - classification_loss: 0.1183 - regression_loss: 0.8744 - classification_Precision: 0.7236 - classification_Recall: 0.7236 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 89/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9918 - classification_loss: 0.1181 - regression_loss: 0.8737 - classification_Precision: 0.7244 - classification_Recall: 0.7244 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 90/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9887 - classification_loss: 0.1177 - regression_loss: 0.8710 - classification_Precision: 0.7253 - classification_Recall: 0.7253 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 91/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9887 - classification_loss: 0.1178 - regression_loss: 0.8708 - classification_Precision: 0.7248 - classification_Recall: 0.7248 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 92/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9895 - classification_loss: 0.1180 - regression_loss: 0.8715 - classification_Precision: 0.7245 - classification_Recall: 0.7245 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 93/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9855 - classification_loss: 0.1175 - regression_loss: 0.8680 - classification_Precision: 0.7256 - classification_Recall: 0.7256 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 94/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9897 - classification_loss: 0.1176 - regression_loss: 0.8721 - classification_Precision: 0.7250 - classification_Recall: 0.7250 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 95/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9847 - classification_loss: 0.1173 - regression_loss: 0.8674 - classification_Precision: 0.7255 - classification_Recall: 0.7255 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 96/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9904 - classification_loss: 0.1175 - regression_loss: 0.8729 - classification_Precision: 0.7251 - classification_Recall: 0.7251 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 97/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9827 - classification_loss: 0.1172 - regression_loss: 0.8655 - classification_Precision: 0.7261 - classification_Recall: 0.7261 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 98/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9818 - classification_loss: 0.1174 - regression_loss: 0.8644 - classification_Precision: 0.7259 - classification_Recall: 0.7259 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 99/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9872 - classification_loss: 0.1174 - regression_loss: 0.8698 - classification_Precision: 0.7256 - classification_Recall: 0.7256 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 0.0008493465599999999.\n",
      "Epoch 100/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9824 - classification_loss: 0.1172 - regression_loss: 0.8652 - classification_Precision: 0.7259 - classification_Recall: 0.7259 - lr: 8.4935e-04\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 101/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9808 - classification_loss: 0.1169 - regression_loss: 0.8639 - classification_Precision: 0.7266 - classification_Recall: 0.7266 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 102/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9775 - classification_loss: 0.1168 - regression_loss: 0.8607 - classification_Precision: 0.7267 - classification_Recall: 0.7267 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 103/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9803 - classification_loss: 0.1169 - regression_loss: 0.8634 - classification_Precision: 0.7263 - classification_Recall: 0.7263 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 104/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9761 - classification_loss: 0.1166 - regression_loss: 0.8596 - classification_Precision: 0.7270 - classification_Recall: 0.7270 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 105/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9745 - classification_loss: 0.1169 - regression_loss: 0.8576 - classification_Precision: 0.7265 - classification_Recall: 0.7265 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 106/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9693 - classification_loss: 0.1162 - regression_loss: 0.8531 - classification_Precision: 0.7275 - classification_Recall: 0.7275 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 107/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 0.9781 - classification_loss: 0.1167 - regression_loss: 0.8614 - classification_Precision: 0.7271 - classification_Recall: 0.7271 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 108/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9877 - classification_loss: 0.1170 - regression_loss: 0.8707 - classification_Precision: 0.7262 - classification_Recall: 0.7262 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 109/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9670 - classification_loss: 0.1161 - regression_loss: 0.8510 - classification_Precision: 0.7284 - classification_Recall: 0.7284 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 110/300\n",
      "1204/1204 [==============================] - 69s 58ms/step - loss: 0.9718 - classification_loss: 0.1160 - regression_loss: 0.8558 - classification_Precision: 0.7279 - classification_Recall: 0.7279 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 111/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9755 - classification_loss: 0.1165 - regression_loss: 0.8591 - classification_Precision: 0.7272 - classification_Recall: 0.7272 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 112/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9767 - classification_loss: 0.1163 - regression_loss: 0.8604 - classification_Precision: 0.7278 - classification_Recall: 0.7278 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 113/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9693 - classification_loss: 0.1158 - regression_loss: 0.8534 - classification_Precision: 0.7280 - classification_Recall: 0.7280 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 114/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9746 - classification_loss: 0.1159 - regression_loss: 0.8587 - classification_Precision: 0.7281 - classification_Recall: 0.7281 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 115/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9658 - classification_loss: 0.1158 - regression_loss: 0.8499 - classification_Precision: 0.7282 - classification_Recall: 0.7282 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 116/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9632 - classification_loss: 0.1153 - regression_loss: 0.8479 - classification_Precision: 0.7290 - classification_Recall: 0.7290 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 117/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9702 - classification_loss: 0.1159 - regression_loss: 0.8544 - classification_Precision: 0.7281 - classification_Recall: 0.7281 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 118/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9680 - classification_loss: 0.1156 - regression_loss: 0.8523 - classification_Precision: 0.7286 - classification_Recall: 0.7286 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 119/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9661 - classification_loss: 0.1152 - regression_loss: 0.8510 - classification_Precision: 0.7297 - classification_Recall: 0.7297 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 0.0008153726975999999.\n",
      "Epoch 120/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9645 - classification_loss: 0.1153 - regression_loss: 0.8492 - classification_Precision: 0.7290 - classification_Recall: 0.7290 - lr: 8.1537e-04\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 121/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9551 - classification_loss: 0.1150 - regression_loss: 0.8402 - classification_Precision: 0.7300 - classification_Recall: 0.7300 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 122/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9579 - classification_loss: 0.1150 - regression_loss: 0.8429 - classification_Precision: 0.7296 - classification_Recall: 0.7296 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 123/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9675 - classification_loss: 0.1152 - regression_loss: 0.8523 - classification_Precision: 0.7294 - classification_Recall: 0.7294 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 124/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9593 - classification_loss: 0.1148 - regression_loss: 0.8445 - classification_Precision: 0.7300 - classification_Recall: 0.7300 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 125/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9625 - classification_loss: 0.1150 - regression_loss: 0.8475 - classification_Precision: 0.7296 - classification_Recall: 0.7296 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 126/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9581 - classification_loss: 0.1145 - regression_loss: 0.8435 - classification_Precision: 0.7304 - classification_Recall: 0.7304 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 127/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9541 - classification_loss: 0.1146 - regression_loss: 0.8395 - classification_Precision: 0.7306 - classification_Recall: 0.7306 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 128/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9555 - classification_loss: 0.1144 - regression_loss: 0.8411 - classification_Precision: 0.7308 - classification_Recall: 0.7308 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 129/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9578 - classification_loss: 0.1142 - regression_loss: 0.8436 - classification_Precision: 0.7311 - classification_Recall: 0.7311 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 130/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9592 - classification_loss: 0.1147 - regression_loss: 0.8445 - classification_Precision: 0.7302 - classification_Recall: 0.7302 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 131/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9502 - classification_loss: 0.1141 - regression_loss: 0.8361 - classification_Precision: 0.7310 - classification_Recall: 0.7310 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 132/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9577 - classification_loss: 0.1145 - regression_loss: 0.8432 - classification_Precision: 0.7308 - classification_Recall: 0.7308 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 133/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9524 - classification_loss: 0.1140 - regression_loss: 0.8384 - classification_Precision: 0.7315 - classification_Recall: 0.7315 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 134/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9576 - classification_loss: 0.1144 - regression_loss: 0.8432 - classification_Precision: 0.7308 - classification_Recall: 0.7308 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 135/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9516 - classification_loss: 0.1140 - regression_loss: 0.8375 - classification_Precision: 0.7315 - classification_Recall: 0.7315 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 136/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9504 - classification_loss: 0.1136 - regression_loss: 0.8368 - classification_Precision: 0.7323 - classification_Recall: 0.7323 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 137/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9561 - classification_loss: 0.1140 - regression_loss: 0.8420 - classification_Precision: 0.7316 - classification_Recall: 0.7316 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 138/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9542 - classification_loss: 0.1138 - regression_loss: 0.8403 - classification_Precision: 0.7318 - classification_Recall: 0.7318 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 139/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9513 - classification_loss: 0.1137 - regression_loss: 0.8375 - classification_Precision: 0.7322 - classification_Recall: 0.7322 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 0.0007827577896959999.\n",
      "Epoch 140/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9509 - classification_loss: 0.1138 - regression_loss: 0.8371 - classification_Precision: 0.7320 - classification_Recall: 0.7320 - lr: 7.8276e-04\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 141/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9479 - classification_loss: 0.1136 - regression_loss: 0.8343 - classification_Precision: 0.7322 - classification_Recall: 0.7322 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 142/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9511 - classification_loss: 0.1135 - regression_loss: 0.8377 - classification_Precision: 0.7323 - classification_Recall: 0.7323 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 143/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9514 - classification_loss: 0.1137 - regression_loss: 0.8377 - classification_Precision: 0.7316 - classification_Recall: 0.7316 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 144/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9418 - classification_loss: 0.1131 - regression_loss: 0.8287 - classification_Precision: 0.7331 - classification_Recall: 0.7331 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 145/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9485 - classification_loss: 0.1132 - regression_loss: 0.8353 - classification_Precision: 0.7327 - classification_Recall: 0.7327 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 146/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9434 - classification_loss: 0.1132 - regression_loss: 0.8303 - classification_Precision: 0.7325 - classification_Recall: 0.7325 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 147/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9436 - classification_loss: 0.1131 - regression_loss: 0.8306 - classification_Precision: 0.7327 - classification_Recall: 0.7327 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 148/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9508 - classification_loss: 0.1131 - regression_loss: 0.8377 - classification_Precision: 0.7329 - classification_Recall: 0.7329 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 149/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9442 - classification_loss: 0.1128 - regression_loss: 0.8314 - classification_Precision: 0.7337 - classification_Recall: 0.7337 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 150/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9454 - classification_loss: 0.1132 - regression_loss: 0.8322 - classification_Precision: 0.7327 - classification_Recall: 0.7327 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 151: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 151/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9513 - classification_loss: 0.1131 - regression_loss: 0.8382 - classification_Precision: 0.7329 - classification_Recall: 0.7329 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 152: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 152/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9425 - classification_loss: 0.1128 - regression_loss: 0.8297 - classification_Precision: 0.7332 - classification_Recall: 0.7332 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 153: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 153/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9361 - classification_loss: 0.1124 - regression_loss: 0.8238 - classification_Precision: 0.7344 - classification_Recall: 0.7344 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 154: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 154/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9430 - classification_loss: 0.1125 - regression_loss: 0.8305 - classification_Precision: 0.7339 - classification_Recall: 0.7339 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 155: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 155/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9440 - classification_loss: 0.1128 - regression_loss: 0.8312 - classification_Precision: 0.7334 - classification_Recall: 0.7334 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 156: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 156/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9397 - classification_loss: 0.1125 - regression_loss: 0.8273 - classification_Precision: 0.7341 - classification_Recall: 0.7341 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 157: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 157/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9456 - classification_loss: 0.1127 - regression_loss: 0.8329 - classification_Precision: 0.7333 - classification_Recall: 0.7333 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 158: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 158/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9436 - classification_loss: 0.1125 - regression_loss: 0.8311 - classification_Precision: 0.7340 - classification_Recall: 0.7340 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 159: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 159/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9405 - classification_loss: 0.1125 - regression_loss: 0.8280 - classification_Precision: 0.7339 - classification_Recall: 0.7339 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 160: LearningRateScheduler setting learning rate to 0.0007514474781081599.\n",
      "Epoch 160/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9417 - classification_loss: 0.1122 - regression_loss: 0.8294 - classification_Precision: 0.7339 - classification_Recall: 0.7339 - lr: 7.5145e-04\n",
      "\n",
      "Epoch 161: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 161/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9378 - classification_loss: 0.1120 - regression_loss: 0.8258 - classification_Precision: 0.7348 - classification_Recall: 0.7348 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 162: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 162/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9345 - classification_loss: 0.1118 - regression_loss: 0.8227 - classification_Precision: 0.7354 - classification_Recall: 0.7354 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 163: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 163/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9350 - classification_loss: 0.1120 - regression_loss: 0.8231 - classification_Precision: 0.7347 - classification_Recall: 0.7347 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 164: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 164/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9389 - classification_loss: 0.1122 - regression_loss: 0.8268 - classification_Precision: 0.7343 - classification_Recall: 0.7343 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 165: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 165/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9351 - classification_loss: 0.1119 - regression_loss: 0.8232 - classification_Precision: 0.7350 - classification_Recall: 0.7350 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 166: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 166/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9387 - classification_loss: 0.1122 - regression_loss: 0.8266 - classification_Precision: 0.7344 - classification_Recall: 0.7344 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 167: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 167/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9307 - classification_loss: 0.1117 - regression_loss: 0.8189 - classification_Precision: 0.7351 - classification_Recall: 0.7351 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 168: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 168/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9350 - classification_loss: 0.1120 - regression_loss: 0.8230 - classification_Precision: 0.7351 - classification_Recall: 0.7351 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 169: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 169/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9362 - classification_loss: 0.1116 - regression_loss: 0.8246 - classification_Precision: 0.7353 - classification_Recall: 0.7353 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 170: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 170/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9302 - classification_loss: 0.1114 - regression_loss: 0.8188 - classification_Precision: 0.7356 - classification_Recall: 0.7356 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 171: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 171/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9286 - classification_loss: 0.1112 - regression_loss: 0.8174 - classification_Precision: 0.7361 - classification_Recall: 0.7361 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 172: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 172/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9316 - classification_loss: 0.1113 - regression_loss: 0.8203 - classification_Precision: 0.7359 - classification_Recall: 0.7359 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 173: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 173/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9316 - classification_loss: 0.1114 - regression_loss: 0.8203 - classification_Precision: 0.7358 - classification_Recall: 0.7358 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 174: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 174/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9321 - classification_loss: 0.1113 - regression_loss: 0.8208 - classification_Precision: 0.7360 - classification_Recall: 0.7360 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 175: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 175/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9310 - classification_loss: 0.1112 - regression_loss: 0.8198 - classification_Precision: 0.7359 - classification_Recall: 0.7359 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 176: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 176/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9385 - classification_loss: 0.1114 - regression_loss: 0.8271 - classification_Precision: 0.7361 - classification_Recall: 0.7361 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 177: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 177/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9276 - classification_loss: 0.1110 - regression_loss: 0.8167 - classification_Precision: 0.7367 - classification_Recall: 0.7367 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 178: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 178/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9324 - classification_loss: 0.1111 - regression_loss: 0.8213 - classification_Precision: 0.7361 - classification_Recall: 0.7361 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 179: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 179/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9266 - classification_loss: 0.1106 - regression_loss: 0.8160 - classification_Precision: 0.7370 - classification_Recall: 0.7370 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 180: LearningRateScheduler setting learning rate to 0.0007213895789838334.\n",
      "Epoch 180/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9326 - classification_loss: 0.1111 - regression_loss: 0.8215 - classification_Precision: 0.7362 - classification_Recall: 0.7362 - lr: 7.2139e-04\n",
      "\n",
      "Epoch 181: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 181/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9247 - classification_loss: 0.1104 - regression_loss: 0.8143 - classification_Precision: 0.7378 - classification_Recall: 0.7378 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 182: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 182/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9301 - classification_loss: 0.1107 - regression_loss: 0.8194 - classification_Precision: 0.7369 - classification_Recall: 0.7369 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 183: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 183/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9262 - classification_loss: 0.1105 - regression_loss: 0.8157 - classification_Precision: 0.7376 - classification_Recall: 0.7376 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 184: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 184/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9305 - classification_loss: 0.1107 - regression_loss: 0.8198 - classification_Precision: 0.7369 - classification_Recall: 0.7369 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 185: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 185/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9248 - classification_loss: 0.1104 - regression_loss: 0.8144 - classification_Precision: 0.7374 - classification_Recall: 0.7374 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 186: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 186/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9253 - classification_loss: 0.1104 - regression_loss: 0.8148 - classification_Precision: 0.7376 - classification_Recall: 0.7376 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 187: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 187/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9257 - classification_loss: 0.1101 - regression_loss: 0.8156 - classification_Precision: 0.7386 - classification_Recall: 0.7386 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 188: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 188/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9260 - classification_loss: 0.1103 - regression_loss: 0.8157 - classification_Precision: 0.7375 - classification_Recall: 0.7375 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 189: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 189/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9216 - classification_loss: 0.1099 - regression_loss: 0.8117 - classification_Precision: 0.7385 - classification_Recall: 0.7385 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 190: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 190/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9243 - classification_loss: 0.1101 - regression_loss: 0.8143 - classification_Precision: 0.7383 - classification_Recall: 0.7383 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 191: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 191/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9215 - classification_loss: 0.1096 - regression_loss: 0.8118 - classification_Precision: 0.7387 - classification_Recall: 0.7387 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 192: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 192/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9228 - classification_loss: 0.1101 - regression_loss: 0.8126 - classification_Precision: 0.7384 - classification_Recall: 0.7384 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 193: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 193/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9266 - classification_loss: 0.1104 - regression_loss: 0.8162 - classification_Precision: 0.7375 - classification_Recall: 0.7375 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 194: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 194/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9211 - classification_loss: 0.1099 - regression_loss: 0.8112 - classification_Precision: 0.7383 - classification_Recall: 0.7383 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 195: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 195/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9234 - classification_loss: 0.1099 - regression_loss: 0.8135 - classification_Precision: 0.7389 - classification_Recall: 0.7389 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 196: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 196/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9222 - classification_loss: 0.1098 - regression_loss: 0.8123 - classification_Precision: 0.7386 - classification_Recall: 0.7386 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 197: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 197/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9269 - classification_loss: 0.1100 - regression_loss: 0.8169 - classification_Precision: 0.7383 - classification_Recall: 0.7383 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 198: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 198/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9195 - classification_loss: 0.1096 - regression_loss: 0.8100 - classification_Precision: 0.7389 - classification_Recall: 0.7389 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 199: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 199/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9182 - classification_loss: 0.1096 - regression_loss: 0.8086 - classification_Precision: 0.7393 - classification_Recall: 0.7393 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 200: LearningRateScheduler setting learning rate to 0.0006925339958244801.\n",
      "Epoch 200/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9270 - classification_loss: 0.1098 - regression_loss: 0.8172 - classification_Precision: 0.7382 - classification_Recall: 0.7382 - lr: 6.9253e-04\n",
      "\n",
      "Epoch 201: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 201/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9212 - classification_loss: 0.1097 - regression_loss: 0.8115 - classification_Precision: 0.7388 - classification_Recall: 0.7388 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 202: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 202/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9184 - classification_loss: 0.1095 - regression_loss: 0.8090 - classification_Precision: 0.7395 - classification_Recall: 0.7395 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 203: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 203/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9188 - classification_loss: 0.1092 - regression_loss: 0.8096 - classification_Precision: 0.7398 - classification_Recall: 0.7398 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 204: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 204/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9231 - classification_loss: 0.1097 - regression_loss: 0.8134 - classification_Precision: 0.7389 - classification_Recall: 0.7389 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 205: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 205/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9169 - classification_loss: 0.1092 - regression_loss: 0.8077 - classification_Precision: 0.7398 - classification_Recall: 0.7398 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 206: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 206/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9141 - classification_loss: 0.1088 - regression_loss: 0.8052 - classification_Precision: 0.7403 - classification_Recall: 0.7403 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 207: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 207/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9166 - classification_loss: 0.1087 - regression_loss: 0.8079 - classification_Precision: 0.7404 - classification_Recall: 0.7404 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 208: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 208/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9198 - classification_loss: 0.1089 - regression_loss: 0.8109 - classification_Precision: 0.7402 - classification_Recall: 0.7402 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 209: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 209/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9188 - classification_loss: 0.1092 - regression_loss: 0.8096 - classification_Precision: 0.7394 - classification_Recall: 0.7394 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 210: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 210/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9159 - classification_loss: 0.1087 - regression_loss: 0.8071 - classification_Precision: 0.7406 - classification_Recall: 0.7406 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 211: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 211/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9146 - classification_loss: 0.1088 - regression_loss: 0.8058 - classification_Precision: 0.7403 - classification_Recall: 0.7403 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 212: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 212/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9126 - classification_loss: 0.1086 - regression_loss: 0.8041 - classification_Precision: 0.7405 - classification_Recall: 0.7405 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 213: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 213/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9144 - classification_loss: 0.1085 - regression_loss: 0.8059 - classification_Precision: 0.7409 - classification_Recall: 0.7409 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 214: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 214/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9153 - classification_loss: 0.1087 - regression_loss: 0.8067 - classification_Precision: 0.7408 - classification_Recall: 0.7408 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 215: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 215/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9146 - classification_loss: 0.1084 - regression_loss: 0.8062 - classification_Precision: 0.7410 - classification_Recall: 0.7410 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 216: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 216/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9148 - classification_loss: 0.1085 - regression_loss: 0.8063 - classification_Precision: 0.7409 - classification_Recall: 0.7409 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 217: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 217/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9170 - classification_loss: 0.1090 - regression_loss: 0.8080 - classification_Precision: 0.7402 - classification_Recall: 0.7402 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 218: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 218/300\n",
      "1204/1204 [==============================] - 67s 56ms/step - loss: 0.9117 - classification_loss: 0.1083 - regression_loss: 0.8034 - classification_Precision: 0.7412 - classification_Recall: 0.7412 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 219: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 219/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9138 - classification_loss: 0.1083 - regression_loss: 0.8055 - classification_Precision: 0.7419 - classification_Recall: 0.7419 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 220: LearningRateScheduler setting learning rate to 0.0006648326359915007.\n",
      "Epoch 220/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9129 - classification_loss: 0.1080 - regression_loss: 0.8050 - classification_Precision: 0.7420 - classification_Recall: 0.7420 - lr: 6.6483e-04\n",
      "\n",
      "Epoch 221: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 221/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9121 - classification_loss: 0.1081 - regression_loss: 0.8041 - classification_Precision: 0.7417 - classification_Recall: 0.7417 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 222: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 222/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9111 - classification_loss: 0.1081 - regression_loss: 0.8030 - classification_Precision: 0.7415 - classification_Recall: 0.7415 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 223: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 223/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9115 - classification_loss: 0.1082 - regression_loss: 0.8032 - classification_Precision: 0.7412 - classification_Recall: 0.7412 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 224: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 224/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 0.9085 - classification_loss: 0.1077 - regression_loss: 0.8008 - classification_Precision: 0.7426 - classification_Recall: 0.7426 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 225: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 225/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9107 - classification_loss: 0.1080 - regression_loss: 0.8027 - classification_Precision: 0.7417 - classification_Recall: 0.7417 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 226: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 226/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9128 - classification_loss: 0.1079 - regression_loss: 0.8049 - classification_Precision: 0.7419 - classification_Recall: 0.7419 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 227: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 227/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9097 - classification_loss: 0.1079 - regression_loss: 0.8018 - classification_Precision: 0.7425 - classification_Recall: 0.7425 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 228: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 228/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9082 - classification_loss: 0.1076 - regression_loss: 0.8006 - classification_Precision: 0.7423 - classification_Recall: 0.7423 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 229: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 229/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9114 - classification_loss: 0.1078 - regression_loss: 0.8036 - classification_Precision: 0.7419 - classification_Recall: 0.7419 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 230: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 230/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9128 - classification_loss: 0.1077 - regression_loss: 0.8051 - classification_Precision: 0.7423 - classification_Recall: 0.7423 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 231: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 231/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9100 - classification_loss: 0.1076 - regression_loss: 0.8025 - classification_Precision: 0.7424 - classification_Recall: 0.7424 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 232: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 232/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9119 - classification_loss: 0.1077 - regression_loss: 0.8042 - classification_Precision: 0.7422 - classification_Recall: 0.7422 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 233: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 233/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9069 - classification_loss: 0.1073 - regression_loss: 0.7997 - classification_Precision: 0.7433 - classification_Recall: 0.7433 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 234: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 234/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 0.9042 - classification_loss: 0.1069 - regression_loss: 0.7974 - classification_Precision: 0.7437 - classification_Recall: 0.7437 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 235: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 235/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9120 - classification_loss: 0.1075 - regression_loss: 0.8045 - classification_Precision: 0.7427 - classification_Recall: 0.7427 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 236: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 236/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9097 - classification_loss: 0.1074 - regression_loss: 0.8023 - classification_Precision: 0.7427 - classification_Recall: 0.7427 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 237: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 237/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9065 - classification_loss: 0.1073 - regression_loss: 0.7992 - classification_Precision: 0.7431 - classification_Recall: 0.7431 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 238: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 238/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9096 - classification_loss: 0.1076 - regression_loss: 0.8020 - classification_Precision: 0.7427 - classification_Recall: 0.7427 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 239: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 239/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9098 - classification_loss: 0.1072 - regression_loss: 0.8025 - classification_Precision: 0.7431 - classification_Recall: 0.7431 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 240: LearningRateScheduler setting learning rate to 0.0006382393305518408.\n",
      "Epoch 240/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9068 - classification_loss: 0.1072 - regression_loss: 0.7996 - classification_Precision: 0.7430 - classification_Recall: 0.7430 - lr: 6.3824e-04\n",
      "\n",
      "Epoch 241: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 241/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.9038 - classification_loss: 0.1069 - regression_loss: 0.7970 - classification_Precision: 0.7436 - classification_Recall: 0.7436 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 242: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 242/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9073 - classification_loss: 0.1069 - regression_loss: 0.8003 - classification_Precision: 0.7440 - classification_Recall: 0.7440 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 243: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 243/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9077 - classification_loss: 0.1070 - regression_loss: 0.8007 - classification_Precision: 0.7430 - classification_Recall: 0.7430 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 244: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 244/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9022 - classification_loss: 0.1066 - regression_loss: 0.7956 - classification_Precision: 0.7445 - classification_Recall: 0.7445 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 245: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 245/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9046 - classification_loss: 0.1068 - regression_loss: 0.7978 - classification_Precision: 0.7441 - classification_Recall: 0.7441 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 246: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 246/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9032 - classification_loss: 0.1066 - regression_loss: 0.7966 - classification_Precision: 0.7446 - classification_Recall: 0.7446 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 247: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 247/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9053 - classification_loss: 0.1068 - regression_loss: 0.7984 - classification_Precision: 0.7440 - classification_Recall: 0.7440 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 248: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 248/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9071 - classification_loss: 0.1068 - regression_loss: 0.8003 - classification_Precision: 0.7438 - classification_Recall: 0.7438 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 249: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 249/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9050 - classification_loss: 0.1067 - regression_loss: 0.7983 - classification_Precision: 0.7437 - classification_Recall: 0.7437 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 250: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 250/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.9006 - classification_loss: 0.1062 - regression_loss: 0.7944 - classification_Precision: 0.7450 - classification_Recall: 0.7450 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 251: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 251/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9026 - classification_loss: 0.1064 - regression_loss: 0.7962 - classification_Precision: 0.7444 - classification_Recall: 0.7444 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 252: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 252/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9060 - classification_loss: 0.1066 - regression_loss: 0.7994 - classification_Precision: 0.7445 - classification_Recall: 0.7445 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 253: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 253/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9008 - classification_loss: 0.1061 - regression_loss: 0.7947 - classification_Precision: 0.7450 - classification_Recall: 0.7450 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 254: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 254/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9020 - classification_loss: 0.1061 - regression_loss: 0.7959 - classification_Precision: 0.7450 - classification_Recall: 0.7450 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 255: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 255/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.9032 - classification_loss: 0.1062 - regression_loss: 0.7970 - classification_Precision: 0.7450 - classification_Recall: 0.7450 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 256: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 256/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8993 - classification_loss: 0.1062 - regression_loss: 0.7932 - classification_Precision: 0.7450 - classification_Recall: 0.7450 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 257: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 257/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9001 - classification_loss: 0.1061 - regression_loss: 0.7939 - classification_Precision: 0.7454 - classification_Recall: 0.7454 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 258: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 258/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9033 - classification_loss: 0.1062 - regression_loss: 0.7971 - classification_Precision: 0.7449 - classification_Recall: 0.7449 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 259: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 259/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.9016 - classification_loss: 0.1062 - regression_loss: 0.7954 - classification_Precision: 0.7455 - classification_Recall: 0.7455 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 260: LearningRateScheduler setting learning rate to 0.0006127097573297671.\n",
      "Epoch 260/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8992 - classification_loss: 0.1059 - regression_loss: 0.7933 - classification_Precision: 0.7455 - classification_Recall: 0.7455 - lr: 6.1271e-04\n",
      "\n",
      "Epoch 261: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 261/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8989 - classification_loss: 0.1060 - regression_loss: 0.7929 - classification_Precision: 0.7456 - classification_Recall: 0.7456 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 262: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 262/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.8986 - classification_loss: 0.1058 - regression_loss: 0.7928 - classification_Precision: 0.7456 - classification_Recall: 0.7456 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 263: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 263/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8990 - classification_loss: 0.1055 - regression_loss: 0.7935 - classification_Precision: 0.7462 - classification_Recall: 0.7462 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 264: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 264/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8975 - classification_loss: 0.1056 - regression_loss: 0.7919 - classification_Precision: 0.7462 - classification_Recall: 0.7462 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 265: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 265/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8979 - classification_loss: 0.1058 - regression_loss: 0.7921 - classification_Precision: 0.7458 - classification_Recall: 0.7458 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 266: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 266/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.8985 - classification_loss: 0.1055 - regression_loss: 0.7930 - classification_Precision: 0.7465 - classification_Recall: 0.7465 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 267: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 267/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8958 - classification_loss: 0.1054 - regression_loss: 0.7904 - classification_Precision: 0.7465 - classification_Recall: 0.7465 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 268: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 268/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8967 - classification_loss: 0.1055 - regression_loss: 0.7913 - classification_Precision: 0.7466 - classification_Recall: 0.7466 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 269: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 269/300\n",
      "1204/1204 [==============================] - 70s 57ms/step - loss: 0.8977 - classification_loss: 0.1055 - regression_loss: 0.7922 - classification_Precision: 0.7464 - classification_Recall: 0.7464 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 270: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 270/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8979 - classification_loss: 0.1055 - regression_loss: 0.7924 - classification_Precision: 0.7461 - classification_Recall: 0.7461 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 271: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 271/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8951 - classification_loss: 0.1053 - regression_loss: 0.7898 - classification_Precision: 0.7469 - classification_Recall: 0.7469 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 272: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 272/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.8953 - classification_loss: 0.1051 - regression_loss: 0.7902 - classification_Precision: 0.7470 - classification_Recall: 0.7470 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 273: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 273/300\n",
      "1204/1204 [==============================] - 68s 57ms/step - loss: 0.8959 - classification_loss: 0.1054 - regression_loss: 0.7905 - classification_Precision: 0.7469 - classification_Recall: 0.7469 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 274: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 274/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8950 - classification_loss: 0.1051 - regression_loss: 0.7898 - classification_Precision: 0.7471 - classification_Recall: 0.7471 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 275: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 275/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8964 - classification_loss: 0.1051 - regression_loss: 0.7914 - classification_Precision: 0.7475 - classification_Recall: 0.7475 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 276: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 276/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8954 - classification_loss: 0.1049 - regression_loss: 0.7906 - classification_Precision: 0.7474 - classification_Recall: 0.7474 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 277: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 277/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8979 - classification_loss: 0.1051 - regression_loss: 0.7928 - classification_Precision: 0.7470 - classification_Recall: 0.7470 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 278: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 278/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8943 - classification_loss: 0.1049 - regression_loss: 0.7893 - classification_Precision: 0.7474 - classification_Recall: 0.7474 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 279: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 279/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8951 - classification_loss: 0.1051 - regression_loss: 0.7900 - classification_Precision: 0.7472 - classification_Recall: 0.7472 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 280: LearningRateScheduler setting learning rate to 0.0005882013670365765.\n",
      "Epoch 280/300\n",
      "1204/1204 [==============================] - 67s 56ms/step - loss: 0.8949 - classification_loss: 0.1049 - regression_loss: 0.7900 - classification_Precision: 0.7477 - classification_Recall: 0.7477 - lr: 5.8820e-04\n",
      "\n",
      "Epoch 281: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 281/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8940 - classification_loss: 0.1048 - regression_loss: 0.7891 - classification_Precision: 0.7475 - classification_Recall: 0.7475 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 282: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 282/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8938 - classification_loss: 0.1047 - regression_loss: 0.7891 - classification_Precision: 0.7478 - classification_Recall: 0.7478 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 283: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 283/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8939 - classification_loss: 0.1047 - regression_loss: 0.7892 - classification_Precision: 0.7476 - classification_Recall: 0.7476 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 284: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 284/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8944 - classification_loss: 0.1048 - regression_loss: 0.7896 - classification_Precision: 0.7480 - classification_Recall: 0.7480 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 285: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 285/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8921 - classification_loss: 0.1043 - regression_loss: 0.7877 - classification_Precision: 0.7484 - classification_Recall: 0.7484 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 286: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 286/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8937 - classification_loss: 0.1048 - regression_loss: 0.7889 - classification_Precision: 0.7476 - classification_Recall: 0.7476 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 287: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 287/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8925 - classification_loss: 0.1045 - regression_loss: 0.7880 - classification_Precision: 0.7487 - classification_Recall: 0.7487 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 288: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 288/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8940 - classification_loss: 0.1045 - regression_loss: 0.7895 - classification_Precision: 0.7482 - classification_Recall: 0.7482 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 289: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 289/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8913 - classification_loss: 0.1043 - regression_loss: 0.7870 - classification_Precision: 0.7483 - classification_Recall: 0.7483 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 290: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 290/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8915 - classification_loss: 0.1043 - regression_loss: 0.7872 - classification_Precision: 0.7483 - classification_Recall: 0.7483 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 291: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 291/300\n",
      "1204/1204 [==============================] - 67s 56ms/step - loss: 0.8929 - classification_loss: 0.1044 - regression_loss: 0.7884 - classification_Precision: 0.7480 - classification_Recall: 0.7480 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 292: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 292/300\n",
      "1204/1204 [==============================] - 67s 56ms/step - loss: 0.8914 - classification_loss: 0.1043 - regression_loss: 0.7871 - classification_Precision: 0.7486 - classification_Recall: 0.7486 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 293: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 293/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8924 - classification_loss: 0.1043 - regression_loss: 0.7881 - classification_Precision: 0.7487 - classification_Recall: 0.7487 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 294: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 294/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8905 - classification_loss: 0.1041 - regression_loss: 0.7864 - classification_Precision: 0.7493 - classification_Recall: 0.7493 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 295: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 295/300\n",
      "1204/1204 [==============================] - 68s 56ms/step - loss: 0.8898 - classification_loss: 0.1041 - regression_loss: 0.7856 - classification_Precision: 0.7490 - classification_Recall: 0.7490 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 296: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 296/300\n",
      "1204/1204 [==============================] - 66s 55ms/step - loss: 0.8895 - classification_loss: 0.1041 - regression_loss: 0.7855 - classification_Precision: 0.7491 - classification_Recall: 0.7491 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 297: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 297/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8916 - classification_loss: 0.1040 - regression_loss: 0.7876 - classification_Precision: 0.7489 - classification_Recall: 0.7489 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 298: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 298/300\n",
      "1204/1204 [==============================] - 70s 58ms/step - loss: 0.8922 - classification_loss: 0.1042 - regression_loss: 0.7880 - classification_Precision: 0.7486 - classification_Recall: 0.7486 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 299: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 299/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8896 - classification_loss: 0.1040 - regression_loss: 0.7856 - classification_Precision: 0.7491 - classification_Recall: 0.7491 - lr: 5.6467e-04\n",
      "\n",
      "Epoch 300: LearningRateScheduler setting learning rate to 0.0005646733123551134.\n",
      "Epoch 300/300\n",
      "1204/1204 [==============================] - 69s 57ms/step - loss: 0.8897 - classification_loss: 0.1040 - regression_loss: 0.7857 - classification_Precision: 0.7490 - classification_Recall: 0.7490 - lr: 5.6467e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe32c041100>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 300\n",
    "model.fit(train_dataset,\n",
    "          epochs=epochs,\n",
    "          callbacks=[lr_callback],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3888922174.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[63], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    q!\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (1, 24, 32, 1)\n",
      "Images max: 255.0\n",
      "Images min: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 가정: train_dataset은 이미 tf.data.Dataset 객체로 생성되어 있음\n",
    "# new_batch_size = 9\n",
    "\n",
    "# # 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "# val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "# val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, _, _ in val_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2AAAANuCAYAAABwmGrUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAo20lEQVR4nO3de4zdB3nn4ffMOXM7M45nxnbwOM7FTki4hAQ3S4Cmq1I1LVGLWtpVkSq0Udquki5NGy3QPyq1UhGFbVdQSmFb0Y0IqFUFu1W6m2orthcuK0iAVQLEIMhCAnEc4suMPZ775Zw5+0eIVW+ddjLmfSfTPI8UjX005zu/md+5zGeOYzd6vV4vAAAASNe31QcAAADwQiHAAAAAirT+/wvOnDkTi4uLW3Es5drtduzcuXOrDwMAAHiBOCfAzpw5Ex/84DtjbW1qq46nVH//7rjzzt8SYQAAQIlzAmxxcTHW1qbiZ392OPbsaW/VMZU4eXIx7r13KhYXFwUYAABQ4h/9EcSIiD172jE5uaP6WLbA0lYfAAAA8ALiL+EAAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACiypQHW7a7H+npvKw8BAACgzHMKsNe97iNx551/HXfe+dexc+fvxu7d/yl+67c+Gb3e0xG1stKJt7/9b+KSS34/RkbeHa9+9d3x6U9/5+z1P/KRL8fY2O/Gffc9Ei972X+OwcHfiSNHzsSnP/2duPHG/xIjI++OsbHfjZtu+nA8/vjM2ev98R//n7jyyj+MgYF3xjXXfDD+9E+/cs5xNRrviLvvfih+5mc+Hu32u+LFL/5A3HffI5v/qgAAACR4zq+AffSjX4lWqy+++MV/F+9//y3x+7//+bj77ociIuLOO/86HnjgaHzsY/8mHn74l+Pnfu5lccstfxbf/Ob02esvLq7F7/3e5+Luu38qvva1t8TExHC88Y0fix/+4cvj4Yd/OR544Jfi9tt/IBqNRkRE/OVffj3uuusT8ba3vTa++tW3xB133BC/8Av/Iz71qW+fc1zveMdn4k1velk8/PC/j5/4iavizW++N06d8u98AQAAzx/n/YeY/ymXXnpRvO99r49GoxHXXLM7Dh8+Ee973+fj9a+/Ku6558tx5Mh/iH37nv5HnN/+9h+MT3ziW3HPPV+Od7/7RyMiYm1tPf7oj34irr9+b0REnDq1FGfOrMQb3nB1XHnlREREvPSle85+vPe854G47bZXxlve8qqIiHjrW18bn//80XjPex6IH/mRA2ff77bbro+f//lXRETEu9/9o/GHf/jF+OIXn4xbbrlqM18XAACA77vnHGCvec3+s69ORUS89rX7473vfSAOHz4e3W4vrr76A+e8/8pKN3btap/9/cBAM6677kVnfz8xMRy33fbKeP3r/yx+7MeujJtvPhBvetPLY3Ly6Yj7+tdPxu23/8A5mzfddGm8//1fOOeyf7g5MjIQF100GCdOLDzXTw8AACDNcw6wZzM/vxrNZiMefPD2aDbP/ZONo6MDZ389PNw6J+AiIu6556fj137txvjEJ74VH//41+I3f/NT8bd/+2/jNa/Zv+GP39/fPOf3jUb4Cz4AAIDnlef8/4B94QtPnvP7z3/+aLz4xRNx6NBkdLu9OHFiIa66auKc//buHf1ndw8dmozf+I1/Hfff/0tx7bUXx5//+eGIePqPI37uc0+c876f+9wT8bKX7TnfDAAAwPPWc34F7MiRM/HWt/6vuOOOG+Khh56KD3zgi/He9/54XH31rnjzm18Rt9763+O97/3xOHRob5w8uRh///ePxXXXvSh+8ievPu/et799Ov7kTx6Mn/qpa2Lfvh3xyCPT8c1vTsett14XERG//us/GG9603+LQ4f2xs03H4y/+qv/G/fe+/X4u7+79cI+cwAAgGLPOcBuvfW6WFpaixtvvDuazUbcdder4/bbb4iIp/8o4e/8zv+Ot73tb+LJJ2dj9+52vOY1++MNbzh/fEVEtNv98Y1vTMdHP/pfY3p6KSYnR+NXfuVVcccd/yoiIt74xpfE+99/S7znPQ/EXXd9Ig4cGI977vnpeN3rrtjcZwwAALBFGr1n/hGviHjqqafiQx/6jbjjjl1n/xKMf+h1r/tIvPKVe+MP/uCW0oPM8NRTc/GhD03HHXf8x5icnNzqwwEAAF4AnvP/AwYAAMDmCDAAAIAiz+n/Afv0p29LOgwAAIB/+bwCBgAAUESAAQAAFBFgAAAARQQYAABAkfP+JRwnTy5WH0e5F8LnCAAAPL+cE2Dtdjv6+3fHvfdORcTSFh1Snf7+3dFut7f6MAAAgBeIRq/X6/3DC86cOROLiy+MV4fa7Xbs3Llzqw8DAAB4gfhHAQYAAEAOfwkHAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQpLXVB7Cd/eqv/mrq/srKSur+6Oho6n5ExPr6eur+7Oxs6v4VV1yRun/48OHU/YiIdruduv+Vr3wldf/gwYOp+0899VTq/vLycup+RMQTTzyRun/JJZek7p85c+a8l798ZSX+57Fj8ZN798bXBgc3vd9sNjd93Y3odrup+xH5n0P2Y/XIyMi23o+IOHr0aOr+vn37Uvc7nU7q/tDQUOr+1NRU6n5ExIEDB1L3H3vssdT9RqORut/r9VL3IyJuvPHG1P3s2+mHP/zhDb2fV8AAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIq2tPoDt7PTp06n7s7OzqfutVv7pf8lLXpK6Pzk5mbp/6NCh1P2ZmZnU/YqPMTo6mrq/sLCQul9xDrLt2LEjdf/UqVOp+91u97yXdzqds29XG41N7y8uLm76uhuR/fWPiFhaWkrdbzabqfvPnEue3draWup+9nP+6upq6v7FF1+cuh8Rcfz48dT97HOwb9++1P0vfelLqfsREZ/5zGdS93/xF38xdX+jvAIGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARVpbfQDbWbvdTt1/8MEHU/dvuOGG1P2IiPHx8dT9u+66K3W/2+2m7k9OTqbuR0R85zvfSd1/6KGHUvePHTuWun/kyJHU/QojIyOp+ydPnkzd37dv33kvn1hcjJiaiomJiXjRBTzezs/Pb/q6G9Fq5T+Vnj59OnV/cHAwdT/7HAwMDKTuR0T09eX+zHpubi51P/t7luzHoUceeSR1PyLiwIEDqfsHDx5M3f/Sl76Uur9///7U/YiISy+9NHX/L/7iL1L33/nOd27o/bwCBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQJHWVh/AdjY8PJy6PzExsa33IyKefPLJ1P0TJ06k7i8sLKTuDw0Npe5XOHToUOr+kSNHUvc/+9nPpu5XyL6fLS4upu5ffPHF57282+2efdvpdDa9fyHX3YjBwcHU/YiItbW11P0dO3ak7mdrNBrpH2NgYCB1f2VlJXW/ry/3Z+7Zt9FLL700dT8i/7E0+7Hoh37oh1L3v/rVr6buR0Q8+OCDqftXXXVV6v5GeQUMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAirS2+gC2s2984xup+5deemnq/unTp1P3IyJmZmZS93/7t387df+mm25K3d+xY0fqfkTE/Px86v7NN9+cun/ttdem7j/yyCOp+6urq6n7ERH33Xdf6v7o6Gjqfqt1/qeiZrN59u2zvc9GrK+vb/q6G3H8+PHU/YiI2dnZ1P3sx6Jer5e6/8xtJVNfX+7PrLNvp9nHfyH30Y3IPv6IiMsvvzx1/8iRI6n709PTqfvZt9GIiBtuuCF1/4knnkjd3yivgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAECR1lYfwHa2uLiYur+2tpa6v2PHjtT9CqdOnUrdv//++1P3X/WqV6XuR0Rcf/31qftjY2Op++12O3X/mmuuSd0/efJk6n5ExOnTp1P3d+3albo/MzNz3svnVlaefjs3FzOrq5veX1hY2PR1N6LT6aTuR0T09/en7vd6vdT97OPP3o/IP89DQ0Op+9nn+OUvf3nq/he+8IXU/YiIpaWl1P2JiYnU/d27d6fuf/azn03dj4gYHR1N3X++fO/rFTAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAo0trqA9jO9u3bl7r/rW99K3V/z549qfsVLrnkktT9T37yk6n7IyMjqfsREaOjo6n7hw4dSt3v68v9OdE111yTut9sNlP3IyLGx8dT99vtdup+q3X+p6LBZ94ODsbQ0ND3ff/7ZXZ2NnU/Iv8c9Hq91P1Go5G63+l0UvcjIpaWllL3JyYmUvezv0bLy8up+wcOHEjdj4g4fPhw6v7c3Fzq/mWXXZa6f8UVV6TuR0R0u93U/UcffTR1f6O8AgYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAECR1lYfwHY2MzOTur9r167U/QqDg4Op+9nnYPfu3an7x44dS92PiPjUpz6Vun/11Ven7mffhhqNRup+s9lM3Y+IuOiii1L3l5aWUvcXFhbOe/n82trTb+fn48zKyqb3V1dXN33d58N+RES73U7dn5ubS93v9Xqp+wMDA6n7ERHLy8up+yMjI6n7KxdwH9qI7OPP/vpH5N+Osr+nOH78eOp+hZ07d6buZz+fbZRXwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKBIa6sPYDtrt9tbfQgXZHZ2Nv1jNJvN1P3HH388dX/nzp2p+ydOnEjdj4hYWFhI3X/Xu96Vuj85OZm6f9lll6Xuj4+Pp+5HRDQajdT9bre7JfvPXN7tdqPbt/mfF46MjGz6uhuR/fWJiOh0Oqn7AwMDqfvZzwUVJiYmUveXl5dT91ut3G/5sp9rpqamUvcjIl70ohel7mffj8fGxlL3V1ZWUvcj8p/PLr/88tT9jfIKGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABRpbfUBbGcrKyup+51OZ1vvR0Ssra2l7i8vL2/r/WazmbofEdFoNFL32+126v78/HzqfrfbTd3PPv6IiP7+/tT9gYGB1P1nO/7Bvqd/Rjg4OBjDg4Ob3l9fX9/0dTei4n6c/TGyHyey9Xq99I+RfTvKfr7MduTIkdT92dnZ1P2I/Me6bBXf12XLfqxrtZ4f6eMVMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACjS2uoD2M663W7q/tLSUur+4OBg6n5ERKfTSd0fHR1N3Z+fn0/dbzQaqfsREcvLy6n76+vrqfunTp1K3c8+x0NDQ6n7ERHT09Op+2tra6n7Y2Nj57289b3H2FarFf39/Zvez34cupBj26her2f/n5D9OBQRsbq6mrqf/Tm0Wrnf8k1MTKTuN5vN1P2I/Ofk7Ofj7P3sx9KI/M8h+3v3jfIKGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEVaW30A29l3v/vd1P35+fnU/Z07d6buR0QsLCyk7g8NDaXudzqd1P1WK/8umP05jI6Opu7Pzc2l7s/MzKTur66upu5HRKyvr6fur6yspO73er3vy/s8m+xz0Gw2U/cjItbW1lL3u91u6n6j0Ujdzz7+iPz7WfbnkP1c8Pjjj6fuZ3/9I/Jvp9mfQ/b3RCMjI6n7ERHDw8Pben+jvAIGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARVpbfQDb2c6dO1P3W63c0zM6Opq6H5H/OQwNDaXu/0s4BwMDA6n7KysrqfvNZjN1P/t+vLa2lrofETE+Pp66f+zYsdT9bEtLS6n7IyMjqfsREevr69t6v9frpe5X6Ha7qfvb/RxPTk6m7lc8li4sLKTuZ98Psvc7nU7qfkTE1NRU6n72/WCjvAIGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARVpbfQDbWbfbTd3v9Xqp+0tLS6n7ERErKyup+wsLC6n7y8vLqfvz8/Op+xERi4uLqfs7duxI3W82m6n7nU4ndT/7cSIiYnBwMHV/aGgodb+/v/+8l7e+97VrtVrP+j4bMTo6uunrPl9kPx9k7zcajdT9vr7t//Pk7X4OTpw4kbqf/fWJiFhfX0/d37NnT+p+9vPl8PBw6n5Ezfemzwfb/xELAABgmxBgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQJHWVh/AdtbXl9uvQ0NDqfsVhoeHU/dnZmZS90dHR1P3O51O6n5E/u2ov78/dX9lZSV1f3p6OnW/2+2m7kdEDA4Opu5nfw7NZvO8l6+vr599+8yvNyP767O6upq6X6HRaKTut1q5325kPw5F1NyXMz3b/ez7Jft7orW1tdT9iPznm+zn/NnZ2dT906dPp+5HRMzPz6fuZ39fulFeAQMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKBIa6sPYDs7duxY6n5/f3/qfqPRSN2PiJiYmEjdX15eTt0fHR1N3e90Oqn7Efm3o16vl7qfrdvtpu43m83U/YqPkX2OFxcXz3v58urq02+Xl2NxfX3T+6vf28nSbrdT9yPyH6+z97Nvo61W/rczfX25P7Nev4Db+EYMDAyk7mfLfqyuUPF8kKniNjQ+Pp66v2/fvtT9jfIKGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABRpbfUBbGf79+9P3T916lTq/tzcXOp+RMSJEydS96+99trU/fvvvz91f3h4OHU/IqLb7abuLy0tpe7v2bMndb/ifpBteno6dT/7drq2tnbeyzudztm3a43Gpvf37du36etuxOjoaOp+RMTMzEzq/rFjx1L3+/v7U/dnZ2dT9yNqHq8zjY2Npe4//vjjqfsVX//s7+seffTR1P3LLrssdX9kZCR1PyJicXExdf/58pzvFTAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAo0trqA9jOms1m6v7OnTtT91ut/NO/tLSUuv/tb387dX96ejp1f9++fan7ERFDQ0Op+319uT/HWVtbS90fHh5O3V9eXk7dj4gYGBhI3Z+ZmUndf7bb0Gq3+/Tb1dVY/t6vN2NqamrT192I7PtYRESv10vdz34+azQaqfvZj0MR+edgfX09dX9lZSV1P/uxdHZ2NnU/ImLv3r2p+9dff33q/p49e1L3H3744dT9iKcf7zPt378/dX+jvAIGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARVpbfQDbWV9fbr8ODAyk7jcajdT9iIiRkZHU/ZWVldT9AwcOpO6Pjo6m7kdEzMzMpO5nn4PZ2dnU/csvvzx1f2xsLHU/ImJoaCh1/+jRo6n7z3b8u5eXI+bnY/fu3TF5AZ/j+vr6pq+7EZ1OJ3W/wuDgYOp+q5X77Ub2faBC9u00+7E6+7lm7969qfsREePj46n7Dz74YOr+1NRU6n63203dj8h/LPryl7+cur9RXgEDAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgSGurD2A7m56e3upDuCCtVv7p7+vLbfyZmZnU/eyv0draWup+RP7X6ODBg6n7R44cSd0/ffp06n7F/Wx1dTV1/8yZM6n7u3btOu/lKysrZ98uX8B+9jk4efJk6n5ExPLyhXwF/nnZj0Xdbndb70ds/3MwPz+fuj82Npa6f/z48dT9iPzHina7nbp/4MCB1P2nnnoqdT8iYnx8PHW/2Wym7m+UV8AAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgSGurD2A7u+SSS1L3m81m6v7IyEjqfkTEqVOntvV+q5V7F7noootS9yMiduzYkbo/NDSUur9r167U/WyTk5PpH2Nqaip1f2xsLHX/2bS/9xjYbrdjdHh40zvZ9+Ps/YiI1dXV1P3t/jXq68v/efL8/HzqfqfTSd3v9Xqp+9nneHR0NHU/ImJiYiJ1P/scz83Npe4vLy+n7kdEnD59OnX/yJEjqfsb5RUwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKNLa6gPYzlZWVlL35+fnU/fHx8dT9yPyP4exsbHU/Wyrq6vpH6PVyr2bHz16NHV/eXk5dX9tbS11v+J+lm1oaCh1f25u7ryXdzqds2+zz9OF6PV66R+j2+2m7g8MDKTur6+vp+5nH39ERLPZTN3v68v9mXj2801/f3/q/rM9Tnw/LS4upu5fffXVqfvZt9Hs5+OIiP3796fuX3fddan7G+UVMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACgiwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACKCDAAAIAiAgwAAKCIAAMAACjS2uoD2M76+nL7dWZmJnW/1co//d1uN3X/pS99aer+qVOnUvdPnz6duh8RMTAwkLr/ile8InV/dnY2df/o0aOp+ydOnEjdj8g/x51OJ3V/eHj4vJcP9npPvx0cfNb32YiRkZFNX3cjFhYWUvcjIhqNRup+9vPB+vp66v6F3D42anV1NXU/+3uK7HOc/Vh95ZVXpu5H5J/j7373u6n7U1NTqfsHDhxI3Y+IGB0dTd1/9NFHU/c3yitgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFGlt9QFsZ6urq6n7y8vL23o/IuLUqVOp++Pj46n7jz32WOp+t9tN3Y+IOHjwYOr+4cOHU/eHhoZS94eHh1P3+/v7U/cj8s/x9PR06v7c3Nx5L19fXz/79plfb8bx48c3fd2NuJBj26i1tbX0j5Ep+/myry//58mzs7Op+9mPdUtLS6n7e/fuTd2fmZlJ3Y/IP8c33nhj6v7JkydT9ytkn4Ps5/yN8goYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFBFgAAAARQQYAABAEQEGAABQRIABAAAUEWAAAABFBBgAAEARAQYAAFBEgAEAABQRYAAAAEUEGAAAQBEBBgAAUESAAQAAFGn0er3eVh8EAADAC4FXwAAAAIoIMAAAgCICDAAAoIgAAwAAKCLAAAAAiggwAACAIgIMAACgiAADAAAoIsAAAACK/D9nb3RC4cDs6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.5, top_n=100):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i in range(len(predictions)):\n",
    "        reg_prediction = predictions[i][:4]\n",
    "        cls_prediction = predictions[i][4:]\n",
    "        max_score = tf.reduce_max(cls_prediction)\n",
    "        if max_score > score_threshold:\n",
    "            class_index = tf.argmax(cls_prediction)\n",
    "            scores.append((max_score, i, class_index))\n",
    "    \n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "    \n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i, j = scores.pop(0)\n",
    "        reg_prediction = predictions[i][:4]\n",
    "        dx, dy, dw, dh = reg_prediction\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "    \n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        x_min, y_min, x_max, y_max = x_min.numpy()[0], y_min.numpy()[0], x_max.numpy()[0], y_max.numpy()[0]\n",
    "        x_min, y_min, x_max, y_max = float(x_min), float(y_min), float(x_max), float(y_max)\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(1):\n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0)) # 첫 번째 이미지에 대한 예측 결과\n",
    "    predictions = tf.concat([predictions['regression'], predictions['classification']], axis=-1)\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    # print(np.array(decoded_boxes).shape)\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePredictions(tf.keras.layers.Layer):\n",
    "    def __init__(self, confidence_threshold=0.9, iou_threshold=0.5, top_k=100, num_classes=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.top_k = top_k\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def call(self, inputs):\n",
    "        predictions = inputs\n",
    "\n",
    "        # 앵커 박스 생성\n",
    "        anchor_box = AnchorBox()\n",
    "        anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "        # 스코어 필터링\n",
    "        scores = predictions[..., -1]\n",
    "        score_mask = scores > self.confidence_threshold\n",
    "        filtered_predictions = tf.boolean_mask(predictions, score_mask)\n",
    "        filtered_anchors = tf.boolean_mask(anchors, tf.reshape(score_mask, [-1]))\n",
    "\n",
    "        # NMS 적용\n",
    "        boxes = self.decode_boxes(filtered_predictions, filtered_anchors)\n",
    "        nms_indices = tf.image.non_max_suppression(boxes, tf.boolean_mask(scores, score_mask), max_output_size=self.top_k, iou_threshold=self.iou_threshold)\n",
    "        decoded_boxes = tf.gather(boxes, nms_indices)\n",
    "        decoded_scores = tf.gather(tf.boolean_mask(scores, score_mask), nms_indices)\n",
    "\n",
    "        # 바운딩 박스와 스코어 합치기\n",
    "        decoded_predictions = tf.concat([decoded_boxes, tf.expand_dims(decoded_scores, axis=-1)], axis=-1)\n",
    "\n",
    "        return decoded_predictions\n",
    "\n",
    "    def decode_boxes(self, predictions, anchors):\n",
    "        box_variance = [0.1, 0.1, 0.2, 0.2]\n",
    "        dx = predictions[..., 0]\n",
    "        dy = predictions[..., 1]\n",
    "        dw = predictions[..., 2]\n",
    "        dh = predictions[..., 3]\n",
    "        anchor_x = anchors[..., 0]\n",
    "        anchor_y = anchors[..., 1]\n",
    "        anchor_w = anchors[..., 2]\n",
    "        anchor_h = anchors[..., 3]\n",
    "\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = tf.exp(dh * box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 모델 생성\n",
    "image = tf.keras.Input(shape=[24, 32, 1], name=\"image\")\n",
    "predictions = model(image, training=False)\n",
    "detections = DecodePredictions(confidence_threshold=0.5)(predictions)\n",
    "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(1):    \n",
    "    predictions = inference_model.predict(tf.expand_dims(img[0], axis=0))  # 첫 번째 이미지에 대한 예측 결과\n",
    "    print(predictions)\n",
    "    draw_bounding_boxes(img[0].numpy(), predictions, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "custom_objects = {\n",
    "    'DepthwiseSeparableConv': DepthwiseSeparableConv,\n",
    "    'DepthwiseConv': DepthwiseConv,\n",
    "    'Conv': Conv,\n",
    "    'Bottleneck': Bottleneck,\n",
    "    'CSPDenseLayer': CSPDenseLayer,\n",
    "    'ChannelAttention': ChannelAttention,\n",
    "    'SpatialAttention': SpatialAttention,\n",
    "    'CBAM': CBAM,\n",
    "    'SPPF': SPPFast,\n",
    "    'BackBone': BackBone,\n",
    "    'NeckLayer': NeckLayer,\n",
    "    'HeadLayer': HeadLayer,\n",
    "    'CustomModel': CustomModel,\n",
    "    'DecodePredictions': DecodePredictions\n",
    "}\n",
    "\n",
    "export_path = 'ObjectDetection/model_v6_backup_plan'\n",
    "inference_model.save(export_path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "custom_objects = {\n",
    "    'DepthwiseSeparableConv': DepthwiseSeparableConv,\n",
    "    'DepthwiseConv': DepthwiseConv,\n",
    "    'Conv': Conv,\n",
    "    'Bottleneck': Bottleneck,\n",
    "    'CSPDenseLayer': CSPDenseLayer,\n",
    "    'ChannelAttention': ChannelAttention,\n",
    "    'SpatialAttention': SpatialAttention,\n",
    "    'CBAM': CBAM,\n",
    "    'SPPF': SPPFast,\n",
    "    'BackBone': BackBone,\n",
    "    'NeckLayer': NeckLayer,\n",
    "    'HeadLayer': HeadLayer,\n",
    "    'CustomModel': CustomModel,\n",
    "    'DecodePredictions': DecodePredictions\n",
    "}\n",
    "\n",
    "export_path = 'ObjectDetection/model_v6_backup_plan'\n",
    "loaded_model = tf.keras.models.load_model(export_path, custom_objects=custom_objects, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(1):    \n",
    "    predictions = loaded_model.predict(tf.expand_dims(img[0], axis=0))  # 첫 번째 이미지에 대한 예측 결과\n",
    "    print(predictions)\n",
    "    draw_bounding_boxes(img[0].numpy(), predictions, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_dir = 'ObjectDetection/model_v6_backup_plan'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# 입력과 출력의 데이터 타입을 설정\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open('ObjectDetection/tflite/model_v6_backup_plan.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Lite 모델 로드\n",
    "tflite_model_path = 'ObjectDetection/tflite/model_v6_backup_plan.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "for img, _, _ in val_dataset.take(50):\n",
    "    # 입력 이미지 전처리\n",
    "    input_data = tf.expand_dims(img[0], axis=0)\n",
    "    input_data = input_data.numpy()\n",
    "    \n",
    "    # 모델 추론\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(predictions)\n",
    "    predictions[:, -1]\n",
    "    \n",
    "    scores = predictions[:, -1]\n",
    "\n",
    "    # scores가 0.5 이상인 인덱스를 찾습니다.\n",
    "    indices = tf.where(scores >= 0.5)\n",
    "\n",
    "    # 해당 인덱스에 해당하는 predictions만 필터링합니다.\n",
    "    filtered_predictions = tf.gather(predictions, indices[:, 0])\n",
    "\n",
    "    # 결과 후처리 및 시각화\n",
    "    draw_bounding_boxes(img[0].numpy(), filtered_predictions, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q! 이거 봐라 개쩔꺼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def iou(box1, box2):\n",
    "#     x1, y1, x2, y2 = box1\n",
    "#     x3, y3, x4, y4 = box2\n",
    "    \n",
    "#     x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "#     y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    \n",
    "#     intersection = x_overlap * y_overlap\n",
    "#     area1 = (x2 - x1) * (y2 - y1)\n",
    "#     area2 = (x4 - x3) * (y4 - y3)\n",
    "#     union = area1 + area2 - intersection\n",
    "    \n",
    "#     return intersection / union\n",
    "\n",
    "# def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.9, top_n=9000):\n",
    "#     decoded_boxes = []\n",
    "#     scores = []\n",
    "    \n",
    "#     for i, prediction in enumerate(predictions):\n",
    "#         score = prediction[-1]\n",
    "#         if score > score_threshold:\n",
    "#             scores.append((score, i))\n",
    "    \n",
    "#     # 점수에 따라 내림차순 정렬\n",
    "#     scores.sort(reverse=True)\n",
    "    \n",
    "#     # 상위 N개 선택\n",
    "#     scores = scores[:top_n]\n",
    "    \n",
    "#     # NMS 적용\n",
    "#     for score, i in scores:\n",
    "#         prediction = predictions[i]\n",
    "#         dx, dy, dw, dh = prediction[:4]\n",
    "#         anchor = anchors[i]\n",
    "#         anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        \n",
    "#         cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "#         width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "#         height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        \n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         decoded_box = [x_min, y_min, x_min + width, y_min + height]\n",
    "        \n",
    "#         keep = True\n",
    "#         for other_box in decoded_boxes:\n",
    "#             if iou(decoded_box, other_box) >= iou_threshold:\n",
    "#                 keep = False\n",
    "#                 break\n",
    "        \n",
    "#         if keep:\n",
    "#             decoded_boxes.append(decoded_box)\n",
    "    \n",
    "#     return decoded_boxes\n",
    "\n",
    "# def draw_bounding_boxes(image, boxes):\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     plt.imshow(image)\n",
    "#     ax = plt.gca()\n",
    "#     for box in boxes:\n",
    "#         x_min, y_min, x_max, y_max = box\n",
    "#         rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "# for img, _, _ in val_dataset:    \n",
    "#     predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "#     decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "#     draw_bounding_boxes(img[0].numpy(), decoded_boxes)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    \n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    \n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.9, top_n=9000):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "    \n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "    \n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "    \n",
    "    # NMS 적용\n",
    "    for score, i in scores:\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        \n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        \n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height]\n",
    "        \n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box, other_box) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        \n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "    \n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, save_path=None):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "for i, (img, _, _) in enumerate(val_dataset):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    save_path = f\"prediction_img/output_{i}.png\"  # 이미지 저장 경로 지정\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, save_path=save_path)  # 디코딩된 바운딩 박스를 이미지에 그리고 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
