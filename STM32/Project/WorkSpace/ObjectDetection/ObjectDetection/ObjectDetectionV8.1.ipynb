{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 10:35:34.833006: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-19 10:35:34.869381: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-19 10:35:34.869411: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-19 10:35:34.869433: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-19 10:35:34.876506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-19 10:35:35.566042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 10:35:37.056767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 22198 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.057641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:1 with 22198 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.058291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:2 with 22198 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.058973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:3 with 22198 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.059657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:4 with 22198 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.060314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:5 with 22198 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.060973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:6 with 22198 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 11755414000435609343\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8392404693956173022\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1263123768246476716\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 2144165316,\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14280154689295566272\n",
       " physical_device_desc: \"device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1651660799,\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1215896689005264885\n",
       " physical_device_desc: \"device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 878896533,\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15733022138843502904\n",
       " physical_device_desc: \"device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 615190153,\n",
       " name: \"/device:GPU:5\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 296526323768596889\n",
       " physical_device_desc: \"device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1769886423,\n",
       " name: \"/device:GPU:6\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23277207552\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 4301976896118646234\n",
       " physical_device_desc: \"device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 893286608]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # 사용할 GPU를 설정 (여기서는 GPU 0번만 사용)\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # GPU 0만 TensorFlow에서 사용하도록 설정\n",
    "#         tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "#         # GPU 메모리 성장 허용 설정\n",
    "#         tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "#     except RuntimeError as e:\n",
    "#         # GPU가 이미 사용 중이라면 예외 발생\n",
    "#         print(e)\n",
    "        \n",
    "# # TensorFlow가 실제로 GPU를 사용하는지 확인하기 위한 간단한 테스트\n",
    "# tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17820, 24, 32, 1) (17820,) (17820, 4, 4) 17820\n",
      "255 0\n",
      "(16824, 24, 32, 1)\n",
      "(16824, 4, 4)\n",
      "16824\n",
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 0)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 10:35:37.182312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22198 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "24\n",
      "32\n",
      "bbox:  tf.Tensor(\n",
      "[[11  0 20  4]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]], shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 10:35:37.182518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22198 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.182703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22198 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.182887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 22198 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.183070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 22198 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.183272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 22198 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-19 10:35:37.183461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 22198 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SIZE_WIDTH:   32\n",
      "IMG_SIZE_HEIGHT:  24\n",
      "N_DATA:           16824\n",
      "N_TRAIN:          15142\n",
      "N_VAL:            1682\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.1)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16824, 24, 32, 1)\n",
      "(16824, 4, 4)\n",
      "(16824, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "    \n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    \n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[[0.78125    0.         1.         0.29166666]\n",
      "  [0.65625    0.20833333 1.         0.5       ]\n",
      "  [0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.        ]]], shape=(1, 4, 4), dtype=float32)\n",
      "tf.Tensor([[1 1 0 0]], shape=(1, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "15142\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "for _, _, _ in val_dataset:\n",
    "    val += 1\n",
    "print(val)\n",
    "\n",
    "\n",
    "train = 0\n",
    "for _, _, _ in train_dataset:\n",
    "    train += 1\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.125      0.45833334 0.34375    0.7916667 ]\n",
      " [0.34375    0.45833334 0.5625     0.75      ]\n",
      " [0.4375     0.625      0.6875     1.        ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0] * RES_WIDTH,\n",
    "    \t bbox[:,1] * RES_HEIGHT,\n",
    "    \t bbox[:,2] * RES_WIDTH,\n",
    "    \t bbox[:,3] * RES_HEIGHT\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.421875   0.6041667  0.28125    0.37500003]\n",
      " [0.09375    0.8541666  0.1875     0.2916667 ]\n",
      " [0.109375   0.4375     0.21875    0.29166666]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(249.0, shape=(), dtype=float32) tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.28125    0.4166667  0.28125    0.37500003]\n",
      " [0.         0.70833325 0.1875     0.2916667 ]\n",
      " [0.         0.2916667  0.21875    0.29166666]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.28125    0.4166667  0.28125    0.37500003], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.         0.70833325 0.1875     0.2916667 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.         0.2916667  0.21875    0.29166666], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.734375   0.6041666  0.34375    0.4583333 ]\n",
      " [0.171875   0.625      0.34375    0.33333334]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n",
      "tf.Tensor(243.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.5625     0.37499997 0.34375    0.4583333 ]\n",
      " [0.         0.4583333  0.34375    0.33333334]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.5625     0.37499997 0.34375    0.4583333 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.         0.4583333  0.34375    0.33333334], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0. 0.], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_sizes (pixels):  [[ 5.688694   7.2506824]\n",
      " [ 6.555434  11.472465 ]\n",
      " [ 9.367521  13.62963  ]\n",
      " [ 9.532935   8.862275 ]]\n",
      "anchor_ratios:  [0.81325746 0.5791896  0.6934732  1.1092904 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def compute_anchor_boxes(bboxes, img_width, img_height):\n",
    "    all_bboxes = []\n",
    "    for image_bboxes in bboxes:\n",
    "        # 정규화된 좌표를 픽셀 단위 좌표로 변환\n",
    "        pixel_bboxes = np.copy(image_bboxes)\n",
    "        pixel_bboxes[:, 0] *= img_width\n",
    "        pixel_bboxes[:, 1] *= img_height\n",
    "        pixel_bboxes[:, 2] *= img_width\n",
    "        pixel_bboxes[:, 3] *= img_height\n",
    "        all_bboxes.extend(pixel_bboxes)\n",
    "    \n",
    "    all_bboxes = np.array(all_bboxes)\n",
    "    \n",
    "    # 높이가 0인 바운딩 박스 제거\n",
    "    valid_bboxes = all_bboxes[np.logical_and(all_bboxes[:, 2] > all_bboxes[:, 0], all_bboxes[:, 3] > all_bboxes[:, 1])]\n",
    "    \n",
    "    box_sizes = valid_bboxes[:, 2:] - valid_bboxes[:, :2]\n",
    "    box_ratios = box_sizes[:, 0] / box_sizes[:, 1]\n",
    "    \n",
    "    data = np.column_stack((box_sizes[:, 0], box_sizes[:, 1], box_ratios))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(data)\n",
    "    \n",
    "    anchor_sizes = kmeans.cluster_centers_[:, :2]\n",
    "    anchor_ratios = kmeans.cluster_centers_[:, 2]\n",
    "    \n",
    "    return anchor_sizes, anchor_ratios\n",
    "\n",
    "bboxes = []\n",
    "for image, image_bboxes, label in train_dataset:\n",
    "    bboxes.append(image_bboxes.numpy())\n",
    "\n",
    "# 이미지 너비와 높이 설정\n",
    "img_width = 32\n",
    "img_height = 24\n",
    "\n",
    "anchor_sizes, anchor_ratios = compute_anchor_boxes(bboxes, img_width, img_height)\n",
    "print(\"anchor_sizes (pixels): \", anchor_sizes)\n",
    "print(\"anchor_ratios: \", anchor_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.6, 0.8, 1.1]        \n",
    "        self.scales = [2** x for x in [1/3, 2/3]]\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [4.5, 5.5, 3.5]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1),\n",
    "                    [1, 1, 2]\n",
    "                )\n",
    "                dims = tf.cast(dims, tf.float32)  # 데이터 타입을 float32로 변환\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor 음수 값: False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0] / RES_WIDTH\n",
    "ymin = anchor[:, 1] / RES_HEIGHT\n",
    "xmax = anchor[:, 2] / RES_WIDTH\n",
    "ymax = anchor[:, 3] / RES_HEIGHT\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x * RES_WIDTH, top_left_y * RES_HEIGHT), width * RES_WIDTH, height * RES_HEIGHT, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelEncoder:\n",
    "#     def __init__(self):\n",
    "#         self._anchor_box = AnchorBox()\n",
    "#         self._box_variance = tf.convert_to_tensor(\n",
    "#             [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "#     def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "#         iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "#         max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "\n",
    "#         matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "#         positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "#         negative_mask = tf.less(max_iou, ignore_iou)\n",
    "\n",
    "#         ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "#         return (\n",
    "#             matched_gt_idx,\n",
    "#             tf.cast(positive_mask, dtype = tf.float32),\n",
    "#             tf.cast(ignore_mask, dtype = tf.float32),\n",
    "#         )\n",
    "    \n",
    "#     def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "#         box_target = tf.concat(\n",
    "#             [\n",
    "#                 (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "#                 tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "#             ],\n",
    "#             axis = -1,\n",
    "#         )\n",
    "#         box_target = box_target / self._box_variance\n",
    "#         return box_target\n",
    "    \n",
    "\n",
    "#     def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "#         anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "#         # 앵커 박스 정규화\n",
    "#         xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "#         ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "#         xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "#         ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "\n",
    "#         # 정규화된 좌표를 스택으로 결합\n",
    "#         normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "#         cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "#         matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "#             normalized_anchor, gt_boxes\n",
    "#         )\n",
    "\n",
    "#         matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "\n",
    "        \n",
    "#         box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "\n",
    "#         matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "\n",
    "#         cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "#         cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "\n",
    "#         cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "#         num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "#         print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "#         label = tf.concat([box_target, cls_target], axis=-1)\n",
    "#         return label\n",
    "\n",
    "#     def encode_batch(self, batch_images, gt_boxes, cls_ids):       \n",
    "#         images_shape = tf.shape(batch_images)\n",
    "#         batch_size = images_shape[0]\n",
    "\n",
    "#         labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "#         for i in range(batch_size):\n",
    "#             label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "#             labels = labels.write(i, label)\n",
    "#         return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou=0.5):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
    "        return matched_gt_idx, max_iou\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        box_target = box_target / self._box_variance\n",
    "        return box_target\n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # Normalize anchor boxes\n",
    "        xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "        ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "        xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "        ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        matched_gt_idx, iou_scores = self._match_anchor_boxes(normalized_anchor, gt_boxes)\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        \n",
    "        # Use IoU scores as labels for classification\n",
    "        cls_target = iou_scores\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            labels = labels.write(i, label)\n",
    "        return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248.0 1.0\n",
      "(1, 6048, 5)\n",
      "Positive 개수: 68\n",
      "Negative 개수: 5980\n",
      "243.0 0.0\n",
      "(1, 6048, 5)\n",
      "Positive 개수: 116\n",
      "Negative 개수: 5932\n",
      "242.0 8.0\n",
      "(1, 6048, 5)\n",
      "Positive 개수: 94\n",
      "Negative 개수: 5954\n"
     ]
    }
   ],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, labels = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(labels.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.greater_equal(labels[0, :, 4], 0.5), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.less(labels[0, :, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    # print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 0\n",
      "Negative 개수: 5869\n",
      "Ignore 개수: 0\n",
      "Positive 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    label_idx = 0\n",
    "    for label in labels:\n",
    "        # if label[4] == 1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        # elif label[4] == -1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        dx, dy, dw, dh = label[:4]\n",
    "        anchor = anchors[label_idx]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, width, height]\n",
    "        # print(np.array(decoded_box))\n",
    "        if label[4] == 1.0:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "        label_idx += 1\n",
    "        # if len(np.array(decoded_boxes)) > 1: \n",
    "            # break\n",
    "    print(\"Positive\",len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes    \n",
    "    # print(np.array(decoded_boxes))\n",
    "    \n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    # print(len(decoded_boxes))\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i+=1\n",
    "        # print(box)\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    # print(i)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(1):\n",
    "    image = batch[0][0].numpy()\n",
    "    labels = batch[1][0].numpy()  # 여기서 labels는 [오프셋x, 오프셋y, 스케일w, 스케일h, 클래스, 앵커 박스 인덱스]를 포함한다고 가정\n",
    "    # print(labels)\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(labels, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bottleneck(layers.Layer):\n",
    "#     def __init__(self, out_channels, stride=1):\n",
    "#         super(Bottleneck, self).__init__()\n",
    "#         self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "#         self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         identity = x\n",
    "#         out = self.conv_0(x)\n",
    "#         out = self.conv_1(out)\n",
    "#         out += identity\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=2, padding='SAME'):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding=padding, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "        self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.conv_1(out)\n",
    "        out += identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding='SAME'):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv1 = Conv(out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.maxpool1 = layers.MaxPooling2D(pool_size=1, strides=1, padding='SAME')\n",
    "        self.maxpool2 = layers.MaxPooling2D(pool_size=3, strides=1, padding='SAME')\n",
    "        self.maxpool3 = layers.MaxPooling2D(pool_size=5, strides=1, padding='SAME')\n",
    "        self.conv2 = Conv(out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "    \n",
    "        pool1 = self.maxpool1(x)\n",
    "        pool2 = self.maxpool2(x)\n",
    "        pool3 = self.maxpool3(x)\n",
    "\n",
    "        concatenated = tf.concat([x, pool1, pool2, pool3], axis=-1)\n",
    "\n",
    "        out = self.conv2(concatenated)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiStageFeatureExtractionLayer\n",
    "class MSFELayer(layers.Layer):\n",
    "    def __init__(self, sperate_input_channel, out_channel):\n",
    "        super(MSFELayer, self).__init__()\n",
    "        self.cbam = CBAM()\n",
    "        self.bottleneck = Bottleneck(sperate_input_channel)\n",
    "        self.conv_out = Conv(out_channel, kernel_size=3, stride=1, padding='SAME')\n",
    "\n",
    "    def call(self, x):\n",
    "        cbam = self.cbam(x)\n",
    "        bottle = self.bottleneck(x)\n",
    "        out = tf.concat([bottle, cbam], axis = -1)\n",
    "        out = self.conv_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "        # self.conv = layers.Conv2D(out_channel, kernel_size = 1, strides = 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    def call(self, inputs):\n",
    "        out = self.upsample(inputs)\n",
    "        # out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose(layers.Layer):\n",
    "    def __init__(self, out_channel, size):\n",
    "        super(Conv2DTranspose, self).__init__()\n",
    "        self.transpose = layers.Conv2DTranspose(filters=out_channel, kernel_size=3, strides=size, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.transpose(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSUpsample(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size, size, interpolation = 'bilinear'):\n",
    "        super(CSUpsample, self).__init__()\n",
    "        self.upsample = Upsample(size=size, interpolation = interpolation)\n",
    "        self.transpose = Conv2DTranspose(out_channel * 2, size=size)\n",
    "        self.conv = Conv(out_channel, kernel_size = kernel_size, stride=1, padding='SAME')\n",
    "    \n",
    "    def call(self, x):\n",
    "        upsample, transpose = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        upsample = self.upsample(upsample)\n",
    "        transpose = self.transpose(transpose)\n",
    "\n",
    "        out = tf.concat([upsample, transpose], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(layers.Layer):\n",
    "    def __init__(self, filters, reduction=2, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.reduction = reduction\n",
    "        self.f = layers.Conv2D(filters // reduction, 1, use_bias=False)\n",
    "        self.g = layers.Conv2D(filters // reduction, 1, use_bias=False)\n",
    "        self.h = layers.Conv2D(filters, 1, use_bias=False)\n",
    "        self.softmax = layers.Softmax(axis=-1)\n",
    "\n",
    "    def call(self, x):\n",
    "        f = self.f(x)\n",
    "        g = self.g(x)\n",
    "        h = self.h(x)\n",
    "\n",
    "        s = tf.matmul(g, f, transpose_b=True)\n",
    "        beta = self.softmax(s)\n",
    "\n",
    "        o = tf.matmul(beta, h)\n",
    "        o = tf.add(o, x)\n",
    "        return o\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(out_channels=8, kernel_size=3, stride=1) # 24, 32\n",
    "        self.msfe1 = MSFELayer(8, 12)\n",
    "\n",
    "        self.conv2 = Conv(out_channels=12, kernel_size=3, stride=2) # 12, 16\n",
    "        self.msfe2 = MSFELayer(12, 20)\n",
    "\n",
    "        self.conv3 = Conv(out_channels=20, kernel_size=3, stride=2) # 6, 8\n",
    "        self.msfe3 = MSFELayer(20, 28)\n",
    "\n",
    "        self.conv4 = Conv(out_channels=28, kernel_size=3, stride=2) # 3, 4\n",
    "        self.msfe4 = MSFELayer(28, 36)\n",
    "        # self.sppf = SPPFast(24)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1 = self.conv1(inputs) \n",
    "        p1_out = self.msfe1(p1) # 24, 32, 18\n",
    "\n",
    "        p2 = self.conv2(p1_out)\n",
    "        p2_out = self.msfe2(p2) # 12, 16, 21\n",
    "\n",
    "        p3 = self.conv3(p2_out) \n",
    "        p3_out = self.msfe3(p3) # 6, 8, 24\n",
    "\n",
    "        p4 = self.conv4(p3_out)\n",
    "        p4_out = self.msfe4(p4) # 3, 4, 27\n",
    "\n",
    "        # return p1_out, p2_out, p3_out, p4_out\n",
    "        return p1_out, p2_out, p3_out, p4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPPN(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FPPN, self).__init__()\n",
    "        self.csupsample1 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csupsample2 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csupsample3 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        # FPN layers\n",
    "        self.lateral_conv1 = MSFELayer(12, 36)\n",
    "        self.lateral_conv2 = MSFELayer(20, 36)\n",
    "        self.lateral_conv3 = MSFELayer(28, 36)\n",
    "        self.lateral_conv4 = MSFELayer(36, 36)\n",
    "        \n",
    "        self.smooth_conv1 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv2 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv3 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "#   • c1=tf.Tensor(shape=(None, 24, 32, 12), dtype=float32)\n",
    "#   • c2=tf.Tensor(shape=(None, 12, 16, 12), dtype=float32)\n",
    "#   • c3=tf.Tensor(shape=(None, 6, 8, 20), dtype=float32)\n",
    "\n",
    "    def call(self, p1_out, p2_out, p3_out, p4_out):\n",
    "        lateral_conv1 = self.lateral_conv1(p1_out)\n",
    "        lateral_conv2 = self.lateral_conv2(p2_out)\n",
    "        lateral_conv3 = self.lateral_conv3(p3_out)\n",
    "        lateral_conv4 = self.lateral_conv4(p4_out)\n",
    "\n",
    "        fpn_out4 = lateral_conv4\n",
    "        fpn_out3 = layers.Add()([self.csupsample1(fpn_out4), lateral_conv3])\n",
    "        fpn_out2 = layers.Add()([self.csupsample2(fpn_out3), lateral_conv2])\n",
    "        fpn_out1 = layers.Add()([self.csupsample3(fpn_out2), lateral_conv1])\n",
    "\n",
    "        fpn_out1 = self.smooth_conv1(fpn_out1)\n",
    "        fpn_out2 = self.smooth_conv2(fpn_out2)\n",
    "        fpn_out3 = self.smooth_conv3(fpn_out3)\n",
    "        \n",
    "        return fpn_out1, fpn_out2, fpn_out3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 1, num_anchors_per_location = 6):\n",
    "        super(DetectionModel, self).__init__()\n",
    "\n",
    "        self.backbone = BackBone()\n",
    "        # self.neck = Neck()\n",
    "        # self.head = Head()\n",
    "        self.fppn = FPPN()\n",
    "        self.msfe1 = MSFELayer(36, 72)\n",
    "        self.conv1 = Conv(72, kernel_size = 1, stride=1)\n",
    "        self.conv2 = Conv(72, kernel_size = 3, stride=1)\n",
    "        self.cbam = CBAM()\n",
    "        self.attention = SelfAttention(num_anchors_per_location * num_classes)\n",
    "        # self.msfe2 = MSFELayer(72, 72)\n",
    "        \n",
    "        \n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            self.msfe1,\n",
    "            self.conv1,\n",
    "            self.conv2,\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            self.cbam,\n",
    "            self.attention,\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(36, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            layers.Conv2D(36, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "            # self.msfe2,\n",
    "            # self.conv2,\n",
    "            layers.Conv2D(num_anchors_per_location * 4, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal()),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1_out, p2_out, p3_out, p4_out = self.backbone(inputs)\n",
    "        # c1, c2, c3 = self.neck(p1, p2, p3, p4)\n",
    "        # h1_out, h2_out, h3_out = self.head(c1, c2, c3)\n",
    "        fpn_out1, fpn_out2, fpn_out3 = self.fppn(p1_out, p2_out, p3_out, p4_out)\n",
    "\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        N = tf.shape(inputs)[0]\n",
    "        \n",
    "        for _, feature in enumerate([fpn_out1, fpn_out2, fpn_out3]):\n",
    "            cls_output = self.classification_head(feature)\n",
    "            reg_output = self.regression_head(feature)\n",
    "            \n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "\n",
    "            cls_outputs.append(cls_output)\n",
    "            reg_outputs.append(reg_output)\n",
    "\n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "        # clipped_outputs = tf.clip_by_value(cls_outputs, -4, 4)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"detection_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " back_bone (BackBone)        multiple                  63012     \n",
      "                                                                 \n",
      " fppn (FPPN)                 multiple                  162020    \n",
      "                                                                 \n",
      " msfe_layer_8 (MSFELayer)    (None, None, None, 72)    61002     \n",
      "                                                                 \n",
      " conv_31 (Conv)              (None, None, None, 72)    5544      \n",
      "                                                                 \n",
      " conv_32 (Conv)              (None, None, None, 72)    47016     \n",
      "                                                                 \n",
      " cbam_9 (CBAM)               (None, None, None, 6)     126       \n",
      "                                                                 \n",
      " self_attention (SelfAttent  (None, None, None, 6)     72        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, None, 6)     117984    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, None, 24)    3552      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 346568 (1.32 MB)\n",
      "Trainable params: 344720 (1.32 MB)\n",
      "Non-trainable params: 1848 (7.22 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DetectionModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred, sample_weight=None):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "\n",
    "        # Positive 샘플에 대해서만 손실을 계산하고, 나머지는 0으로 설정\n",
    "        positive_mask = tf.cast(tf.greater(y_true, 0.0), tf.float32)\n",
    "        loss = loss * positive_mask\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            loss = tf.multiply(loss, sample_weight)\n",
    "\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class ConditionalFocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, threshold=0.75, **kwargs):\n",
    "        super(ConditionalFocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= 0.5, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true_binary)\n",
    "        alpha_t = tf.where(tf.equal(y_true_binary, 1.0), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.equal(y_true_binary, 1.0), y_pred, 1 - y_pred)\n",
    "        \n",
    "        # Condition 1: y_true = 1\n",
    "        condition1 = tf.equal(y_true_binary, 1.0)\n",
    "        loss1 = tf.where(tf.less(p_t, self.threshold),\n",
    "                         -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "                         0.0)\n",
    "        \n",
    "        # Condition 2: y_true = 0\n",
    "        condition2 = tf.equal(y_true_binary, 0.0)\n",
    "        loss2 = tf.where(tf.greater_equal(p_t, self.threshold),\n",
    "                         -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "                         0.0)\n",
    "        \n",
    "        fl = tf.where(condition1, loss1, tf.where(condition2, loss2, 0.0))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):  # Precision (0.55 best)\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, threshold=0.5, **kwargs):\n",
    "        super(FocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true)\n",
    "        alpha_t = tf.where(tf.greater(y_true, self.threshold), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.greater(y_true, self.threshold), y_pred, 1 - y_pred)\n",
    "        fl = -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class IoUF1ScoreLoss(tf.keras.losses.Loss):  # Precision\n",
    "    def __init__(self, threshold=0.5, beta=3, reduction='auto', **kwargs):\n",
    "        super().__init__(reduction=reduction, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= self.threshold, tf.float32)\n",
    "        y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true_binary * y_pred_binary, axis=-1)\n",
    "        fp = tf.reduce_sum((1 - y_true_binary) * y_pred_binary, axis=-1)\n",
    "        fn = tf.reduce_sum(y_true_binary * (1 - y_pred_binary), axis=-1)\n",
    "\n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "        beta_squared = self.beta ** 2\n",
    "        f1_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "        return 1 - f1_score\n",
    "    \n",
    "\n",
    "    # # Hard Negative Mining \n",
    "class Loss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=1, alpha=0.25, gamma=2, delta=1, negative_ratio=1.5):\n",
    "        super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "        self._box_loss = BoxLoss(delta=delta)\n",
    "        self._focal_loss = ConditionalFocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self._num_classes = num_classes\n",
    "        self._negative_ratio = negative_ratio\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "        cls_labels = y_true[:, :, 4:]\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "        positive_mask = tf.cast(tf.greater_equal(cls_labels, 0.5), tf.bool)\n",
    "        negative_mask = tf.cast(tf.less(cls_labels, 0.5), tf.bool)\n",
    "\n",
    "        num_positives = tf.reduce_sum(tf.cast(positive_mask, tf.float32), axis=1)\n",
    "        num_negatives = tf.cast(self._negative_ratio * tf.reduce_max(num_positives), tf.int32)\n",
    "\n",
    "        negative_cls_loss = self._focal_loss(tf.boolean_mask(cls_labels, negative_mask),\n",
    "                                             tf.boolean_mask(cls_predictions, negative_mask))\n",
    "        negative_cls_loss = tf.reshape(negative_cls_loss, [-1])\n",
    "        _, top_k_indices = tf.math.top_k(negative_cls_loss, k=tf.minimum(num_negatives, tf.shape(negative_cls_loss)[0]), sorted=True)\n",
    "        negative_indices = tf.where(negative_mask)\n",
    "        hard_negative_indices = tf.gather(negative_indices, top_k_indices)\n",
    "        hard_negative_mask = tf.scatter_nd(hard_negative_indices, tf.ones(tf.shape(top_k_indices)[0], dtype=tf.int32),\n",
    "                                           tf.cast(tf.shape(negative_mask), tf.int64))\n",
    "        hard_negative_mask = tf.cast(hard_negative_mask, tf.bool)\n",
    "\n",
    "        focal_loss = self._focal_loss(tf.boolean_mask(cls_labels, tf.logical_or(positive_mask, hard_negative_mask)),\n",
    "                                      tf.boolean_mask(cls_predictions, tf.logical_or(positive_mask, hard_negative_mask)))\n",
    "        box_loss = self._box_loss(box_labels, box_predictions, sample_weight=tf.cast(positive_mask, tf.float32))\n",
    "\n",
    "        cls_weight = 0.7\n",
    "        box_weight = 0.3\n",
    "        # loss = cls_weight * (focal_loss / (num_positives + 1e-6))+ box_weight * box_loss\n",
    "        loss = cls_weight * focal_loss+ box_weight * box_loss\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class mAP(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, num_classes, iou_threshold=0.5, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "#         super(mAP, self).__init__(name=name, **kwargs)\n",
    "#         self.num_classes = num_classes\n",
    "#         self.iou_threshold = iou_threshold\n",
    "#         self.anchors = anchors\n",
    "#         self.box_variance = box_variance\n",
    "#         self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "#         self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "#         self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "#         true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "#         pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        \n",
    "#         pred_probs = tf.nn.sigmoid(y_pred[..., 4])\n",
    "        \n",
    "#         iou = self.iou(true_boxes, pred_boxes)\n",
    "        \n",
    "#         true_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.greater_equal(pred_probs, self.iou_threshold), tf.greater_equal(iou, self.iou_threshold))), tf.float32))\n",
    "#         false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.less(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.greater_equal(pred_probs, self.iou_threshold), tf.greater_equal(iou, self.iou_threshold))), tf.float32))  \n",
    "#         false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.less(pred_probs, self.iou_threshold), tf.less(iou, self.iou_threshold))), tf.float32))\n",
    "        \n",
    "#         self.true_positives.assign(self.true_positives + true_positives)\n",
    "#         self.false_positives.assign(self.false_positives + false_positives)\n",
    "#         self.false_negatives.assign(self.false_negatives + false_negatives)\n",
    "\n",
    "#     def result(self):\n",
    "#         per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "#         return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "#     def reset_state(self):\n",
    "#         self.true_positives.assign(tf.zeros_like(self.true_positives)) \n",
    "#         self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "#         self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "#     def decode_predictions(self, labels, anchors):\n",
    "#         anchor_x = anchors[..., 0]\n",
    "#         anchor_y = anchors[..., 1] \n",
    "#         anchor_w = anchors[..., 2]\n",
    "#         anchor_h = anchors[..., 3]\n",
    "\n",
    "#         cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "#         width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "#         height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         x_max = x_min + width\n",
    "#         y_max = y_min + height\n",
    "\n",
    "#         decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "#         return decoded_boxes\n",
    "\n",
    "#     def iou(self, y_true, y_pred):\n",
    "#         x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "#         y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "#         x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "#         y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "\n",
    "#         intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "#         area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "#         area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "#         union = area_true + area_pred - intersection\n",
    "#         iou = intersection / (union + 1e-6)\n",
    "#         return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class Recall(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Recall', threshold=0.5, **kwargs):\n",
    "        super(Recall, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.actual_positives = self.add_weight(name='actual_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        \n",
    "        actual_positives = tf.cast(labels, self.dtype)\n",
    "        self.actual_positives.assign_add(tf.reduce_sum(actual_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.actual_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class Precision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Precision', threshold=0.5, **kwargs):\n",
    "        super(Precision, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.predicted_positives = self.add_weight(name='predicted_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        self.predicted_positives.assign_add(tf.reduce_sum(pred_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.predicted_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='F1Score', threshold=0.5, **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.precision = Precision(threshold=threshold)\n",
    "        self.recall = Recall(threshold=threshold)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "        return f1_score\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class mAP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, iou_threshold=0.5, score_threshold=0.5, max_detections_per_class=1, max_total_detections=20, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "        super(mAP, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.score_threshold = score_threshold\n",
    "        self.max_detections_per_class = max_detections_per_class\n",
    "        self.max_total_detections = max_total_detections\n",
    "        self.anchors = anchors\n",
    "        self.box_variance = box_variance\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Decode predictions and true boxes\n",
    "        true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "        true_labels = tf.cast(y_true[..., 4], tf.int32)\n",
    "        pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        pred_scores = y_pred[..., 4:]\n",
    "\n",
    "        # Batch size for dynamic handling\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "\n",
    "        # Initialize containers for updates\n",
    "        tp_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "        fp_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "        fn_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "\n",
    "        # Iterate through the batch\n",
    "        for i in range(batch_size):\n",
    "            single_true_boxes = true_boxes[i]\n",
    "            single_true_labels = true_labels[i]\n",
    "            single_pred_boxes = tf.expand_dims(pred_boxes[i], axis=2)  # NMS expects [N, num_boxes, 1, 4]\n",
    "            single_pred_scores = pred_scores[i]  # Scores from the model\n",
    "\n",
    "            # Perform NMS\n",
    "            selected_indices, selected_scores, num_detections = tf.image.combined_non_max_suppression(\n",
    "                boxes=single_pred_boxes,\n",
    "                scores=single_pred_scores,\n",
    "                max_output_size_per_class=self.max_detections_per_class,\n",
    "                max_total_size=self.max_total_detections,\n",
    "                iou_threshold=self.iou_threshold,\n",
    "                score_threshold=self.score_threshold,\n",
    "                pad_per_class=False,\n",
    "                clip_boxes=False\n",
    "            )\n",
    "\n",
    "            # Filter only detected indices\n",
    "            detected_boxes = tf.gather(single_pred_boxes[:, :, 0], selected_indices)\n",
    "            detected_scores = selected_scores\n",
    "            detected_classes = tf.cast(tf.argmax(detected_scores, axis=-1), tf.int32)\n",
    "\n",
    "            # Count true positives, false positives, and false negatives\n",
    "            for c in range(self.num_classes):\n",
    "                class_mask = tf.equal(single_true_labels, c)\n",
    "                class_true_boxes = tf.boolean_mask(single_true_boxes, class_mask)\n",
    "                class_detected_mask = tf.equal(detected_classes, c)\n",
    "                class_detected_boxes = tf.boolean_mask(detected_boxes, class_detected_mask)\n",
    "\n",
    "                # Compute IOU between true and detected boxes for this class\n",
    "                ious = self.iou(tf.expand_dims(class_true_boxes, axis=1), tf.expand_dims(class_detected_boxes, axis=0))\n",
    "                max_iou = tf.reduce_max(ious, axis=0)\n",
    "                iou_mask = max_iou > self.iou_threshold\n",
    "\n",
    "                # Update TP, FP based on IOU mask\n",
    "                tp_updates = tp_updates + tf.reduce_sum(tf.cast(iou_mask, tf.int32))\n",
    "                fp_updates = fp_updates + tf.reduce_sum(tf.cast(tf.logical_not(iou_mask), tf.int32))\n",
    "                fn_updates = fn_updates + (tf.shape(class_true_boxes)[0] - tf.reduce_sum(tf.cast(iou_mask, tf.int32)))\n",
    "\n",
    "        # Assign updated values to the metric variables\n",
    "        self.true_positives.assign_add(tf.cast(tp_updates, dtype=self.dtype))\n",
    "        self.false_positives.assign_add(tf.cast(fp_updates, dtype=self.dtype))\n",
    "        self.false_negatives.assign_add(tf.cast(fn_updates, dtype=self.dtype))\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros_like(self.true_positives))\n",
    "        self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "        self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "    def decode_predictions(self, labels, anchors, batch_size = 9):\n",
    "        anchors = tf.tile(anchors[None, ...], [batch_size, 1, 1])\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = tf.split(anchors, 4, axis=-1)\n",
    "        anchor_w = tf.squeeze(anchor_w, axis=-1)\n",
    "        anchor_h = tf.squeeze(anchor_h, axis=-1)\n",
    "        anchor_x = tf.squeeze(anchor_x, axis=-1)\n",
    "        anchor_y = tf.squeeze(anchor_y, axis=-1)\n",
    "\n",
    "        cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "        cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "        height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return decoded_boxes\n",
    "\n",
    "    def iou(self, y_true, y_pred):\n",
    "        y_true = tf.expand_dims(y_true, axis=0)\n",
    "        y_pred = tf.expand_dims(y_pred, axis=1)\n",
    "\n",
    "        x1 = tf.maximum(y_true[..., 0:1], y_pred[..., 0:1])\n",
    "        y1 = tf.maximum(y_true[..., 1:2], y_pred[..., 1:2])\n",
    "        x2 = tf.minimum(y_true[..., 2:3], y_pred[..., 2:3])\n",
    "        y2 = tf.minimum(y_true[..., 3:4], y_pred[..., 3:4])\n",
    "\n",
    "        intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        area_true = (y_true[..., 2:3] - y_true[..., 0:1]) * (y_true[..., 3:4] - y_true[..., 1:2])\n",
    "        area_pred = (y_pred[..., 2:3] - y_pred[..., 0:1]) * (y_pred[..., 3:4] - y_pred[..., 1:2])\n",
    "        union = area_true + area_pred - intersection\n",
    "\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0002\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "initial_learning_rate = 0.0005\n",
    "decay_steps = 5\n",
    "decay_rate = 0.5\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import Precision, Recall\n",
    "# import tfr\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "model = DetectionModel(num_classes)\n",
    "loss_fn = Loss(num_classes=1)\n",
    "# optimizer = tf.optimizers.Adam(clipnorm = 1.0)\n",
    "\n",
    "\n",
    "# map_metric = MeanAveragePrecision(num_classes=num_classes, anchors=anchors)\n",
    "# iou_metric = IntersectionOverUnion(num_classes=num_classes, anchors=anchors)\n",
    "\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)\n",
    "# iou_metric = MultiBoxIoUMetric(anchors=anchors)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer=optimizer, \n",
    "#               loss=[loss_fn],\n",
    "#               metrics=[Precision()])\n",
    "\n",
    "# mAP(num_classes = num_classes, anchors = anchors),  \n",
    "model.compile(optimizer='adam', \n",
    "              loss=[loss_fn],\n",
    "              metrics=['accuracy', F1Score(), Precision(), Recall()]) # Precision(), Recall()]) # # mAP(num_classes = num_classes, anchors = anchors), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 9\n",
    "\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     print(f\"Images shape: {images.shape}\")\n",
    "#     print(f\"Labels shape: {labels.shape}\")\n",
    "#     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "#     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "# # for images, labels in val_dataset.take(1):\n",
    "# #     print(f\"Images shape: {images.shape}\")\n",
    "# #     print(f\"Labels shape: {labels.shape}\")\n",
    "# #     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "# #     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "\n",
    "# val = 0\n",
    "# for _, _ in val_dataset:\n",
    "#     val += 1\n",
    "# print(val)\n",
    "\n",
    "\n",
    "# train = 0\n",
    "# for _, _ in train_dataset:\n",
    "#     train += 1\n",
    "# print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0005.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 10:36:19.535487: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-04-19 10:36:23.800681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f431c61cda0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-19 10:36:23.800712: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.800718: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.800721: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.800725: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.800728: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.800732: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.800735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-19 10:36:23.806194: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-19 10:36:23.928859: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    255/Unknown - 46s 54ms/step - loss: 3.5446 - accuracy: 0.2301 - F1Score: 0.0394 - Precision: 0.0201 - Recall: 0.9627"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=lr_callback,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 51: LearningRateScheduler setting learning rate to 3.125e-06.\n",
    "# Epoch 51/100\n",
    "# 249/473 [==============>...............] - ETA: 6s - loss: 6.8215 - accuracy: 0.7611 - F1Score: 0.6611 - Precision: 0.7209 - Recall: 0.6104\n",
    "\n",
    "\n",
    "# Epoch 17: LearningRateScheduler setting learning rate to 0.00025.\n",
    "# Epoch 17/100\n",
    "# 131/473 [=======>......................] - ETA: 10s - loss: 7.7444 - accuracy: 0.7838 - F1Score: 0.6975 - Precision: 0.7270 - Recall: 0.6702\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2): \n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.5, top_n=20):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "\n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "\n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i = scores.pop(0)\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "\n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, in val_dataset.take(30):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
