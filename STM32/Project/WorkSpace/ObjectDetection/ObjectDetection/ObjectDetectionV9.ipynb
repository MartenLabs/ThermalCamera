{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 10:00:30.522333: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-16 10:00:30.557522: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-16 10:00:30.557552: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-16 10:00:30.557569: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-16 10:00:30.563974: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-16 10:00:31.256507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1\n",
    "N_BATCH = 3\n",
    "N_EPOCH = 200\n",
    "LR = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 10:00:32.753735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20889 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:32.754655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:1 with 21939 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:32.755401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:2 with 21939 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:32.756093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:3 with 21939 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:32.756803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:4 with 21939 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:32.757501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:5 with 21939 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:32.758195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:6 with 21939 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3648146192302251874\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 21904687104\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 6231520161923211349\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419,\n",
       " name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23005691904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 16343685697460338030\n",
       " physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 2144165316,\n",
       " name: \"/device:GPU:2\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23005691904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9413951801829883177\n",
       " physical_device_desc: \"device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1651660799,\n",
       " name: \"/device:GPU:3\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23005691904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7243438413332499645\n",
       " physical_device_desc: \"device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 878896533,\n",
       " name: \"/device:GPU:4\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23005691904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14167279257039306\n",
       " physical_device_desc: \"device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 615190153,\n",
       " name: \"/device:GPU:5\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23005691904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9117100956836989399\n",
       " physical_device_desc: \"device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 1769886423,\n",
       " name: \"/device:GPU:6\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23005691904\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 15502338053445529808\n",
       " physical_device_desc: \"device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 893286608]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현제 바운딩박스는 xmin, ymin, xmax, ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17820, 24, 32, 1) (17820,) (17820, 4, 4) 17820\n",
      "255 0\n",
      "(828, 24, 32, 1)\n",
      "(828, 4, 4)\n",
      "828\n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " ...\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 3)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " ...\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  7 11 17]\n",
      " [19  2 29 11]\n",
      " [25  0 32  5]\n",
      " [25  5 32 12]]\n",
      "255 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGdCAYAAABZ+qqcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAolUlEQVR4nO3dfXCc5Xnv8d+zr3qXLMuWLPyCbYKdAHYaBxxNAnWwBtt/MBCYDtD8YZIMTKjdKXETGncaCLQzTulMmqbjwplJi5uZBgKdAic5KQmYWDStDccGH4eQ+NhGYBlbsjHWu3a1L/f5Iwc1Ahu0162bXZnvZ2ZnbGkvX7eevffZnx6vdEXOOScAAICAYuVeAAAAOP8ROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAElyj3At6pWCzq+PHjqq+vVxRF5V4OAAA4B+echoaG1N7erljsva9hVFzgOH78uBYsWFDuZQAAgCnq6enR/Pnz3/M+FRc46uvrJUmXr92qRKKq5Pp4pujVf6wlaa6NFfx+S3xUsNfW9I6Za/M19q9ZkmIF+zFPvfamV283OGQvbmm216ZT9lpJxWr7Uy/26htevaOaGnOta6y31ybj5lpJcgn7Fc/YYMard7G+9HPR2+L9I169c3Mb7MUep6Rcg995IT5uPy9ERb9zabbRvvaixz4rJv2uyg9eaH+Xw9jica/eKtrWXhzL6Phd2yZeu99LxQWOt/8bJZGoUiJpCBx5v8CRSHoEjphn4PB4R00i4dE74Rk4IvsxT8TSXr1dlLUXxz16xz0DR9xjn0V+vSOPY+48jpmLewaOuP0JEov7PTeLHl93PJb36u0M33j9d7FPX8/AUSxf4Ch4nMfLGTjiaY89Xu35lkxj4HjbVN4CEexNo9u3b9eFF16oqqoqrV69Wi+88EKoVgAAoMIFCRw//OEPtWXLFt1zzz168cUXtXLlSq1bt04nT54M0Q4AAFS4IIHj29/+tm677TZ94Qtf0Mc+9jE9+OCDqqmp0T/90z+FaAcAACrctAeO8fFx7du3T52dnf/dJBZTZ2endu/e/a77Z7NZDQ4OTroBAIDzy7QHjjfffFOFQkGtra2TPt7a2qre3t533X/btm1qbGycuPEjsQAAnH/K/ptGt27dqoGBgYlbT09PuZcEAACm2bT/WGxLS4vi8bj6+vomfbyvr09tbW3vun86nVY67fejkQAAoLJN+xWOVCqlVatWaefOnRMfKxaL2rlzpzo6Oqa7HQAAmAGC/OKvLVu2aOPGjfrkJz+pK664Qt/5znc0MjKiL3zhCyHaAQCAChckcNx00006deqU7r77bvX29urjH/+4nnrqqXe9kRQAAHw4BPvV5ps3b9bmzZtD/fMAAGAGqbhZKm8bb4yrYBj2VP+W3wCbqjP23yefq/WbFZGrsff2mTMRH/Ob9RDL+NV78ZnPMYXf/X9OeY9Je5LkPJ56Sb9ZKnqfEdLvKWd/rCPPYxYl/J5fZTNqH6woSbGxWnNtoc6+V3yG5UnSmMfwt0TGb5bKeL19jw8ssdemBsyl3lLH/WbfFIwje6LM1M9lZf+xWAAAcP4jcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAILipD7L/gCVGi0okix9431xt3FxbSEdevaveKphrE785aq6NGurNtZJUmG2vd+PjXr0V8zvmVtF4zq8+n7TXJux7VJLXMYuGRvx6+3DOXltT7dU6ytvPRa7geR6L2x+vzJyUuTZb7/f96Kk19ud26ph93ZKUa7Qf88TcYXPt0Em/fVZz3P7cLvodMhVbs7a6sanXcYUDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBVex4+tG5ccVTpY/qTZ/xy1BVb9pHKheTfr0LaY/65iZ7reeo9diRN8y1Lp/36h3FPY6Zz7hzz2OmgkfvuOd4eo9x6cWBQXNt5Dki3o2OmWtjnscsqk7bixvrvHpn5tqPW/8S+9edrzGXSpI6Ln7VXPv6vFlevb+29Gfm2oKzn1MeO/VJc60k/erYcnNtPBN59S6+aZtvH2Wmfj7hCgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAS5V7AuVSfKiqRLJZcl21KevXNzIqba2t78169q98YMte63lP2xu2t9lpJbla9vfj/vubVWwmPLRyboXk7ivzqnbOX5ux7PFZbY66VJJcdtxcXCl69lbfXj8+f5dV6aL59j49eUPo59G3FWr9jdmHNaXPtmuaDXr2vrx0213bn7LX3nvI7lybsrRXzeHpIMp9XCpmp183QMy4AAJhJCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACC4ih1Pn6uLqZgqPQ/VveE3ozf9Vs5cmzgz5tW70JA218aWX2iuLcb9xp0nXusz17q0/WuWJMU9MrPvmHcPUdE+Nlx5+4h4SVI8bi6NVVeZa12V32Mda6i3F/s+1s6ZS0fmpbxaZ5vtay9W20fMx+vs50JJGsxXm2vnJga9ej8xUmeuHSnONtfm9s8y10pSvtmjtsa+RyUpWjpiKxzNTPmuXOEAAADBETgAAEBwBA4AABDctAeOb37zm4qiaNJt+fLl090GAADMIEHeNHrJJZfomWee+e8miYp9byoAAPgABEkCiURCbW1tIf5pAAAwAwV5D8ehQ4fU3t6uJUuW6POf/7yOHj16zvtms1kNDg5OugEAgPPLtAeO1atXa8eOHXrqqaf0wAMPqLu7W1deeaWGhobOev9t27apsbFx4rZgwYLpXhIAACizaQ8cGzZs0B/8wR9oxYoVWrdunX7yk5+ov79fjz766Fnvv3XrVg0MDEzcenp6pntJAACgzIK/m7OpqUkXX3yxDh8+fNbPp9NppX1/2yQAAKhowX8Px/DwsI4cOaJ58+aFbgUAACrUtAeOr371q+rq6tJrr72m//qv/9LnPvc5xeNx3XLLLdPdCgAAzBDT/l8qx44d0y233KLTp09rzpw5+sxnPqM9e/Zozpw5090KAADMENMeOB555JHp/icBAMAMV7G/AjSeKSpRKH2EdyzvMfZbUjFp/1+mYp3fGGqfEdrRmMco6Sq/beAa7WPDo4Gz/7j0lHt7jGqPxu3HzGWz5lpJioY89tmwcYz0/xerqzXXRvX2sd/yON6S5Krtby6PDOeSyc3to78zzX7/c13wOK1EOfs5xdd/vLHEXDuY9/tBgotrT5pra2Lj5trMAnutJClm32fJar/nV0vjsKkun8jq1Snel+FtAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCS5R7AecyfEFc8XS85LrqU5FX3+Rg1lxbqE169R5uT5trq0/bH8rEUM5cK0nxkTGP4tIf40kyGXOpG7Wv2w2PmGslSYWiubQ4NOTVOqqqstfW22vdW2fMtZIUNc/yqvfq7fF45at9m9tLY+Mexc7vXNpSZ3+O/OatVq/e86oGzbX/s+cyc23DbL/zwmBvvbn2ogtPePXOFmyvIflEfsr35QoHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCq9jx9K0vjCiRKJRcVzSMtP9dhWr7iPnM7JRX76FF9vzX12H/umPjftug/T8uMNfW7/cbqRw1NtiLs+P2vvP8xme7fvv47FhNjVfvqL7WXjyes9fOmW2vleQ8aguzPL5mT/XH7KPtJSnTZB8Tn7NPO1dhzO9cevRks7k23+93Ln205wqvequq2WNe9VHN1Ee9v9Orp/yeX1aF0cyU78sVDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwSXKvYBz6V9Wo3iqquS6qv6iV9/htri5tv/jOa/eUZW9PjqdMtfGF4yaayVp6Ivj5trau+u8esf63jLXuqx93a5ttrlWkqKk/annunu8emvcvs9cQ629r3P2WklR1uP5kfM7L7ik/Xuzov2UIkmK5e21Vac8vqc8ZT+nSFK6P2muzVdHXr1H5tsf72Lavk+zo/avWZI0YK/PepxTJCkq2I55cWzqe4wrHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACK5ix9PHs05xwzjrUyv9ZkF/ovPX5toTow1evRMx+0jlnqomc+0ty/aZayXpfx27xFz7m81NXr1buxrNtc1Pv2qujZ0ZMtdKkqtKm2vjc1s8e3uMHT/db69t8nt+aNw+nj427jHjXVIxZj9V+oyXl6T0gP28kBqyj3mvOuN5zJL23mPNfi9NhSr799LxMXtfF/d7/UkOl/6a97bxJvvxlqSicemF7NQLucIBAACCI3AAAIDgCBwAACC4kgPHc889p2uvvVbt7e2KokhPPPHEpM8753T33Xdr3rx5qq6uVmdnpw4dOjRd6wUAADNQyYFjZGREK1eu1Pbt28/6+fvvv1/f/e539eCDD+r5559XbW2t1q1bp0wm471YAAAwM5X8VuANGzZow4YNZ/2cc07f+c539Bd/8Re67rrrJEnf//731draqieeeEI333yz32oBAMCMNK3v4eju7lZvb686OzsnPtbY2KjVq1dr9+7dZ63JZrMaHBycdAMAAOeXaQ0cvb29kqTW1tZJH29tbZ343Dtt27ZNjY2NE7cFCxZM55IAAEAFKPtPqWzdulUDAwMTt56ennIvCQAATLNpDRxtbW2SpL6+vkkf7+vrm/jcO6XTaTU0NEy6AQCA88u0Bo7Fixerra1NO3funPjY4OCgnn/+eXV0dExnKwAAMIOU/FMqw8PDOnz48MTfu7u7tX//fjU3N2vhwoW688479Vd/9Vf6yEc+osWLF+sb3/iG2tvbdf3110/nugEAwAxScuDYu3evPvvZz078fcuWLZKkjRs3aseOHbrrrrs0MjKi22+/Xf39/frMZz6jp556SlVVVdO3agAAMKOUHDjWrFkj9x5TXKMo0n333af77rvPa2EAAOD8UfafUgEAAOe/kq9wfFDiWadE8dxXUs5l1sGiV9+XV579p2mmYvW8o169V9W/Zq79H8NXmmtbkwPmWkn6VOtr5tqnDnzSq/fwBZG5NnHlYnNtzYmsuVaSkq+fMte6oWGv3lEibu+dtX/d0XjOXCtJKhTste9xVXYqoqy9d3rAY92SEiN5c21UsJ8PE6dHzLWSNHJxs713xu88XnPC/r10/bFxc62zn44kSbGCfZ+OtKW8ejvjaaEwPvXHiiscAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIrqLH08cN4+lH5/hlKPeLWebaX17tN377mZc/aq5dvfxVc+2+oQvNtZKUd/ZjXqj2Gxue9zjk2Xr7utNn7CPeJSnpUxzzm4Ht0vYx1lFtrb1x0W/kuFL2o+ZSfqe6aMw+sjx9OuPVOzZsry9W2R9rl/Q7ZtW9Y/becb89nq+x75XU6VFzbW5WtblWkiJnPx+m+wtevZPDeVNdPp+d8n25wgEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAqdjz92Jy44qnSR4DPOmQfIy1Jby1Lm2uH/mOuV+/aywfMtQd+stxcm11uHyMtScVx+6j2ZJt9FLQkpV+vM9e27HvLXOszrlyS16h1rxHxklzC/njJo9Z33LkPF/mNO4/lbKO7JSk26rdXolGP8fY+4+mr/B6vKJsz18Y8n1/xIY/n19jUx62/U6zO/vohSSrax9MnZd+jkpQYNO6zAuPpAQBABSFwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAguES5F3AuLT/tViKWKrnurc4lXn2bjoyba89cXPp6f1fufzeaa90nhsy1yVfqzbWS1PxK0Vxb15Pz6p04c8pcGw2OmGuLLfbHSpI0kvGota9bkqJU0l4c8/geJel3uolG7ccsNjzm1duNjNqL0x7H21OUK9hrM/ZaSco31ZhrEx7rliQ5Z6/N5c2l8RH764ckRaNZc22xtsqr9weBKxwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiuYsfTj61YoESy9HG7Dd1+Y6jHG+0j5uuP+Y1UHr51wFyb3dtsrq097jHKWVLTL98y17pk3Ku3T32U8Kj1GS8v+Y15v6DNq3UhZX/aR4eP2msXtptrJcll7KO75THaXpLcqH08fdTU4NXbZ69EPsfsdL+9VlI8Pc9eXCh69S42VJtrI49zSrHK7yU1cXrQXBuL+10/cHHj112Y+usHVzgAAEBwBA4AABAcgQMAAARXcuB47rnndO2116q9vV1RFOmJJ56Y9Plbb71VURRNuq1fv3661gsAAGagkgPHyMiIVq5cqe3bt5/zPuvXr9eJEycmbg8//LDXIgEAwMxW8ltqN2zYoA0bNrznfdLptNra/N5JDwAAzh9B3sOxa9cuzZ07V8uWLdMdd9yh06dPn/O+2WxWg4ODk24AAOD8Mu2BY/369fr+97+vnTt36q//+q/V1dWlDRs2qFA4+++o2LZtmxobGyduCxYsmO4lAQCAMpv2X/x18803T/z5sssu04oVK7R06VLt2rVLa9eufdf9t27dqi1btkz8fXBwkNABAMB5JviPxS5ZskQtLS06fPjwWT+fTqfV0NAw6QYAAM4vwQPHsWPHdPr0ac2b5/FrbgEAwIxW8n+pDA8PT7pa0d3drf3796u5uVnNzc269957deONN6qtrU1HjhzRXXfdpYsuukjr1q2b1oUDAICZo+TAsXfvXn32s5+d+Pvb77/YuHGjHnjgAR04cED//M//rP7+frW3t+uaa67RX/7lXyqdTk/fqgEAwIxScuBYs2aNnDv3dLif/vSnXgsCAADnH2apAACA4Kb9x2Kni4v99laqQpXfl1Tz6hlz7VufbPHq3fA9+0/ojDWf+6rT+2l+ZdhcK0nFWvt/l8VefcOv90L7m5Fd0mOvRJG9VlI0mjHXulzOq7db1GqujRZdYG+cHbfXSooS9sfLZezHW5JirXPMtcW03zmpeOQ1c220/CJzrbtovrlW8jsXpwZHvXpHmby9NmevjY/47TOXTpprxxY2+vWO285p+VxSemVq9+UKBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgqvY8fRR0SkqlD5yPZYrevUt1thHrdf2+o0NTwzZx3dXH7N/3fG3Bs21kuRS9pHKUUO9V++YxzhoV1tlro08x1DLlb63J3pX2feoJCVOnDHXuqqUvfGZAXutJNfUYK6NItvo7YneA/bnSOQxclySoiWLzLWZ9jpzbfqk54j4hP372eKp0369F7aba13a/rI4tmCWuVaSal/sMdemzmS9ehdqjPs0X5jyXbnCAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4Cp2PL0USYaR0i7uN4Y632Qf/Z1603Occ8Y+3t4d77M3rq2x10pS0r6Nig1+vWOn7WPDiw3V5lq/XSbT3n6b8zjeklR8/Q1zbXxui73v/FZzreT3WLtMxqu3EuU7VRZfP2aurR4aMde6nP18JEnJ+jpzbf6jF3r1jo+Mm2uLVcYx7ZKq+sbMtZI08nsL7L1P+vVOnrHVR4XslO/LFQ4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMElyr2A6eZikVd9rFA010Z5e60kqejRu6baXOvqa821kuSqU/balOcWTNrrY6Pj9r4xz6yeSppLo2zOq3Xkccx89qhXrSQ3MGgv9vmaJUW1NebaQm3aq3cs7VEfj9trZzXYayUNL20y19YePuPVu+hxzCNn7/vm79XbiyXN7Tppri022F8DJGnwYtvjnc9lpF9O7b5c4QAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAVO54+ck5RsfQ5wZHzmC0sKTGQNde6eOTV26fatc229837jQ2PCh7HPFfw6u1qquzFb3qMwG7yG93tfMalDw559Y61zrEX5+2PV7EmZe8ryV262Fw7Psuvd9XJjLk2X5f06h2tXGquLaTt31PGs37nheRw3lx7qqPFq3fD6+PmWp9jNvv/DJtrJen06rnm2pqTOa/e1tcvV5x6HVc4AABAcAQOAAAQHIEDAAAEV1Lg2LZtmy6//HLV19dr7ty5uv7663Xw4MFJ98lkMtq0aZNmz56turo63Xjjjerr65vWRQMAgJmlpMDR1dWlTZs2ac+ePXr66aeVy+V0zTXXaGRkZOI+X/nKV/SjH/1Ijz32mLq6unT8+HHdcMMN075wAAAwc5T0Vvmnnnpq0t937NihuXPnat++fbrqqqs0MDCgf/zHf9QPfvADXX311ZKkhx56SB/96Ee1Z88efepTn5q+lQMAgBnD6z0cAwMDkqTm5mZJ0r59+5TL5dTZ2Tlxn+XLl2vhwoXavXv3Wf+NbDarwcHBSTcAAHB+MQeOYrGoO++8U5/+9Kd16aWXSpJ6e3uVSqXU1NQ06b6tra3q7e0967+zbds2NTY2TtwWLFhgXRIAAKhQ5sCxadMmvfzyy3rkkUe8FrB161YNDAxM3Hp6erz+PQAAUHlMv+5w8+bN+vGPf6znnntO8+fPn/h4W1ubxsfH1d/fP+kqR19fn9ra2s76b6XTaaXTacsyAADADFHSFQ7nnDZv3qzHH39czz77rBYvnvyrhletWqVkMqmdO3dOfOzgwYM6evSoOjo6pmfFAABgxinpCsemTZv0gx/8QE8++aTq6+sn3pfR2Nio6upqNTY26ktf+pK2bNmi5uZmNTQ06I//+I/V0dHBT6gAAPAhVlLgeOCBByRJa9asmfTxhx56SLfeeqsk6W//9m8Vi8V04403KpvNat26dfqHf/iHaVksAACYmUoKHG4Kk1irqqq0fft2bd++3bwoAABwfmGWCgAACM70UyofhGI8UjERlVznYnGvvomERwYrlL7e3xWlkvbWtSlzbXwwa66VpNjImL3Y42uWJFdt/7qjfN7euFi010pS5LFXpnCl8b0Ua6vNtT6PdWZOlblWkuJjBXNttsHvvKCife3OcB77XanBnLk2nrXv00La7/vRsTn253Zjt985KV9jf7zH6+21Q/PrzLWS1HJg5P3vdA75Gr9zaa7atk8L8anXcYUDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBVe54+mSkYrL0cbmR59TwTKt9dHf1sWGv3sUq+8PhO2Ley1jGXhv3y7zRuMeI+VmNHn3tI8MlSUWPEfPV9j0qSdGox+OVsx/v6uP20duSFDvUY65NLV3g1btQlzLXZpv9xobHxuzHPCrYT4jZ2bXmWkmqO24/J43X+x2zxGjBXJtvsZ+HZ/9qzFwrSUOLasy1NSfHvXo3vmZ7vPL5qddxhQMAAARH4AAAAMEROAAAQHAEDgAAEByBAwAABEfgAAAAwRE4AABAcAQOAAAQHIEDAAAER+AAAADBETgAAEBwBA4AABAcgQMAAARH4AAAAMEROAAAQHCJci/gXGI5p5hc6YWGkt+VnRU319YczHj1do015troxEl749YWe60kl8t51fuIxrLm2kJLg7k2fvy0uVaS3LjHMWtu9OqtvlP22nTaXBob8nt++PRWwu97q9QbZ8y1sWy9V28Xt689PjJurq07aP+aJWlsUZO5tqZnyKu3S9rP44lM0lxbqLL3laSaPvvjFc/kvXqraHvxdPmpn8u4wgEAAIIjcAAAgOAIHAAAIDgCBwAACI7AAQAAgiNwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIKruGmxzv12Yl0+b5ws6TkttpCzT/vLF+yTSyWpWLD3jhXtUwbluW6VsXdULNpbF+zTS13Rb92u6DHZ0ffxch6PVzGy15ZxnxU9HmvJ7/HO5+3TRyXJOY/vC32OucdzS5LyOfsx9z2Xupj9mOVz9pfFfAmTU88mKthfwFy+PNNi336s3n7tfi+Rm8q9PkDHjh3TggULyr0MAAAwRT09PZo/f/573qfiAkexWNTx48dVX1+vKHr3d1ODg4NasGCBenp61NDQUIYVzjwcs9JxzErHMSsdx6x0HLPShTxmzjkNDQ2pvb1dsfe5slRx/6USi8XeNyVJUkNDA5utRByz0nHMSscxKx3HrHQcs9KFOmaNjY1Tuh9vGgUAAMEROAAAQHAzLnCk02ndc889SqfT5V7KjMExKx3HrHQcs9JxzErHMStdpRyzinvTKAAAOP/MuCscAABg5iFwAACA4AgcAAAgOAIHAAAIbsYFju3bt+vCCy9UVVWVVq9erRdeeKHcS6pY3/zmNxVF0aTb8uXLy72sivLcc8/p2muvVXt7u6Io0hNPPDHp88453X333Zo3b56qq6vV2dmpQ4cOlWexFeL9jtmtt976rn23fv368iy2Amzbtk2XX3656uvrNXfuXF1//fU6ePDgpPtkMhlt2rRJs2fPVl1dnW688Ub19fWVacXlN5VjtmbNmnftsy9/+ctlWnH5PfDAA1qxYsXEL/fq6OjQv//7v098vhL22IwKHD/84Q+1ZcsW3XPPPXrxxRe1cuVKrVu3TidPniz30irWJZdcohMnTkzcfvGLX5R7SRVlZGREK1eu1Pbt28/6+fvvv1/f/e539eCDD+r5559XbW2t1q1bp0zGbxjYTPZ+x0yS1q9fP2nfPfzwwx/gCitLV1eXNm3apD179ujpp59WLpfTNddco5GRkYn7fOUrX9GPfvQjPfbYY+rq6tLx48d1ww03lHHV5TWVYyZJt91226R9dv/995dpxeU3f/58fetb39K+ffu0d+9eXX311bruuuv0q1/9SlKF7DE3g1xxxRVu06ZNE38vFAquvb3dbdu2rYyrqlz33HOPW7lyZbmXMWNIco8//vjE34vFomtra3N/8zd/M/Gx/v5+l06n3cMPP1yGFVaedx4z55zbuHGju+6668qynpng5MmTTpLr6upyzv12TyWTSffYY49N3OfXv/61k+R2795drmVWlHceM+ec+/3f/333J3/yJ+Vb1Awwa9Ys973vfa9i9tiMucIxPj6uffv2qbOzc+JjsVhMnZ2d2r17dxlXVtkOHTqk9vZ2LVmyRJ///Od19OjRci9pxuju7lZvb++kPdfY2KjVq1ez597Hrl27NHfuXC1btkx33HGHTp8+Xe4lVYyBgQFJUnNzsyRp3759yuVyk/bZ8uXLtXDhQvbZ//fOY/a2f/mXf1FLS4suvfRSbd26VaOjo+VYXsUpFAp65JFHNDIyoo6OjorZYxU3vO1c3nzzTRUKBbW2tk76eGtrq37zm9+UaVWVbfXq1dqxY4eWLVumEydO6N5779WVV16pl19+WfX19eVeXsXr7e2VpLPuubc/h3dbv369brjhBi1evFhHjhzRn//5n2vDhg3avXu34vF4uZdXVsViUXfeeac+/elP69JLL5X0232WSqXU1NQ06b7ss9862zGTpD/8wz/UokWL1N7ergMHDujP/uzPdPDgQf3bv/1bGVdbXr/85S/V0dGhTCajuro6Pf744/rYxz6m/fv3V8QemzGBA6XbsGHDxJ9XrFih1atXa9GiRXr00Uf1pS99qYwrw/ns5ptvnvjzZZddphUrVmjp0qXatWuX1q5dW8aVld+mTZv08ssv816qEpzrmN1+++0Tf77ssss0b948rV27VkeOHNHSpUs/6GVWhGXLlmn//v0aGBjQv/7rv2rjxo3q6uoq97ImzJj/UmlpaVE8Hn/Xu2r7+vrU1tZWplXNLE1NTbr44ot1+PDhci9lRnh7X7Hn/CxZskQtLS0f+n23efNm/fjHP9bPf/5zzZ8/f+LjbW1tGh8fV39//6T7s8/OfczOZvXq1ZL0od5nqVRKF110kVatWqVt27Zp5cqV+ru/+7uK2WMzJnCkUimtWrVKO3funPhYsVjUzp071dHRUcaVzRzDw8M6cuSI5s2bV+6lzAiLFy9WW1vbpD03ODio559/nj1XgmPHjun06dMf2n3nnNPmzZv1+OOP69lnn9XixYsnfX7VqlVKJpOT9tnBgwd19OjRD+0+e79jdjb79++XpA/tPjubYrGobDZbOXvsA3t76jR45JFHXDqddjt27HCvvPKKu/32211TU5Pr7e0t99Iq0p/+6Z+6Xbt2ue7ubvef//mfrrOz07W0tLiTJ0+We2kVY2hoyL300kvupZdecpLct7/9bffSSy+5119/3Tnn3Le+9S3X1NTknnzySXfgwAF33XXXucWLF7uxsbEyr7x83uuYDQ0Nua9+9atu9+7drru72z3zzDPuE5/4hPvIRz7iMplMuZdeFnfccYdrbGx0u3btcidOnJi4jY6OTtzny1/+slu4cKF79tln3d69e11HR4fr6Ogo46rL6/2O2eHDh919993n9u7d67q7u92TTz7plixZ4q666qoyr7x8vv71r7uuri7X3d3tDhw44L7+9a+7KIrcz372M+dcZeyxGRU4nHPu7//+793ChQtdKpVyV1xxhduzZ0+5l1SxbrrpJjdv3jyXSqXcBRdc4G666SZ3+PDhci+rovz85z93kt5127hxo3Putz8a+41vfMO1tra6dDrt1q5d6w4ePFjeRZfZex2z0dFRd80117g5c+a4ZDLpFi1a5G677bYP9TcFZztWktxDDz00cZ+xsTH3R3/0R27WrFmupqbGfe5zn3MnTpwo36LL7P2O2dGjR91VV13lmpubXTqddhdddJH72te+5gYGBsq78DL64he/6BYtWuRSqZSbM2eOW7t27UTYcK4y9hjj6QEAQHAz5j0cAABg5iJwAACA4AgcAAAgOAIHAAAIjsABAACCI3AAAIDgCBwAACA4AgcAAAiOwAEAAIIjcAAAgOAIHAAAIDgCBwAACO7/AVhDmPoxXzoeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset['images'][0])\n",
    "print(dataset['bboxes'][0])\n",
    "print(dataset['images'].max(), dataset['images'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "24\n",
      "32\n",
      "bbox:  tf.Tensor(\n",
      "[[ 1  7 11 17]\n",
      " [19  2 29 11]\n",
      " [25  0 32  5]\n",
      " [25  5 32 12]], shape=(4, 4), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 10:00:33.002497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20889 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1d:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:33.002742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21939 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:1f:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:33.002963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 21939 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:20:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:33.003202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 21939 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:33.003426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 21939 MB memory:  -> device: 4, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:22:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:33.003650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 21939 MB memory:  -> device: 5, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:23:00.0, compute capability: 8.6\n",
      "2024-04-16 10:00:33.003878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 21939 MB memory:  -> device: 6, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:24:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAHkCAYAAACuQJ7yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe8UlEQVR4nO3dW6xd+X0X8O/ae5+7z7F9bI89ySSTZqI0VYHS0AutVBShPiFVwAMUEBKXviBKpQpEQQiKWuWFigcQFITUxwoQSBWlKiBaUKuAqCBBpU0vSZrJTOaWGY/tsc/97MviYWZsKuSz10l+9Tj+fz4v68F/fdfae92+Z8n7v7q+7/sAANCM0Xu9AQAAPFoKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0JjJ0IF/5Pt+omyl46NFWVaSHF1bKcsazevmxe7mZVFJks3XjsqyZpt131mSjOZ1+3T1+ZtlWf3de2VZSZKnrtRlra2WRS02ivfn77xUltVtbZVlJUl/absua2VclzWp/Xt6dK/ufF9sr5dlje8clGUlyfTGxbqw4tcaTHfqzqvxad01slvUftCTS3WfczHp6rJW6rKS5O6H687Rw+dOy7KSJIu6z/riD/zIoHGeAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGjN4ImgA4OvDP/v0T2b3dH/Q2H5UOOFy7dzNpRaFjaefFM86XmngRNAKIAA8YXZP93PttPhNSDxRFEAAeELN0+X26tmvT/QE8Pwe5yeATw8cpwACwBPq9up2/sx3/60zx3gX8Pk91u8CHjjOj0AAABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYwZPA3NycVy20u3btT+fXr9T9/Pp6Vbd55xu1v6EvR/X9fXx0awsK0lGx7V5ZcZ1+zNJ0hXu09m8LqsvntFpZbUua1T8d+a07ljrCvdBNyk+1h5Xh0elcaOjrbKs+YXC4zZJXzilydFO3VQrk+Plc9C9O7dfP+pyumTdp9t152jlVCurd8uiyq2+Wrc/k2S+Xho3iCeAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRmMnTgyuHi93I7vibTrXFZ1nytK8tavz0vy0qSyW9/uSyr29kuy0qS+ZW6vP70tCwro7r9Wa07ndZlzVbKspKkm9SdU9X7oNs7KM0r0/e1eZsbZVHdrO763c+L7wXjuuPj+NpqWVaSnGzXPSO5+Ym669rqy8s/5+KXkhwni9XkK99x9vk8vVi3TydP7Zdl7b1Rdw4kyeardde1Re2hlsX1k9rAATwBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGjN4HkAAnlz/5HM/lcuzAXO4Vc8DeKfuOUT/2dpnGn3hFJaLn62bJ7KbL9+wa3v37i8/9RM/fubYvvBr60Z1n7NfFM8heo6ped/c2s6f/kt/vXT9jxsFEIBcnu3n2nTv0a+4sk/Wza1e7/C9We2473Pj3t33ZuU81hRAAO6bp8vtlQtnDKh+E0jhE8DJY/wEcO3RPwEc933mXZeb2ztnjvUE8IFr+29/by1QAAG47/bKhfz5b/7hh/579+qbpetbPHu9LOvgg1tlWcnX96vgPvUTP54b9+7m5vZOvudHfvTMsbWvgjsqy5q9B6+C+6//9MdyY6+NJ6Z+BAIA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRm8DyAB9eXz58z1Frhq3+SZP3NuvmVFit12zZfK+7Xu5fqsk5rp8wfffGVsqx+NivL6gonmU2SVE4QWrkP5sUTl47rzvfqiYMXd++VZXWbdfOM9Yd1858lyahwH3Qba8sH9Q+W3eyMfXbxjEmivwrHT9Xtg7c+XHjcJplt1mV910efL8t68enLS8eMVuf3l1e//fUzx/7N5/5zyXYlybxwVul/e/PbyrKS5Dde/tjyQf/veXDGaTA+rp2kevHm8rkdq3kCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMZOhAzffWJSt9OTSSllWkhxfHpdlbX1lVpa18cpeWVaS9F+5WRf2vut1WUn6y9t1YZ9/oS5rMvgQH2bUyN9MXVeX1fd1WUn6ad05OtraLMvqT07LspIk83ld1uycWWeMP33m8te4Mb/b3jN15+jh++vuU0my2KrbBx/avFWW9Yndzy0dszk+vb/8C8/+yplj/8TWfsl2JcmXpnVZP3az9j41GbBpXf9gedb4UfHpXnrNHaiRuxkAAO9SAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANGYydODpdl1XvPDKaVlWkqzdnpZlTe4clWXNd9bKspJk9LEPlWUtxl1ZVpJMXni9LKtfK/zexsV/43S131uVbrGoDZzN6rLG47qsJKON9bKsfr3uWBvtbJdlJak91vp+yKAHyzPGHzy9WrJJ7zrZrfuci415WVaSjC/U3VvuzTbKsp6a3Fs6ZvzO/hynXzr+3x1cKNmuJDlYXCnLmv7q5bKsJJntLh/Tjx4sT84YP9scck4N1z13UJo3hCeAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGDJ4IGgD4+rB26+3J3Ndfn+ZPfvRXH9l6K6dH/nP9/yxMG2b0ziTo1/fu5jc++Tce+fpL/Km/N2iYAggAT5hu8XaR6ZKk+EVBZ663NK32bRvn0SUZD3qDztcvBRAAnjD9KOkW71SoR/ifvSorU98/+ldvjvo+Xd7+HIvH9NWfywx9+aYCCABPmJMrK9l4fZrj6yv5j//9mx/Zeg8Wde/X/uS/+v6yrCTpBrzi/Jf+0Y/lxt7dvL59MZ/44b//0HGP87uAvzBwnB+BAAA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYMngZmclQ3k+RoVjsr5WKlrscuLqyWZaV4DqHuaFoXtl47A1B/cbssq7u7V5bVzwb87v8cutO6fdCfnJRldXu1f8st9uumJBhd2CrLSpJu+0JdWOX+3Kib/iJJunnhdfK8E9qeMf54t/ZYm1decqeP77xtn3rlw2VZ92bLj7VPLD6fjUxztFjJz7z58TPHfnTrjapNy+botCzr+AN1WUmS0fLzoJ/095dHzz38Gr2yUXg/TnL14n5p3hCeAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQmMnQgXsfGJetdONmV5aVJCv3Tsqy5lsrZVn771sry0qSjVuDd9dSk71pWVaSjA+OCsPqjrUcH9dlJekP6z5nv39QlpX5oi4ryWJvryyrW18vy0qSbrsur799pyyr271cllWtG3B8dP2D5VnjZxtVW/XuiuuiRqe195b0dXlXL9Sd7799+/rSMdPF+P5y2fin1++VbFeS/PuXfn9Z1s6Vwmtkkntf2V4+6N193nfJycPvRR/50GtFW/W2k3nd/X0oTwABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGPPqJZwb655/+yeyeDpyLbNHXrbirm/epH9fOSdVVfs7CqGTYPGPD1W1cX/mdJaXHx3mO2zvden5o/Y/VrRuApj22BXD3dC/XTuomp4QSxX3ysV8vAE+kx7YAvmueLrfXlsze7Qng+XkC+NV5xE8Ad3OUsfYHQLHHvgDeXtvO93/33z5zzGT/tGx9j/er4GZlWdWvglt56c26sL6wAB7Uvkooa3X7tL+7/An3Tx/9TK7lsGydAJD4EQgAQHMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANCYwfMA3vgfdfOpLdbGZVlJMt+om7vv+MpqWdbes7X9+vXvqvveRqe1U0C+71PvL8va/tXXyrK6iztlWUmSk7o5J7unry8f8+IomSfdeJTRGeP7t2rfmjPa3CzL6ra3yrKSJKeFc1heu1IWVT1d9/xy8fe2RP/lt4+1fjTK7OrDJ9/ffrly0vfk+FLd5OrTJe8MOK/5Ud0198tv7JZlzd5afp9azEf3lzdfvHzm2H/z0neUbFe19StHpXnd5oC5dLv+/vKs8c/frLt2vFc8AQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0JjJ0IF3vmmzbKXrby2WjulH3f3lye7KmWP3b4xLtitJ3vqD07Ksbr0uK0m6W6tlWeMPHJZlJcneXz4ty9r60QtlWaPXb5dlJUl/Uvc5+xtXlo8Zdcn87eXi4tZDx3Urg0/lQfovvVQXdlp7HvQ7D/8ezh/Wl0V1J8Xn+3T5dXKofqXub/1F3eU2STKa1WWt3yx+pnGz7pq79tbZ97HzmG10S8e8+72OZsnO58++Phw8U3esLdbqzqmTw7rvLElyd0Be3z1YnrHPToqvud18+T6t5gkgAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI2ZDB04PunLVnrzW8ZLxyx+IclRslhZPv7j3/tbRVuWvHa4U5Y1GS3KspLkpfVLZVl/9hs/U5aVJD//8jeXZf32X7tUlnX9ly+WZSXJ7i88X5Y1urO3dEy36O8vzxrfr6+VbVeSjJ+6WpbVr6+WZSVJbr1Vl3Wp7nzP6bQuK8nodFaWtRgNudT395fd/OHXrlHdZiVJ1u7WXSdX97qyrCRZv1O4D1bqtu1od8D+XDxYrt86+/49X697FjQ+KotKP17eFc5jZX95jxlNHywvf/bh38vppdpjbVH7UQfxBBAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMmgwce92Urvfy5xdIxo+mD5bLxn/2WGxWblST5zqe/XJb1h7ZfKMtKkn+x/z1lWddX7pZlJckfvv5CWdZ/+rVvK8vaf39XlpUkk+/5hrKszddOlo7pXx0l86QfjzJ95spDx628eLNsu5Kk39svy+om47KsJOlPln9vQ3Wn07KszOd1WUnS111zu5MB29Y/WJ41fu1u7eecHMzKsrr58nvLeUxuHZRlHXx0tyxrcrz8c3b9g+Wy8Zuv1T0L2n75tCyrr718ZzRffk6NZv395eUvPPxac3BjtWy7kqSvvUwO4gkgAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxgyeCBuDJtzvbz0//1j9+6L/3n6+dnberm++63qJu4/oXCp+3DNgFV47u3V/+7M998syxlRMuD5ls+XG2e7L3Xm/CI6MAAnDfOH2uzc64Cda9uKMt79H3Nk6fp45q3/zEk0EBBCB3Vi4MGtePPQH8avSTR/8EcJw+83S5tbFz5lhPAP9/t1e33+tN+D2nAAKQH/rIDwwad/xM7Y3Ru4DPb7a+vLH97M99Mk8d3c2tjZ388e/7u2eOnW56F3CL/AgEAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANGbwNDDjk7qfTx9eW947+9GD5cnO2b8F7//b5YrNSpL8+h+dlmX94me/qSwrSb7zY8+XZX1m70NlWUky6+v+lphv1B1rs7rdmSQ52a77nGt3xssHdQ+W8/WHj1+p2aQHRnXzL/Rrq2VZSdJtbdWFLQqnDVmt3Qv9at0sXd1R3dQca7eOy7KSZLRfl7dYrz3W+pW6fbDxlaOyrCFzMXbvTHnSzftceOnsdc82647d1VuHZVnTyxtlWUnS9XX3lrW35mVZSbKy/+hnCvcEEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQmLpZLgGAx8ru6V7+5Wf+4dmD6uZ9TxZ1ky1XTkifJCnctMJ3HyRJusI56ZO/M2iUAggAT6hx+lw7vfdebwaPIQUQAJ4wd1YuDB/sCeD5ox7jJ4DXBo5TAAHgCfODf+CvDB7rXcDnN92srU+V7wL+LwPH+REIAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQmMET2Rw+NS5b6eUvnC4dM5r195fLxt/+xrWS7UqSvU89VZa19e13y7KS5Nf+w8fKsk4+dlSWlSSL07rjY+VG3TxSay+eYzLUAa5+5nZZVne0/DzIfHF/ufblOw8ft1o3j1eSdFtbZVn9pO7YSJIU5vUrj+9UqH1XNwnuaFo3x9jocMBxew7d4XFd2PpqXVaSfr3u+OhOpmVZoyHXjnMY79VdP7qjk7Ks0YW6e3uS0kmqV1J3TiXJ5F7heTCQJ4AAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABozGTrw2s9/sWylt7/3w0vHLMbd/eXBjZUzx1764mnJdiXJnY+ulmVN/9fFsqwk6T++V5a18pvbZVlJsvubi7KsCy9Ny7Imd26WZSVJd++gLGtxdcDx0XX3l/3m2sPHHRzXbNT9vLrP2a2eff6e26jw79aVwZfApbrD2n0w2j8qy+oPDsuysla8Pwt103lt3nFd3uzSZlnWpPhzpu/rsqazsqjxQd29PUm6w5OyrMXWelnWe8UTQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaMxk68Ohbny1b6c6XjpaOGc36+8tl408vrpZsV5Jsvzwvy9r/i3fLspLk5NO7ZVlbr/ZlWUly6ddvl2X1K+PHMitJukldXndwvHxQ399fnjl+VPy33PtvlEXNVwdfZgbpfufLdVkffF9ZVn98UpaVJDkccHwM1B8elmV1l3bKspKUHrtd9T649VZZ1Hjt6bKszBd1WUkWOxtlWV3hNXexXnvtmNy6V5Y1Gtdec/tx7b1qCE8AAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0ZjJ0YF9YFefrA1bbPVguG7/5/J2vfaPecfvbrpZl7fzUTllWkhzt9mVZu7+5X5aVJIuttbKs0fOvlGUtPvh0WVaS9CuDT5nlum75mIHju8Pjr3Fjfrd+Oq3LevZ6WVaSdM++vy7s5LQsqpsUHhtJ+uO6fTq6fq0sa7FW+zkXX3yhLKv72EfKspKk/8gzZVmD7nsDrd47LMtKku54Vpc1rcsaHxRf19ZWyrKOPnixLCtJ+vE57wcFPAEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANCYydCB3bwvW+loulg+qH+wXDZ+sbn2tW/UO7a+Mi3LmuydlmUlycbLA763gca375VlJUm/ulKW1e1sl2WNDo7LspKk31ovy+rOu239GefgWf/2VejW686pyWt3yrKSpF9frQu7c7csqr+0U5aVJF3XlWX1d+vO926t7lxPku7Dz5ZlHb/vQllWkqy9cViW1U3qnrcsbt4qy0qS7oPvK8vq1wbXiqWOPnC5LCtJtv73S2VZq3dOyrKSZL5Ze14N4QkgAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxdTM2/h7ZPd3Lv/6Vf3D2oMpJcEd1k6+mbt7md9R9zm5RO3FwX/i1dYWbVrldSZLCyXmHHLe7s4O69QHAOx77AjhOn2untW+tAABo2WNbAG+vnuOVPp4AnpsngF+lR/wE8F13xlt16wWgeY9tAfyrH//BwWPH+3Xv3J3u1r3rtfpdwN2QdygP9Fi/C3g2L8vqV2oP8X6j7j20534XMAAU8SMQAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMcMnSSucALcf187OO7u0Vpa1+uZhWVZ3PC3LSpL+1dfrwrY267KSpHC+vcVO3baNbtXOd7jY2SjLKj0LKieoTu38iYsXXynLSpLxU1fLshbPXC/Lqj7W+uPCeSInj+2Ur1m8+HJZ1sZe7asT+2ndNXxl+xwvN1hi9k0fKstKkvFB3Zy1i/W6OWHXXz8qy0qSg2/9QFnW+hu127ZypzZvCE8AAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0ZvJerLQfdaV5o/miLKub1WVlUZiVpNvcKMvqt7fKspKk31ity1otPCxXag/x0eFpYVjh31+rK3VZSbqTaV1W8T4oPa8Ks/q798qykpQeu93WZlnWfGutLCtJRmuFeeNxXVaSXN4pi9p/7lJZ1tbv3CnLSpJF4T7t+rKovPmt23VhSZ765TfKshY7dffjJLn30bpjbShPAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANGYydGC36MtW2vV1WUkyuXtSltWPu7KsuqS39TeulGV1s0VZVpJ088J9Op2XRfWb62VZSZI379RlXdopi+pXBp/Kw9zbK4saXb9WlpUkmdUdH4vN1bKs/vd9Q1lWkpxertu29TeOy7JmF1bKspKk+5bnyrLma7XPNMYnddfJlf1ZWdbN77palpUkOy+elmVV7oMr/2e/LCtJbn3nU2VZm29My7KS2u4xlCeAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRmMnTgYtKVrbQfjcuykmQyKeyx87rP2a2ulGUlyXxrtSxrfO+kLCtJRgdHdWGF31u/UfedJUk3m9WFLRZ1WV3dcZsk6fuyqMXWRllWUnusHV9bL8saH83LspLkZKfwOrmo+5x94b0gSVbvTcuyxieF51SS+VrdveXoWt117eKXaq/fs826Y+10uy5r75kLZVlJcvXXDsqyZpu19/fpRvE1fABPAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMYogAAAjVEAAQAaowACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANGYydOBipStbabcoi0qSHF/fKMvaeHm/LGuxPvjrHWR876Q0r9TRcV3WuO7vku50VpaVJLl8sSyqO52WZWXR12UlyUbdOdUdFh4bSTKt26cbrx6UZY2+8FJZVpKsPveBsqz5hdWyrJPdlbKsJBkd1e3Pbl57czm5slWWdeHVuuv36XbtPpgczsuyZlfr7ntXfuOoLCtJ9p7dLMvafOO0LCtJLr7w6O/vngACADRGAQQAaIwCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0JjJ0IGjaV+31sKoJDm5PC7L2vzccVlWf3GzLCtJutfeqAu7frUuK0k/nZbmVemOTkrz5ld3yrLGr94qy+pPi7//3Yt1Wa/frMtKkrW1sqjRXt35XrldSZJJ3d/nq6/cKcsanWyXZSVJP677nOOD07KsJLnwubrv7ejZS2VZmy/tlWUlSb9Sdw+dHK+UZc3X67YrSTZfrzs+xsezsqwkyaK4GA3gCSAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANAYBRAAoDEKIABAYxRAAIDGKIAAAI1RAAEAGqMAAgA0RgEEAGiMAggA0BgFEACgMQogAEBjFEAAgMZ0fd/37/VGAADw6HgCCADQGAUQAKAxCiAAQGMUQACAxiiAAACNUQABABqjAAIANEYBBABojAIIANCY/wvUoyYqpE8VqAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " ...\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.max(), images.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_SIZE_WIDTH:   32\n",
      "IMG_SIZE_HEIGHT:  24\n",
      "N_DATA:           828\n",
      "N_TRAIN:          663\n",
      "N_VAL:            165\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.2)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 24, 32, 1)\n",
      "(828, 4, 4)\n",
      "(828, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "\n",
    "    number = numbers[idx]\n",
    "    class_id = cls[idx]\n",
    "    # print(len(cls))\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "\n",
    "    number = numbers[idx]\n",
    "    class_id = cls[idx]\n",
    "    # print(len(cls))\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "# LR = 0.0005\n",
    "\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        # 'number': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    # image = image / tf.reduce_max(image)\n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    # num_boxes = tf.shape(bbox)[0] // 4\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    # number = tf.cast(parsed_features['number'], tf.int64)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "# LR = 0.0005\n",
    "\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        # 'number': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    # image = image / tf.reduce_max(image)\n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    # num_boxes = tf.shape(bbox)[0] // 4\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    # number = tf.cast(parsed_features['number'], tf.int64)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[[0.         0.625      0.25       1.        ]\n",
      "  [0.34375    0.625      0.625      1.        ]\n",
      "  [0.3125     0.125      0.625      0.41666666]\n",
      "  [0.34375    0.375      0.625      0.6666667 ]]], shape=(1, 4, 4), dtype=float32)\n",
      "tf.Tensor([[1 1 1 1]], shape=(1, 4), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.5625     0.625      0.84375    1.        ]\n",
      " [0.0625     0.625      0.375      1.        ]\n",
      " [0.84375    0.08333334 1.         0.5416667 ]\n",
      " [0.625      0.08333334 0.84375    0.5416667 ]], shape=(4, 4), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGdCAYAAABZ+qqcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuF0lEQVR4nO3df3Bc5X3v8c/ZXe3qt2RZlmRh2Zb5GX7YaVwwmhBCsIvte4dCoC0Q7r0mZWCS2p0QN01jbgOBZsYZcie/eh24vWlx2zSYkBtgkklog4nNTWpDbfB1SIixjcA2tmT8Q7+1q909z/0DkCOklXefRw+7Mu/XjGZtnfPV99HZs0cfHZ09T2CMMQIAAPAoUuwBAACAMx+BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3sWIP4N3CMNThw4dVU1OjIAiKPRwAAJCDMUb9/f1qbW1VJDL5OYySCxyHDx9WW1tbsYcBAADydPDgQc2ZM2fSdUoucNTU1EiSzrv9HkXj5QXXxwfc7tSeKbc/q1LXOeLUW7Lvnam0/+tYoidtXStJQTq0rg0TUafesUH7sQcZ+3EH6ax1rSRlK+P2vbP245akwGE2g8iQw77Sfcy+1lGQSLh9gSLOABE2N1jXDs+utK4tPzpsXStJ2XL7Hy+REbfXV2Q4Y12brbZ/bTocwiVJmeoy69redvtaScrG7QafHUnqle/cP/qzezIlFzje+TNKNF6uaKLwwBEdcTswGMuNLkmxmOMlMS5/Qiqz7x2Luf3QD4xD4HDs7TL2wNgf1ILQ7YAYxOx/AAaBY+AIHQJH1GEfDxwO5I6CiGPvYgaOqP2+Eisr/Bg6Wht13M9i9j8AI46vr0jU4RcRh9ema+CQwzaLxt0ChxJug8/nEghvF41u2LBB8+fPV3l5uZYsWaLnn3/eVysAAFDivASORx99VGvXrtW9996rF154QYsWLdLy5ct19OhRH+0AAECJ8xI4vva1r+mOO+7QJz/5SV144YV66KGHVFlZqX/4h3/w0Q4AAJS4KQ8cIyMj2rlzp5YtW3aqSSSiZcuWadu2bePWT6VS6uvrG/MBAADOLFMeOI4dO6ZsNqvm5uYxn29ublZXV9e49devX6+6urrRD94SCwDAmafodxpdt26dent7Rz8OHjxY7CEBAIApNuVvi21sbFQ0GlV3d/eYz3d3d6ulpWXc+olEQgnX98gDAICSNuVnOOLxuBYvXqzNmzePfi4MQ23evFkdHR1T3Q4AAEwDXm78tXbtWq1atUq///u/r8suu0zf+MY3NDg4qE9+8pM+2gEAgBLnJXDcdNNNevPNN3XPPfeoq6tLH/zgB/XUU0+Nu5AUAAC8P3i7tfmaNWu0Zs0aX18eAABMIyU3l8o7mp/vVyxW+P3wh2dXOPWten3Aurb3/Fqn3vW77Ce36rp6lnVtvNftHvrJFoe5Hobc5msIy+x7J47ZT041MqvKulZym3RupMF+fgxJivekrGuztfa9o0fdLhkLe/vte5c7XpjuMM+RGXabBC1TYz/2yld77Buf6LWvlWTax79JIF/perfnKxq3n2Mp4jCpY+gy15Ck4Zn2P5IzFW7H8fITdvMFZQuYv6zob4sFAABnPgIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA7wgcAADAOwIHAADwjsABAAC8ixV7ALmEiZjCWOHDiw2HTn2H2qqta6u6Uk69B89tsK5t/H9D1rUjdXHrWkmqOmDfe7i1wql3vDdjXZtssu9d3m3/PUvScGuVdW3imNt+lq61f77L+kasa4Ma+9eWJEXqa61rs/X221uSol0nrWsHrzjfqXflgT7r2sPLZlnXNrxsv70lKTXD/sdLxZtpp96xnqR17UiT/b6SrXD7HT6WNNa1UfuXpiQpVR9Y1WVT+ddxhgMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3pXs22IB4Ez3v5/9phpSA5OuE2Tt3+of7rP/nTKSsX+LpiSZiN3bLCUpCN16K+tQ/0rucdePDChijMIgUE98/Nu8jf23/Db7L2CixWndb4zOzXNdAgcAFElDakBNyV5/DdxuZ/H+lMetfaLGaFbK/v4oZ5JC7mZE4ACAIssq0PHyiW+05XSGI84ZjoJFc4+7MdWnQJKRdCwx/vl6v57h0GB+4YvAAQBFdry8Vjf+wX+fcJnLnUaPfNT+7sUNL7vd0baYdxotO+Zw5+VJ7jT69Oa7FZVRqEB/csW6cctd7zSadQiIA2e5JY7Q8unKppLSt+/Oa10uGgUAAN4ROAAAgHcEDgAA4B2BAwAAeFeyF41GUhlFsoVPPT7c7DbVesWb9nP89s9JOPWufNN+qvVMdZl1bSRtfxW8JJky+4uVEsfdLg5zuQq/srPHujY1223q7qo9x61rR86qc+pd/ka/dW1YYb+fmQH7C/kkySTtpxyX4/T0Lqr2nsi5LMiEo4+51uu+yn6K+dRM61K9cYfbazPYY38snvFbt+N4tcO7VIaa89vHJ1ovU+H2NhWXd7kMtDm+q6ht2KouHMr/dckZDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3sWKPYCpFhsK3b6AQ3ksaZxam8C+NnEiZV0bxqP2jSVFB0fsi0O35yvSN2Rdm51ZY12b2P2ada0khW0t1rXxlw469VZTg3Vp9Fiffd+qCvtaSWqosy51e2VKJpm0rj18w7ycy8JDEWlACssjOry8KUdz69b63E0/tK5tKztu31jSGnOLdW3XrHKn3hVvOOxrk23v4O3lgdS7YPzv62HCbU9Ltaataz9y0StOvdsr7Z7v1EBaX81zXc5wAAAA7wgcAADAOwIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA7wgcAADAu5Kdnt6URWViFtOmO0zxLkllXb3WtclZs5x6V/6my7o2rKu2ro3sdpvWOKix7x0kEk69TaX9NNaRVw/bN26aaV8rKdjTaV98lv3U9pKk7mP2tbU11qUm6vj7zbET1qXRZJVTa9NQb11bNjDJlOXhqcdc6438YY91780nPmBd+4WzfmpdK0mXz3vNuva3Nc1OvY9V1FrXRuLZvNYbuWho/CeN2w+gyvIR69raWMqpd1102KouGc3kvS5nOAAAgHcEDgAA4B2BAwAAeDflgeNLX/qSgiAY83HBBRdMdRsAADCNeLlo9KKLLtLTTz99qkmsZK9NBQAA7wEvSSAWi6mlxfFKegAAcMbwcg3H3r171draqgULFujWW2/VgQMHcq6bSqXU19c35gMAAJxZpjxwLFmyRBs3btRTTz2lBx98UJ2dnfrIRz6i/v7+Cddfv3696urqRj/a2tqmekgAAKDIpjxwrFy5Un/8x3+shQsXavny5frJT36inp4eff/7359w/XXr1qm3t3f04+DBg1M9JAAAUGTer+asr6/Xeeedp3379k24PJFIKOF4t0kAAFDavN+HY2BgQPv379fs2bN9twIAACVqygPH5z73OW3dulWvvfaa/v3f/10f//jHFY1Gdcstt0x1KwAAME1M+Z9UDh06pFtuuUXHjx/XrFmzdMUVV2j79u2a5TixGQAAmL6mPHBs2rRpqr8kAACY5kr2FqBBOqvA5DdN8O+q2nXUqW+mrdG6tvY/3nDqPTLPvnd83xH7xmc5Xl9jJpl++3RG0m69+wbsaxtn2Nc6TJUuSZGWJutac6LHqbccplo3Ds+1qXS7ONzU2u+nkWT+U2hPZKTJfnr7Y5flPo6F/0fSkBTGc69X7TDl+WX1nda1zwy6TUnxR407rGu/m+1w6j0wbL+v1VVNMk17IMm89ThrxvhbPfQMVFr3laThI9XWtT/pv9ipd1mF3bE4HEpKeiavdZm8DQAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAd7FiDyCXbGWZglhZwXWRWfVOfaPH+q1rU+c0OfVOdB6zrk1eOMe+7//rtK6VpOzZZ1nXxg6+6dQ7qCi3Lx5J29fW1drXStJw0ro0qKl2650NrUtNRcK6NnLC/rUlSaa2yr42Gjj1Ts0o/Fj0jrKTuX+vC8JTj2UnoxOuUz4nY937Bwc/ZF17UcMR61pJuq76JevaP2ra4dR7JHu5de2+4415rdc/PP7YkzxeYd1XkmKD9ucAIr1xp95Vh+zqsyMT77cT4QwHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA7wgcAADAOwIHAADwjsABAAC8K9np6aNDaUVj+U97+47IsV6nvqbOfurvxL6jbr3L7acXThzqsa4Nyh2meJcUGbKf5t2E9lOlS5LKHHbhiH3eDgaG7PtKMiMj9r2dOkuK20+1HvQNWteafrfp6eXw+gh63HrHWmusazOtuV8fJmpGHzOtqQnXiUbsXyO3zP0P69pXh2dZ10pSTcR+T22Kuj1fu187y7rWZCY5LphTj4Mnx09Fv+gDr1v3laTfHGm2rjWvVjn1TtXbPV/ZVP51nOEAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOBdrNgDyCXIGAUmLLjOlMfdGqdGrEvDmbVOrSMn+61rsw32vSMneqxrJSkwxr62POHUW0NJ61Izkravta58S1BdZd/bdZu5PF8Or4+gvs66VpLCCvvXdmSk3Kl3NJm1ri07mPv5CrLB6GOu9Y4GDseV+falF1Yeti+W9N2+i6xrn3jjg069FTjUpvP8PXyC9V56Y7ZDY2lG7ZB17fG6Cqfe9a/YnX/IjuR/POEMBwAA8I7AAQAAvCNwAAAA7wgcAADAOwIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCvZ6ekVC6Ro4XkoSNpPny1JmdYG69pYd49T72xTvXVt5EC3dW0Qc9sNzNET9sVVblMqm0zGvtihNnCdIj5in/WDtMP3LElZ+6nWlQ3ta12eK0kRk/802O9mkimn3vE3B61rG3fHcy6LpE89Nu6e+Ps7kSm37v3axY3WtZdWv2pdK0lff3mpde3g0Sqn3tWv2h/TYnnOEF//0vgefZenrftK0rHDdda1czY7tdZgs11dNpr/upzhAAAA3hE4AACAdwQOAADgXcGB49lnn9W1116r1tZWBUGgJ554YsxyY4zuuecezZ49WxUVFVq2bJn27t07VeMFAADTUMGBY3BwUIsWLdKGDRsmXP7AAw/oW9/6lh566CE999xzqqqq0vLly5VMJp0HCwAApqeCL+VduXKlVq5cOeEyY4y+8Y1v6K//+q913XXXSZL+6Z/+Sc3NzXriiSd08803u40WAABMS1N6DUdnZ6e6urq0bNmy0c/V1dVpyZIl2rZt24Q1qVRKfX19Yz4AAMCZZUoDR1dXlySpuXnsG3qbm5tHl73b+vXrVVdXN/rR1tY2lUMCAAAloOjvUlm3bp16e3tHPw4ePFjsIQEAgCk2pYGjpaVFktTdPfaul93d3aPL3i2RSKi2tnbMBwAAOLNMaeBob29XS0uLNm8+dY/Vvr4+Pffcc+ro6JjKVgAAYBop+F0qAwMD2rdv3+j/Ozs7tWvXLjU0NGju3Lm666679OUvf1nnnnuu2tvb9cUvflGtra26/vrrp3LcAABgGik4cOzYsUMf+9jHRv+/du1aSdKqVau0ceNGff7zn9fg4KDuvPNO9fT06IorrtBTTz2l8nL7CYgAAMD0VnDguOqqq2QmmbUxCALdf//9uv/++50GBgAAzhxFf5cKAAA48xV8huO9EukdViQaFlxnqiqc+kZfPWxdm21vdeodeW3ie5XkpaHOujT76gH7vpIiDfUOxW6ZN6iqtK41DWXWtWHc7aUTDKXsi0/2OvV2EVRXWdca1+kNJjmz6l1qxLq09pXcNzMMMuHoY6710hX2r+2fdF5oXfvrhtnWtZI08or9Ow7n/jLr1DveN2xdm5wZz73QnHqsPjx+jNGfu106ELXfzRQbyjj1Lj8ZWNVl0vm/LjnDAQAAvCNwAAAA7wgcAADAOwIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA70p2enrFolI0WnBZcMJt6m4zc4Z1rdP08pLC+S3WtcFvX7OujcyfY10rScGw/VTrpnySqaDzam43pbIkhZX2vbOJwvfN3xWN2Wf9aNptGmpl7Kf+NjH77zuoqrSulSSFDtPTR+z3E0ky8TLr2mBgkqnSjRl9zLVe9RH77Zb6hf3U9gfL7GslqW2H/XGh7GTSqXfk8JvWtfGK/KaYr33hyLjP1Ti8PiTJVFdY1w61VTv1rngzbVWXyeRfxxkOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4V7LT06cbK2Vi+U0T/LvClhqnvuWv2k9rnLqozal34sAJ61ozx2Fq+8mmz86nd0XCvjbilnkDh6naIwMOU2Bn7Ke2lyTjML19WO82DbXL8x0kR6xrw5M91rXOjMPU9pIiQaN9cRDkXmROPQbZcMJ1YoP2+3jz8w6vj6TddOXviL5xzLo23W5/PJMkneixLg3K8zuehcdPjq9tm23dV5KC18dPeZ+vquGZTr2H59db1YXKvX+/G2c4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhXsvfhAID3ixnZQf3z6/9rwmXmUJF+L3S8d0mu+4rk1fq4/X1qJEkjDvcQSee+r0REZvTxu/2Pjl9hj+O4HbaZ+tz2E9OZ//00fle/MTonz3UJHABQZFEZNWYHJl6YfW/HUhLs7y/nLo+cFUiaZYbGL7C/z5o7196W9YXcnpPAAQBFciJaddp1TPR9eIYjVsQzHJPcGbbeJBWRUahAPcEEP2qjRTzD4bifmKj9GQ6N9Oe1LoEDAIrkM3P+y2nXSbfOeA9GMt50vrV5ZMfL1rX53tp8wlrHW5vriP3UGmoqzq3NM5mk9PSX8lqXi0YBAIB3BA4AAOAdgQMAAHhH4AAAAN6V7EWjyRlxxcriBddFkw5X+UpKzW+0rg0ybr2HzptlXVuxz+ECrTa3i42iAynr2rC8zKl3kLW/KjxI2b/fMJJ0fN/eSPGyvtO7B4aH7WtT9vuJJAUx+8NVmEw69Y44vGMjO6vOqXdyVuHHwXdUvj5oXRsZcnu+srMdjqXbdzv1jrbaX7w5sqDZurbslTesa12NtNY61Ucydvt4IXWc4QAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHclOz19oietWKzwqcfDuFuGivXbT8k83Frl1Fv2M2ArNa/BujZdbT/FuyQFDQnr2mjSfop4ScqW24/ddjpmSUp0D1nXSlL0ZL99ccZtmzlxmCI+cm67U2tTZv9cx473OfXONNdb1w7Mq3TqPTjb/vuODlfY147Yv64lqez5Pda1kaZZTr3Dxjrr2vjew/aNq9ye66EPNtoXB4Fb7ya713Z2JMx7Xc5wAAAA7wgcAADAOwIHAADwruDA8eyzz+raa69Va2urgiDQE088MWb5bbfdpiAIxnysWLFiqsYLAACmoYIDx+DgoBYtWqQNGzbkXGfFihU6cuTI6McjjzziNEgAADC9FXxZ6sqVK7Vy5cpJ10kkEmppabEeFAAAOLN4eVvsli1b1NTUpBkzZujqq6/Wl7/8Zc2cOXPCdVOplFKpU29F7etze/uaT//zN3+nGemBnMvNS8W7JCYw9m/xNI5vp3LhMm7JcewOvYPQbdz51J+IVukzZ93q1Aen983uTWoIByddx3TbvzXV7HZ7fRmHd60HaYd93L7tW0Yy9rVDjt2P2x+Lg+zp3+Z5IlqpzzT+iXWP96spDxwrVqzQDTfcoPb2du3fv1933323Vq5cqW3btikaHf/KWb9+ve67776pHoYXM9IDmpWe5P4J6fduLACmRkM4qMbs5IFDLrc+4bhQOLc8L+V/awi8h6Y8cNx8882j/77kkku0cOFCnX322dqyZYuWLl06bv1169Zp7dq1o//v6+tTW1vbVA9rSmUV6ERZ9bjPmyhnOArFGY7xZmQHFXU+4qJQWQU6GZ34xk0m4nCGI8YZjsKbO3Z3OBZPdoZjRjjEa9OB9zuNLliwQI2Njdq3b9+EgSORSCiRcLuj3XvtRFm1bl20dtzni3mn0diw/a9gzncadfjtjzuNjvfPB/5Ojdncf7qDHyejlfqvs2+fcFnmrIn/JJyPYt5pdMaeEevaaAF3kJyIy51Gg2q3Y6lpsX++It0nci775+6NajzNn9+Qm/dfyQ8dOqTjx49r9uzZvlsBAIASVfAZjoGBAe3bt2/0/52dndq1a5caGhrU0NCg++67TzfeeKNaWlq0f/9+ff7zn9c555yj5cuXT+nAAQDA9FFw4NixY4c+9rGPjf7/nesvVq1apQcffFC7d+/WP/7jP6qnp0etra265ppr9Dd/8zfT7s8mAABg6hQcOK666iqZSS62+9d//VenAQEAgDMPc6kAAADvvL9LxVYkHSpiCr9KOpp0eCuWpJ4P1ORcFv4mIqWlsCwy4XrlJ9zecXH4v6VOv1IO2Yz9lexlcfsr2SUpzNrn1shetyv4K47av32u4pj9VfjRlNufCCd7l8rphL2ON8cL7b9vk7F/fUXL3bZZkLLfT/svn5dzWfjTmJSVwrKY+i+dM+E6I1X2+3iywe33uoF59s/X4Fll1rV1e61L33LOQuvSxhfc9vHI6132xVWTHJPeebtuEEiJ+LjFyfn2746RpMQJ+58BQcrthi8myP2zbzKZdP7HBM5wAAAA7wgcAADAOwIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA7wgcAADAu5Kdnj5TEZVihU+5nq0YP2VwQYz9er3t9lNBS9J5LYesa+vjw9a1GeOWO7uH7KY1lqSDb1Q49Q6y9rXlJ+ynWi97c8i+sSQlJ5mG2phTjxOsF5ls+ux8lDnsp2n7KbDNyV77vpKUsJ/ePnE897iD0Iw+5lovyNpvs/65jr/XhYF16R8ue8669rlF861rJSn1aLN17bEP1Tr1bnr1sHWtGUrmXvb2a9MYM+F6iSN91n0lySTs9zNTVvjPy9+VrrbbTzPp/Os4wwEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA7wgcAADAOwIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO9Kdnr6MBZRWFZ4HgrL7KdylqREX5hzWRCeepxovcFWt/wWj9hPl35BdZd17fMn51vXStKxgSrr2myD/fcsSeHrceva2ID9VOuR3gHrWkky2dz7mfmdx4nWC6oq3HrH7KexDjIOz1dFuX2tJDn0LjvSk3thGI4+5lovmqy27t12OPdznY9Df1BnXfvUax+wrv3o3P3WtZL07LX2++mM79pvb0kauvwc69rK13pyLzwRkUJJkYjUWD9ucXqm/bFQksqO9lvXmlq340Km3O7nVzbC9PQAAKCEEDgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOBdrNgDyGWoJaZovPDhRUeMU9+R6twZzERPPfafFR1fW+vW+5K6w9a1V1b/1rr2/755jnWtJGWz9rk10uu2CyZ67bd5tC9l3zidtq+VpEhgv16QZ20OQSZrXWsGh+wb5/s959LYYF979HjuZdnw1GOO9SI9fdatkx+cb10rSW1P9VjXVv3no9a1fely61pJGjxRYV0bfmLQqXfbA/b7mkmU5V4YnHqcaL1MldvxbPD3ZlnXVrzpdkyqOjJiVZfJ5F/HGQ4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhXstPT97cFipYXPsVw4qTbFNh9C3NPtRtuMtKgFMaNTl42firgIBo69f6Tuh3WtRfF7aeC/h+xjHWtJFWV201rLEk1L7o9X3X77KdLj/QO2Dd2nSI+lvulF7z9tYMgUFA2yVTZtrL2+6nJ2O8rkZYm61pJbuOumGSq9f5AMnrrOc21Xn2tde/y105Y10rS0atarGtfeS1hXfup33vWulaSXm62f74rNs5w6j0w3/71WfVGMvfCd173QaBsVXzc4uRMtx+piZ6sda2JuR2TUvV2Y8+k8x8zZzgAAIB3BA4AAOAdgQMAAHhXUOBYv369Lr30UtXU1KipqUnXX3+99uzZM2adZDKp1atXa+bMmaqurtaNN96o7u7uKR00AACYXgoKHFu3btXq1au1fft2/exnP1M6ndY111yjwcHB0XU++9nP6kc/+pEee+wxbd26VYcPH9YNN9ww5QMHAADTR0GXpT711FNj/r9x40Y1NTVp586duvLKK9Xb26u///u/1/e+9z1dffXVkqSHH35YH/jAB7R9+3ZdfvnlUzdyAAAwbThdw9Hb2ytJamhokCTt3LlT6XRay5YtG13nggsu0Ny5c7Vt27YJv0YqlVJfX9+YDwAAcGaxDhxhGOquu+7Shz/8YV188cWSpK6uLsXjcdXX149Zt7m5WV1dXRN+nfXr16uurm70o62tzXZIAACgRFkHjtWrV+ull17Spk2bnAawbt069fb2jn4cPHjQ6esBAIDSY3VrsTVr1ujHP/6xnn32Wc2ZM2f08y0tLRoZGVFPT8+Ysxzd3d1qaZn4bnmJREKJhP3d8AAAQOkr6AyHMUZr1qzR448/rmeeeUbt7e1jli9evFhlZWXavHnz6Of27NmjAwcOqKOjY2pGDAAApp2CznCsXr1a3/ve9/Tkk0+qpqZm9LqMuro6VVRUqK6uTrfffrvWrl2rhoYG1dbW6s///M/V0dHBO1QAAHgfKyhwPPjgg5Kkq666asznH374Yd12222SpK9//euKRCK68cYblUqltHz5cn3729+eksECAIDpqaDAYYw57Trl5eXasGGDNmzYYD0oAABwZmEuFQAA4J3Vu1TeC5G0FLGJQ6c/CTO50H69yMm4U+tvHb3aqd7Wy9vbT7/SJGJDgXXtWQeTbr17hh2Ko9alJlFm31dSkMnmt+JEYwzz3UlzcKmPOmyzMrfDTVhTbl0bTWdyLguCYPQxKJv4eTXdb1r3Tl52rnWtJDW+aH8zxL5l9s/Xps7F1rWSlPpFo3Xtif804tR73g/tj0nZxCTbLDj1ONF6id48X9c5JGfYP1+xlNsPv3Sl3TbLjuRfxxkOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4V7LT08eGpajFLNqZSre+tb/KPcV8JB2MPk60XrzfbXrgX775e9a1sSH7vnNeSdsXS5Kx/76DjNs2U2A/DbWJ2uftIHQcdzKVe9k729OYCdczDttbUs4p2POqraywr53se87DZFPMn05YX5NzmTny1j5kgiDnepEy+0Nl4vCAda0k9Syst++9034fP3Gh/X4iSfFa+/208Rduvfvn2NdWdeWeYt4Ep/aVdM34qeQz5W6/w5efsJ/e3sTsj4WSFM6wrCvgaeYMBwAA8I7AAQAAvCNwAAAA7wgcAADAOwIHAADwjsABAAC8I3AAAADvCBwAAMA7AgcAAPCOwAEAALwjcAAAAO8IHAAAwDsCBwAA8I7AAQAAvCNwAAAA72LFHkAuqZlGkXJTcF26Je3Ut3nzJJskPPVYcSwctziSdWqtyl/bf4Foavx48hWWBda1kpSujFrXJo4NO/UO+gata82wfW+TyVjXSlI4nMz9tcNw9DF7smfc8khFuVNvVVY41Dr07rd/riTJ1Nv3ztZNUhsJRh9zrRc52Wfd29RXW9dKUv1LPda18b5a69qqI2XWtZLbMSlV6/a7cN3+EevaSCb3z53AmNHHeO/4Y4CJum2zTJX9913W7/YDqKrLri6Tzr8vZzgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4B2BAwAAeEfgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3JTdbrHl7Nr4wlXs2zcmEw26zxWZHcm+SfmNU8fZjdmT8+EL7yRElSUHa/guYjMNssXKbLTaTts+tmWzKqbcJ7etNaD+jpIzjbLEm937aL6PE24+ZCdaLGLffEwKXbZa1n5EycNnekozDvpLJ5J7RuN+8vb2NUSYz8XHHZZtlHffxwGGbZ9J2x1FJyo647WcmXfhs31PVO5PxM1vs6faVQmZOnYjLSzvIuPUOA7vm7+xj7/zsnkxg8lnrPXTo0CG1tbUVexgAACBPBw8e1Jw5cyZdp+QCRxiGOnz4sGpqahQE43/z7uvrU1tbmw4ePKja2toijHD6YZsVjm1WOLZZ4dhmhWObFc7nNjPGqL+/X62trYpEJj9LUnJ/UolEIqdNSZJUW1vLzlYgtlnh2GaFY5sVjm1WOLZZ4Xxts7q6urzW46JRAADgHYEDAAB4N+0CRyKR0L333qtEIlHsoUwbbLPCsc0KxzYrHNuscGyzwpXKNiu5i0YBAMCZZ9qd4QAAANMPgQMAAHhH4AAAAN4ROAAAgHfTLnBs2LBB8+fPV3l5uZYsWaLnn3++2EMqWV/60pcUBMGYjwsuuKDYwyopzz77rK699lq1trYqCAI98cQTY5YbY3TPPfdo9uzZqqio0LJly7R3797iDLZEnG6b3XbbbeP2uxUrVhRnsCVg/fr1uvTSS1VTU6OmpiZdf/312rNnz5h1ksmkVq9erZkzZ6q6ulo33nijuru7izTi4stnm1111VXj9rNPfepTRRpx8T344INauHDh6M29Ojo69NOf/nR0eSnsY9MqcDz66KNau3at7r33Xr3wwgtatGiRli9frqNHjxZ7aCXroosu0pEjR0Y/fvGLXxR7SCVlcHBQixYt0oYNGyZc/sADD+hb3/qWHnroIT333HOqqqrS8uXLlUzaT4o13Z1um0nSihUrxux3jzzyyHs4wtKydetWrV69Wtu3b9fPfvYzpdNpXXPNNRocHBxd57Of/ax+9KMf6bHHHtPWrVt1+PBh3XDDDUUcdXHls80k6Y477hiznz3wwANFGnHxzZkzR1/5yle0c+dO7dixQ1dffbWuu+46/frXv5ZUIvuYmUYuu+wys3r16tH/Z7NZ09raatavX1/EUZWue++91yxatKjYw5g2JJnHH3989P9hGJqWlhbz1a9+dfRzPT09JpFImEceeaQIIyw9795mxhizatUqc9111xVlPNPB0aNHjSSzdetWY8xb+1RZWZl57LHHRtd5+eWXjSSzbdu2Yg2zpLx7mxljzEc/+lHzmc98pniDmgZmzJhhvvOd75TMPjZtznCMjIxo586dWrZs2ejnIpGIli1bpm3bthVxZKVt7969am1t1YIFC3TrrbfqwIEDxR7StNHZ2amurq4x+1xdXZ2WLFnCPncaW7ZsUVNTk84//3x9+tOf1vHjx4s9pJLR29srSWpoaJAk7dy5U+l0esx+dsEFF2ju3LnsZ2979zZ7x7/8y7+osbFRF198sdatW6ehoaFiDK/kZLNZbdq0SYODg+ro6CiZfazkJm/L5dixY8pms2pubh7z+ebmZv32t78t0qhK25IlS7Rx40adf/75OnLkiO677z595CMf0UsvvaSamppiD6/kdXV1SdKE+9w7yzDeihUrdMMNN6i9vV379+/X3XffrZUrV2rbtm2KRqPFHl5RhWGou+66Sx/+8Id18cUXS3prP4vH46qvrx+zLvvZWybaZpL0iU98QvPmzVNra6t2796tv/qrv9KePXv0wx/+sIijLa5f/epX6ujoUDKZVHV1tR5//HFdeOGF2rVrV0nsY9MmcKBwK1euHP33woULtWTJEs2bN0/f//73dfvttxdxZDiT3XzzzaP/vuSSS7Rw4UKdffbZ2rJli5YuXVrEkRXf6tWr9dJLL3EtVQFybbM777xz9N+XXHKJZs+eraVLl2r//v06++yz3+thloTzzz9fu3btUm9vr37wgx9o1apV2rp1a7GHNWra/EmlsbFR0Wh03FW13d3damlpKdKoppf6+nqdd9552rdvX7GHMi28s1+xz7lZsGCBGhsb3/f73Zo1a/TjH/9YP//5zzVnzpzRz7e0tGhkZEQ9PT1j1mc/y73NJrJkyRJJel/vZ/F4XOecc44WL16s9evXa9GiRfrmN79ZMvvYtAkc8Xhcixcv1ubNm0c/F4ahNm/erI6OjiKObPoYGBjQ/v37NXv27GIPZVpob29XS0vLmH2ur69Pzz33HPtcAQ4dOqTjx4+/b/c7Y4zWrFmjxx9/XM8884za29vHLF+8eLHKysrG7Gd79uzRgQMH3rf72em22UR27dolSe/b/WwiYRgqlUqVzj72nl2eOgU2bdpkEomE2bhxo/nNb35j7rzzTlNfX2+6urqKPbSS9Bd/8Rdmy5YtprOz0/zyl780y5YtM42Njebo0aPFHlrJ6O/vNy+++KJ58cUXjSTzta99zbz44ovm9ddfN8YY85WvfMXU19ebJ5980uzevdtcd911pr293QwPDxd55MUz2Tbr7+83n/vc58y2bdtMZ2enefrpp82HPvQhc+6555pkMlnsoRfFpz/9aVNXV2e2bNlijhw5MvoxNDQ0us6nPvUpM3fuXPPMM8+YHTt2mI6ODtPR0VHEURfX6bbZvn37zP3332927NhhOjs7zZNPPmkWLFhgrrzyyiKPvHi+8IUvmK1bt5rOzk6ze/du84UvfMEEQWD+7d/+zRhTGvvYtAocxhjzt3/7t2bu3LkmHo+byy67zGzfvr3YQypZN910k5k9e7aJx+PmrLPOMjfddJPZt29fsYdVUn7+858bSeM+Vq1aZYx5662xX/ziF01zc7NJJBJm6dKlZs+ePcUddJFNts2GhobMNddcY2bNmmXKysrMvHnzzB133PG+/qVgom0lyTz88MOj6wwPD5s/+7M/MzNmzDCVlZXm4x//uDly5EjxBl1kp9tmBw4cMFdeeaVpaGgwiUTCnHPOOeYv//IvTW9vb3EHXkR/+qd/aubNm2fi8biZNWuWWbp06WjYMKY09jGmpwcAAN5Nm2s4AADA9EXgAAAA3hE4AACAdwQOAADgHYEDAAB4R+AAAADeETgAAIB3BA4AAOAdgQMAAHhH4AAAAN4ROAAAgHcEDgAA4N3/ByM+qE7DrKSwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0] * RES_WIDTH,\n",
    "    \t bbox[:,1] * RES_HEIGHT,\n",
    "    \t bbox[:,2] * RES_WIDTH,\n",
    "    \t bbox[:,3] * RES_HEIGHT\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(255.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    anchor_img = np.zeros((*image.shape[:3], 3), dtype=np.uint8)\n",
    "    anchor_img = anchor_img[idx]\n",
    "\n",
    "    strides = [2, 4, 8]\n",
    "    colors = {\n",
    "        2: [0, 255, 0],  # 초록색\n",
    "        4: [0, 0, 255],  # 파란색\n",
    "        8: [255, 0, 0],   # 빨간색\n",
    "    }\n",
    "\n",
    "    for stride in strides:\n",
    "        color = colors[stride]\n",
    "        for y in range(0, anchor_img.shape[0], stride):\n",
    "            for x in range(0, anchor_img.shape[1], stride):\n",
    "                anchor_img[y, x, :] = color\n",
    "\n",
    "    # 이미지 표시\n",
    "    plt.imshow(image[idx], alpha=1)  \n",
    "    plt.imshow(anchor_img, alpha=0.5) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.203125   0.10416666 0.28125    0.20833333]\n",
      " [0.15625    0.33333334 0.3125     0.3333333 ]\n",
      " [0.125      0.6458334  0.25       0.20833331]\n",
      " [0.796875   0.39583334 0.28125    0.2916667 ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor(251.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.0625     0.         0.28125    0.20833333]\n",
      " [0.         0.16666669 0.3125     0.3333333 ]\n",
      " [0.         0.54166675 0.25       0.20833331]\n",
      " [0.65625    0.25       0.28125    0.2916667 ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.0625     0.         0.28125    0.20833333], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.         0.16666669 0.3125     0.3333333 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.         0.54166675 0.25       0.20833331], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.65625   0.25      0.28125   0.2916667], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 32, 1)\n",
      "tf.Tensor(\n",
      "[[0.453125  0.8333334 0.15625   0.3333333]\n",
      " [0.65625   0.7708333 0.25      0.375    ]\n",
      " [0.890625  0.7083333 0.21875   0.25     ]\n",
      " [0.09375   0.1875    0.1875    0.375    ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor(255.0, shape=(), dtype=float32) tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width:  32\n",
      "height:  24\n",
      "bbox:  tf.Tensor(\n",
      "[[0.375      0.66666675 0.15625    0.3333333 ]\n",
      " [0.53125    0.5833333  0.25       0.375     ]\n",
      " [0.78125    0.5833333  0.21875    0.25      ]\n",
      " [0.         0.         0.1875     0.375     ]], shape=(4, 4), dtype=float32)\n",
      "tf.Tensor([0.375      0.66666675 0.15625    0.3333333 ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.53125   0.5833333 0.25      0.375    ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.78125   0.5833333 0.21875   0.25     ], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.     0.     0.1875 0.375 ], shape=(4,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 1], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_sizes (pixels):  [[ 5.910359  9.265604]\n",
      " [ 8.01403  13.074831]\n",
      " [ 5.771858  6.273226]\n",
      " [ 9.644481  9.19264 ]]\n",
      "anchor_ratios:  [0.64572513 0.61533153 0.9401542  1.0799687 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def compute_anchor_boxes(bboxes, img_width, img_height):\n",
    "    all_bboxes = []\n",
    "    for image_bboxes in bboxes:\n",
    "        # 정규화된 좌표를 픽셀 단위 좌표로 변환\n",
    "        pixel_bboxes = np.copy(image_bboxes)\n",
    "        pixel_bboxes[:, 0] *= img_width\n",
    "        pixel_bboxes[:, 1] *= img_height\n",
    "        pixel_bboxes[:, 2] *= img_width\n",
    "        pixel_bboxes[:, 3] *= img_height\n",
    "        all_bboxes.extend(pixel_bboxes)\n",
    "    \n",
    "    all_bboxes = np.array(all_bboxes)\n",
    "    \n",
    "    # 높이가 0인 바운딩 박스 제거\n",
    "    valid_bboxes = all_bboxes[np.logical_and(all_bboxes[:, 2] > all_bboxes[:, 0], all_bboxes[:, 3] > all_bboxes[:, 1])]\n",
    "    \n",
    "    box_sizes = valid_bboxes[:, 2:] - valid_bboxes[:, :2]\n",
    "    box_ratios = box_sizes[:, 0] / box_sizes[:, 1]\n",
    "    \n",
    "    data = np.column_stack((box_sizes[:, 0], box_sizes[:, 1], box_ratios))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(data)\n",
    "    \n",
    "    anchor_sizes = kmeans.cluster_centers_[:, :2]\n",
    "    anchor_ratios = kmeans.cluster_centers_[:, 2]\n",
    "    \n",
    "    return anchor_sizes, anchor_ratios\n",
    "\n",
    "bboxes = []\n",
    "for image, image_bboxes, label in train_dataset:\n",
    "    bboxes.append(image_bboxes.numpy())\n",
    "\n",
    "# 이미지 너비와 높이 설정\n",
    "img_width = 32\n",
    "img_height = 24\n",
    "\n",
    "anchor_sizes, anchor_ratios = compute_anchor_boxes(bboxes, img_width, img_height)\n",
    "print(\"anchor_sizes (pixels): \", anchor_sizes)\n",
    "print(\"anchor_ratios: \", anchor_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.7, 1.0]         # 이거랑 2268\n",
    "        self.scales = [2** x for x in [1, 1.5]] # 이걸로 바운딩박스 갯수 조절가능\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [3.5, 4.5, 5.5, 6.5, 7.5]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1),\n",
    "                    [1, 1, 2]\n",
    "                )\n",
    "                dims = tf.cast(dims, tf.float32)  # 데이터 타입을 float32로 변환\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor 음수 값: False\n",
      "tf.Tensor(\n",
      "[[ 0.5        0.5        5.8566203  8.3666   ]\n",
      " [ 0.5        0.5        8.282512  11.832159 ]\n",
      " [ 0.5        0.5        7.         7.       ]\n",
      " ...\n",
      " [30.        22.        13.015375  18.593393 ]\n",
      " [30.        22.        11.        11.       ]\n",
      " [30.        22.        15.556349  15.556349 ]], shape=(4032, 4), dtype=float32)\n",
      "(4032, 4)\n",
      "(24, 32, 1)\n",
      "[[0.140625   0.8125     0.30935922 0.41247895]\n",
      " [0.234375   0.7291667  0.21875    0.29166666]\n",
      " [0.484375   0.14583333 0.21875    0.29166666]\n",
      " [0.515625   0.27083334 0.21875    0.29166666]\n",
      " [0.171875   0.22916667 0.21875    0.29166666]\n",
      " [0.96875    0.20833333 0.28125    0.375     ]\n",
      " [0.15625    0.29166666 0.28125    0.375     ]\n",
      " [0.578125   0.14583333 0.30935922 0.41247895]\n",
      " [0.203125   0.7708333  0.18301938 0.34860834]\n",
      " [0.765625   0.3125     0.21875    0.29166666]\n",
      " [0.046875   0.22916667 0.18301938 0.34860834]\n",
      " [0.140625   0.4375     0.18301938 0.34860834]\n",
      " [0.921875   0.0625     0.2588285  0.49300662]\n",
      " [0.578125   0.6458333  0.21875    0.29166666]\n",
      " [0.890625   0.8541667  0.18301938 0.34860834]\n",
      " [0.28125    0.5416667  0.39774755 0.53033006]\n",
      " [0.421875   0.6875     0.18301938 0.34860834]\n",
      " [0.703125   0.9375     0.21875    0.29166666]\n",
      " [0.015625   0.14583333 0.30935922 0.41247895]\n",
      " [0.421875   0.8958333  0.21875    0.29166666]\n",
      " [0.6875     0.41666666 0.40673047 0.7747247 ]\n",
      " [0.09375    0.20833333 0.28125    0.375     ]\n",
      " [0.78125    0.7916667  0.39774755 0.53033006]\n",
      " [0.1875     0.9166667  0.4861359  0.6481812 ]\n",
      " [0.171875   0.3125     0.30935922 0.41247895]\n",
      " [0.84375    0.7916667  0.3327795  0.63386565]\n",
      " [0.046875   0.47916666 0.18301938 0.34860834]\n",
      " [0.765625   0.6875     0.21875    0.29166666]\n",
      " [0.078125   0.14583333 0.30935922 0.41247895]\n",
      " [0.484375   0.0625     0.18301938 0.34860834]\n",
      " [0.84375    0.125      0.3327795  0.63386565]\n",
      " [0.421875   0.8958333  0.18301938 0.34860834]\n",
      " [0.234375   0.3125     0.2588285  0.49300662]\n",
      " [0.890625   0.6875     0.2588285  0.49300662]\n",
      " [0.515625   0.35416666 0.2588285  0.49300662]\n",
      " [0.515625   0.4375     0.2588285  0.49300662]\n",
      " [0.046875   0.14583333 0.18301938 0.34860834]\n",
      " [0.40625    0.04166667 0.23531064 0.44821072]\n",
      " [0.765625   0.8958333  0.21875    0.29166666]\n",
      " [0.96875    0.875      0.28125    0.375     ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0] / RES_WIDTH\n",
    "ymin = anchor[:, 1] / RES_HEIGHT\n",
    "xmax = anchor[:, 2] / RES_WIDTH\n",
    "ymax = anchor[:, 3] / RES_HEIGHT\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "print(anchor)\n",
    "print(anchor.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    print(img.shape)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    print(sample_data)\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x * RES_WIDTH, top_left_y * RES_HEIGHT), width * RES_WIDTH, height * RES_HEIGHT, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    print(boxes1_corners.shape)\n",
    "    print(boxes2_corners.shape)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA.shape: (2, 4)\n",
      "GT.shape: (2, 4)\n",
      "GA (XYWH): tf.Tensor(\n",
      "[[60. 45. 20. 30.]\n",
      " [60. 45. 20. 30.]], shape=(2, 4), dtype=float64)\n",
      "GT (XYWH): tf.Tensor(\n",
      "[[60. 45. 20. 30.]\n",
      " [45. 60. 20. 30.]], shape=(2, 4), dtype=float64)\n",
      "(2, 4)\n",
      "(2, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: tf.Tensor(\n",
      "[[1.         0.06666667]\n",
      " [1.         0.06666667]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "GA = np.array([[50, 30, 70, 60], [50, 30, 70, 60]])  # 예: [xmin, ymin, xmax, ymax]\n",
    "GT = np.array([[50, 30, 70, 60], [35, 45, 55, 75]])  # 예: [xmin, ymin, xmax, ymax]\n",
    "\n",
    "print(\"GA.shape:\", GA.shape)\n",
    "print(\"GT.shape:\", GT.shape)\n",
    "\n",
    "GA_xywh = convert_to_xywh(GA)\n",
    "print(\"GA (XYWH):\", GA_xywh)\n",
    "\n",
    "GT_xywh = convert_to_xywh(GT)\n",
    "print(\"GT (XYWH):\", GT_xywh)\n",
    "\n",
    "iou = compute_iou(GA_xywh, GT_xywh)\n",
    "print(\"IoU:\", iou)\n",
    "# GA = convert_to_corners(GA)\n",
    "# print(GA)\n",
    "# GT = convert_to_corners(GT)\n",
    "# print(GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 주어진 바운딩 박스 데이터\n",
    "box1 = [50, 30, 70, 60]  # [x_min, y_min, x_max, y_max]\n",
    "box2 = [35, 45, 55, 75]\n",
    "\n",
    "# 그림 생성\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 첫 번째 바운딩 박스 추가\n",
    "rect1 = patches.Rectangle((box1[0], box1[1]), box1[2] - box1[0], box1[3] - box1[1], \n",
    "                          linewidth=2, edgecolor='blue', facecolor='none')\n",
    "ax.add_patch(rect1)\n",
    "\n",
    "# 두 번째 바운딩 박스 추가\n",
    "rect2 = patches.Rectangle((box2[0], box2[1]), box2[2] - box2[0], box2[3] - box2[1], \n",
    "                          linewidth=2, edgecolor='red', facecolor='none')\n",
    "ax.add_patch(rect2)\n",
    "\n",
    "# 축 범위 설정\n",
    "ax.set_xlim(0, 90)\n",
    "ax.set_ylim(0, 90)\n",
    "\n",
    "# 그림 표시\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_anchor_boxes(anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        print(\"iou_matrix:  \", iou_matrix)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        print(\"max_iou:  \", max_iou)\n",
    "\n",
    "\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "    \n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        print(\"negative_mask:  \", negative_mask)\n",
    "\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        print(\"ignore_mask:  \", ignore_mask)\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype = tf.float32),\n",
    "            tf.cast(ignore_mask, dtype = tf.float32),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n",
      "(4, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou_matrix:   tf.Tensor(\n",
      "[[1.         0.03100775 0.         0.        ]\n",
      " [0.03100775 1.         0.         0.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.06003535 0.        ]\n",
      " [0.         0.         0.09293901 0.        ]\n",
      " [0.         0.         0.11408175 0.        ]\n",
      " [0.16311106 0.         0.         0.        ]], shape=(8, 4), dtype=float32)\n",
      "max_iou:   tf.Tensor(\n",
      "[1.         1.         1.         0.         0.06003535 0.09293901\n",
      " 0.11408175 0.16311106], shape=(8,), dtype=float32)\n",
      "matched_gt_idx:   tf.Tensor([0 1 2 0 2 2 2 0], shape=(8,), dtype=int64)\n",
      "positive_mask:   tf.Tensor([ True  True  True False False False False False], shape=(8,), dtype=bool)\n",
      "negative_mask:   tf.Tensor([False False False  True  True  True  True  True], shape=(8,), dtype=bool)\n",
      "ignore_mask:   tf.Tensor([False False False False False False False False], shape=(8,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "anchor = np.array([\n",
    "                    [27.,  18.5,  8.,   7.],\n",
    "                    [18.5, 15.5, 11.,   7.],\n",
    "                    [ 6.,   4.,   8.,   6.],\n",
    "                    [ 0.,   0.,   0.,   0.],\n",
    "                    [ 1., 1., 4.242641, 8.485281 ],\n",
    "                    [ 1.,         1.,         5.3453927, 10.690784 ],\n",
    "                    [ 1.,         1.,         6.7347727, 13.469543 ],\n",
    "                    [30.,        22.,         9.899496,   4.949747 ]])\n",
    "\n",
    "gt_boxes = np.array([[27.,  18.5,  8.,   7., ],\n",
    "                     [18.5, 15.5, 11.,   7. ],\n",
    "                     [ 6.,   4.,   8.,   6. ],\n",
    "                     [ 0.,   0.,   0.,   0. ]])\n",
    "# print(gt_boxes.shape)\n",
    "a, b, c = match_anchor_boxes(tf.cast(anchor, tf.float32), tf.cast(gt_boxes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        print(\"iou_matrix:  \", iou_matrix.shape)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        print(\"max_iou:  \", max_iou.shape)\n",
    "\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "        print(\"max_iou:\", max_iou)\n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        print(\"negative_mask:  \", negative_mask.shape)\n",
    "\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        print(\"ignore_mask:  \", ignore_mask.shape)\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype = tf.float32),\n",
    "            tf.cast(ignore_mask, dtype = tf.float32),\n",
    "        )\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        print(\"_compute_box_target anchor_boxes: \", anchor_boxes)\n",
    "        print(\"_compute_box_target matched_gt_boxes : \", matched_gt_boxes)\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis = -1,\n",
    "        )\n",
    "        print(\"box_target:  \", box_target)\n",
    "        box_target = box_target / self._box_variance\n",
    "        print(\"box_target:  \", box_target)\n",
    "        return box_target\n",
    "    \n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "        print(\"image_shape:\", image_shape.shape)\n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # 앵커 박스 정규화\n",
    "        xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "        ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "        xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "        ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "\n",
    "        # 정규화된 좌표를 스택으로 결합\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        print(\"anchor_boxes  : \", normalized_anchor)\n",
    "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "        print(\"cls_ids\", cls_ids)\n",
    "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "            normalized_anchor, gt_boxes\n",
    "        )\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        print(\"ignore_mask:  \", ignore_mask)\n",
    "\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "\n",
    "        print(\"matched_gt_boxes:  \", matched_gt_boxes)\n",
    "        \n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        print(\"box_target:  \", box_target)\n",
    "\n",
    "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "        print(\"matched_gt_cls_ids:  \", matched_gt_cls_ids)\n",
    "        \n",
    "        cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "        cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "\n",
    "        print(\"cls_target:  \", cls_target)\n",
    "\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        print(\"cls_target:  \", cls_target)\n",
    "        num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "        print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "\n",
    "\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        print(\"label:  \", label)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):       \n",
    "        images_shape = tf.shape(batch_images)\n",
    "        print(\"images_shape:  \", images_shape)\n",
    "        batch_size = images_shape[0]\n",
    "        print(\"batch_size:  \", batch_size)\n",
    "\n",
    "        print(\"gt_boxes: \", gt_boxes)\n",
    "\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        print(\"labels:  \", labels)\n",
    "        # batch_size_val = batch_size.numpy()\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            print(\"label:  \", label)\n",
    "            labels = labels.write(i, label)\n",
    "        return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"Eager execution: \", tf.executing_eagerly())\n",
    "if not tf.executing_eagerly():\n",
    "    tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1) (1, 4, 4) (1, 4)\n",
      "images_shape:   tf.Tensor([ 1 24 32  1], shape=(4,), dtype=int32)\n",
      "batch_size:   tf.Tensor(1, shape=(), dtype=int32)\n",
      "gt_boxes:  tf.Tensor(\n",
      "[[[0.203125   0.875      0.28125    0.25      ]\n",
      "  [0.671875   0.7291667  0.21875    0.375     ]\n",
      "  [0.203125   0.5625     0.34375    0.29166666]\n",
      "  [0.171875   0.2916667  0.28125    0.33333334]]], shape=(1, 4, 4), dtype=float32)\n",
      "labels:   <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f3110289f70>\n",
      "image_shape: (4,)\n",
      "anchor_boxes  :  tf.Tensor(\n",
      "[[0.015625   0.02083333 0.18301938 0.34860834]\n",
      " [0.015625   0.02083333 0.2588285  0.49300662]\n",
      " [0.015625   0.02083333 0.21875    0.29166666]\n",
      " ...\n",
      " [0.9375     0.9166667  0.40673047 0.7747247 ]\n",
      " [0.9375     0.9166667  0.34375    0.45833334]\n",
      " [0.9375     0.9166667  0.4861359  0.6481812 ]], shape=(4032, 4), dtype=float32)\n",
      "cls_ids tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "(4032, 4)\n",
      "(4, 4)\n",
      "iou_matrix:   (4032, 4)\n",
      "max_iou:   (4032,)\n",
      "matched_gt_idx:   tf.Tensor([3 3 3 ... 1 1 1], shape=(4032,), dtype=int64)\n",
      "max_iou: tf.Tensor([0.0349627  0.07894596 0.02542371 ... 0.04656056 0.01517241 0.07625204], shape=(4032,), dtype=float32)\n",
      "positive_mask:   tf.Tensor([False False False ... False False False], shape=(4032,), dtype=bool)\n",
      "negative_mask:   (4032,)\n",
      "ignore_mask:   (4032,)\n",
      "matched_gt_idx:   tf.Tensor([3 3 3 ... 1 1 1], shape=(4032,), dtype=int64)\n",
      "positive_mask:   tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(4032,), dtype=float32)\n",
      "ignore_mask:   tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(4032,), dtype=float32)\n",
      "matched_gt_boxes:   tf.Tensor(\n",
      "[[0.171875   0.2916667  0.28125    0.33333334]\n",
      " [0.171875   0.2916667  0.28125    0.33333334]\n",
      " [0.171875   0.2916667  0.28125    0.33333334]\n",
      " ...\n",
      " [0.671875   0.7291667  0.21875    0.375     ]\n",
      " [0.671875   0.7291667  0.21875    0.375     ]\n",
      " [0.671875   0.7291667  0.21875    0.375     ]], shape=(4032, 4), dtype=float32)\n",
      "_compute_box_target anchor_boxes:  tf.Tensor(\n",
      "[[0.015625   0.02083333 0.18301938 0.34860834]\n",
      " [0.015625   0.02083333 0.2588285  0.49300662]\n",
      " [0.015625   0.02083333 0.21875    0.29166666]\n",
      " ...\n",
      " [0.9375     0.9166667  0.40673047 0.7747247 ]\n",
      " [0.9375     0.9166667  0.34375    0.45833334]\n",
      " [0.9375     0.9166667  0.4861359  0.6481812 ]], shape=(4032, 4), dtype=float32)\n",
      "_compute_box_target matched_gt_boxes :  tf.Tensor(\n",
      "[[0.171875   0.2916667  0.28125    0.33333334]\n",
      " [0.171875   0.2916667  0.28125    0.33333334]\n",
      " [0.171875   0.2916667  0.28125    0.33333334]\n",
      " ...\n",
      " [0.671875   0.7291667  0.21875    0.375     ]\n",
      " [0.671875   0.7291667  0.21875    0.375     ]\n",
      " [0.671875   0.7291667  0.21875    0.375     ]], shape=(4032, 4), dtype=float32)\n",
      "box_target:   tf.Tensor(\n",
      "[[ 0.85373473  0.7768986   0.42965186 -0.04480607]\n",
      " [ 0.6036816   0.5493503   0.0830783  -0.39137962]\n",
      " [ 0.71428573  0.9285715   0.2513144   0.13353144]\n",
      " ...\n",
      " [-0.6530738  -0.24202146 -0.6202212  -0.7255817 ]\n",
      " [-0.77272725 -0.4090909  -0.45198512 -0.2006707 ]\n",
      " [-0.5464007  -0.28927097 -0.7985587  -0.54724425]], shape=(4032, 4), dtype=float32)\n",
      "box_target:   tf.Tensor(\n",
      "[[ 8.537347    7.768986    2.1482592  -0.22403035]\n",
      " [ 6.036816    5.493503    0.4153915  -1.9568981 ]\n",
      " [ 7.142857    9.285715    1.256572    0.6676572 ]\n",
      " ...\n",
      " [-6.530738   -2.4202144  -3.101106   -3.6279085 ]\n",
      " [-7.7272725  -4.090909   -2.2599256  -1.0033535 ]\n",
      " [-5.4640074  -2.8927097  -3.9927936  -2.7362213 ]], shape=(4032, 4), dtype=float32)\n",
      "box_target:   tf.Tensor(\n",
      "[[ 8.537347    7.768986    2.1482592  -0.22403035]\n",
      " [ 6.036816    5.493503    0.4153915  -1.9568981 ]\n",
      " [ 7.142857    9.285715    1.256572    0.6676572 ]\n",
      " ...\n",
      " [-6.530738   -2.4202144  -3.101106   -3.6279085 ]\n",
      " [-7.7272725  -4.090909   -2.2599256  -1.0033535 ]\n",
      " [-5.4640074  -2.8927097  -3.9927936  -2.7362213 ]], shape=(4032, 4), dtype=float32)\n",
      "matched_gt_cls_ids:   tf.Tensor([1. 1. 1. ... 1. 1. 1.], shape=(4032,), dtype=float32)\n",
      "cls_target:   tf.Tensor([-1. -1. -1. ... -1. -1. -1.], shape=(4032,), dtype=float32)\n",
      "cls_target:   tf.Tensor(\n",
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]], shape=(4032, 1), dtype=float32)\n",
      "Number of 1.0 values in cls_target: tf.Tensor(213, shape=(), dtype=int64)\n",
      "label:   tf.Tensor(\n",
      "[[ 8.537347    7.768986    2.1482592  -0.22403035 -1.        ]\n",
      " [ 6.036816    5.493503    0.4153915  -1.9568981  -1.        ]\n",
      " [ 7.142857    9.285715    1.256572    0.6676572  -1.        ]\n",
      " ...\n",
      " [-6.530738   -2.4202144  -3.101106   -3.6279085  -1.        ]\n",
      " [-7.7272725  -4.090909   -2.2599256  -1.0033535  -1.        ]\n",
      " [-5.4640074  -2.8927097  -3.9927936  -2.7362213  -1.        ]], shape=(4032, 5), dtype=float32)\n",
      "label:   tf.Tensor(\n",
      "[[ 8.537347    7.768986    2.1482592  -0.22403035 -1.        ]\n",
      " [ 6.036816    5.493503    0.4153915  -1.9568981  -1.        ]\n",
      " [ 7.142857    9.285715    1.256572    0.6676572  -1.        ]\n",
      " ...\n",
      " [-6.530738   -2.4202144  -3.101106   -3.6279085  -1.        ]\n",
      " [-7.7272725  -4.090909   -2.2599256  -1.0033535  -1.        ]\n",
      " [-5.4640074  -2.8927097  -3.9927936  -2.7362213  -1.        ]], shape=(4032, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    img, box, label = preprocess_data(image, bbox, label)\n",
    "    print(img.shape, box.shape, label.shape)\n",
    "\n",
    "    label_encoder.encode_batch(img, box, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 32, 1)\n",
      "(1, 4, 4)\n",
      "(1, 4)\n"
     ]
    }
   ],
   "source": [
    "for img, bbox, label in train_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_shape:   Tensor(\"Shape:0\", shape=(4,), dtype=int32)\n",
      "batch_size:   Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
      "gt_boxes:  Tensor(\"args_1:0\", shape=(1, None, 4), dtype=float32)\n",
      "labels:   <tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f32f0d4b430>\n",
      "image_shape: (4,)\n",
      "anchor_boxes  :  Tensor(\"while/stack_3:0\", shape=(None, 4), dtype=float32)\n",
      "cls_ids Tensor(\"while/Cast:0\", dtype=float32)\n",
      "(None, 4)\n",
      "(None, 4)\n",
      "iou_matrix:   (None, None)\n",
      "max_iou:   (None,)\n",
      "matched_gt_idx:   Tensor(\"while/ArgMax:0\", shape=(None,), dtype=int64)\n",
      "max_iou: Tensor(\"while/Max:0\", shape=(None,), dtype=float32)\n",
      "positive_mask:   Tensor(\"while/GreaterEqual:0\", shape=(None,), dtype=bool)\n",
      "negative_mask:   (None,)\n",
      "ignore_mask:   (None,)\n",
      "matched_gt_idx:   Tensor(\"while/ArgMax:0\", shape=(None,), dtype=int64)\n",
      "positive_mask:   Tensor(\"while/Cast_1:0\", shape=(None,), dtype=float32)\n",
      "ignore_mask:   Tensor(\"while/Cast_2:0\", shape=(None,), dtype=float32)\n",
      "matched_gt_boxes:   Tensor(\"while/GatherV2:0\", shape=(None, 4), dtype=float32)\n",
      "_compute_box_target anchor_boxes:  Tensor(\"while/stack_3:0\", shape=(None, 4), dtype=float32)\n",
      "_compute_box_target matched_gt_boxes :  Tensor(\"while/GatherV2:0\", shape=(None, 4), dtype=float32)\n",
      "box_target:   Tensor(\"while/concat_6:0\", shape=(None, 4), dtype=float32)\n",
      "box_target:   Tensor(\"while/truediv_17:0\", shape=(None, 4), dtype=float32)\n",
      "box_target:   Tensor(\"while/truediv_17:0\", shape=(None, 4), dtype=float32)\n",
      "matched_gt_cls_ids:   Tensor(\"while/GatherV2_1:0\", dtype=float32)\n",
      "cls_target:   Tensor(\"while/SelectV2_1:0\", dtype=float32)\n",
      "cls_target:   Tensor(\"while/ExpandDims_3:0\", dtype=float32)\n",
      "Number of 1.0 values in cls_target: Tensor(\"while/count_nonzero/Sum:0\", shape=(), dtype=int64)\n",
      "label:   Tensor(\"while/concat_7:0\", shape=(None, None), dtype=float32)\n",
      "label:   Tensor(\"while/concat_7:0\", shape=(None, None), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253.0 0.0\n",
      "(1, 4032, 5)\n",
      "Positive 개수: 156\n",
      "Negative 개수: 3697\n",
      "Ignore 개수: 179\n",
      "255.0 2.0\n",
      "(1, 4032, 5)\n",
      "Positive 개수: 233\n",
      "Negative 개수: 3575\n",
      "Ignore 개수: 224\n",
      "255.0 0.0\n",
      "(1, 4032, 5)\n",
      "Positive 개수: 214\n",
      "Negative 개수: 3583\n",
      "Ignore 개수: 235\n"
     ]
    }
   ],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, labels = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(labels.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -2.0), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive 개수: 149\n",
      "Negative 개수: 3485\n",
      "Ignore 개수: 398\n",
      "Positive 149\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    label_idx = 0\n",
    "    for label in labels:\n",
    "        # if label[4] == 1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        # elif label[4] == -1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        dx, dy, dw, dh = label[:4]\n",
    "        anchor = anchors[label_idx]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, width, height]\n",
    "        # print(np.array(decoded_box))\n",
    "        if label[4] == 1.0:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "        label_idx += 1\n",
    "        # if len(np.array(decoded_boxes)) > 1: \n",
    "            # break\n",
    "    print(\"Positive\",len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes    \n",
    "    # print(np.array(decoded_boxes))\n",
    "    \n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    # print(len(decoded_boxes))\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i+=1\n",
    "        # print(box)\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    # print(i)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(1):\n",
    "    image = batch[0][0].numpy()\n",
    "    labels = batch[1][0].numpy()  # 여기서 labels는 [오프셋x, 오프셋y, 스케일w, 스케일h, 클래스, 앵커 박스 인덱스]를 포함한다고 가정\n",
    "    # print(labels)\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -2.0), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(labels, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = layers.DepthwiseConv2D(kernel_size=kernel_size, padding='same' if padding else 'valid', depth_multiplier=1, strides=stride, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.pointwise = layers.Conv2D(out_channels, kernel_size=1, strides=1, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class DepthwiseConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv, self).__init__()\n",
    "        self.depthwise = DepthwiseSeparableConv(out_channels, kernel_size, stride, padding)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.selu = layers.Activation('selu')\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.selu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=2, padding='SAME'):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding=padding, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = layers.Conv2D(out_channels, kernel_size=1, strides=stride, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.conv_1 = layers.Conv2D(out_channels, kernel_size=3, strides=stride, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm_0 = layers.BatchNormalization()\n",
    "        self.batch_norm_1 = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.batch_norm_0(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv_1(out)\n",
    "        out = self.batch_norm_1(out)\n",
    "        out += identity\n",
    "        return self.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "class SPPFast(layers.Layer):\n",
    "    def __init__(self, filters: int, pool_kernel_sizes: List[int] = [1, 2, 4], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pool_kernel_sizes = pool_kernel_sizes\n",
    "        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "        self.conv = layers.Conv2D(filters, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        height, width = tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "        # 글로벌 평균 풀링과 업샘플링\n",
    "        global_features = self.global_pool(inputs)\n",
    "        global_features = tf.expand_dims(tf.expand_dims(global_features, 1), 1)\n",
    "        global_features = tf.image.resize(global_features, [height, width])\n",
    "        # 다양한 크기의 MaxPooling\n",
    "        pooled_outputs = [\n",
    "            layers.MaxPooling2D(pool_size=kernel_size, strides=1, padding='SAME')(inputs)\n",
    "            for kernel_size in self.pool_kernel_sizes\n",
    "        ]\n",
    "        # 업샘플링 및 컨캐터네이션\n",
    "        pooled_outputs = [\n",
    "            tf.image.resize(pooled, [height, width])\n",
    "            for pooled in pooled_outputs\n",
    "        ]\n",
    "        pooled_outputs.append(global_features)\n",
    "        pooled_outputs.append(inputs)\n",
    "        spp_output = tf.concat(pooled_outputs, axis=-1)\n",
    "        # 컨볼루션 적용\n",
    "        spp_output = self.conv(spp_output)\n",
    "        return spp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiStageFeatureExtractionLayer\n",
    "class MSFELayer(layers.Layer):\n",
    "    def __init__(self, sperate_input_channel, out_channel):\n",
    "        super(MSFELayer, self).__init__()\n",
    "        self.sppf = SPPFast(sperate_input_channel // 3)\n",
    "        self.cbam = CBAM()\n",
    "        self.bootleneck = Bottleneck(sperate_input_channel // 3)\n",
    "        self.conv = Conv(out_channel, kernel_size=3, stride=1, padding='SAME')\n",
    "\n",
    "    def call(self, x):\n",
    "        sppf, cbam, bottle = tf.split(x, num_or_size_splits=3, axis=-1)\n",
    "        sppf = self.sppf(sppf)\n",
    "        cbam = self.cbam(cbam)\n",
    "        bottle = self.bootleneck(bottle)\n",
    "\n",
    "        out = tf.concat([sppf, cbam, bottle], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, out_channel, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "        self.conv = layers.Conv2D(out_channel, kernel_size = 1, strides = 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    def call(self, inputs):\n",
    "        out = self.upsample(inputs)\n",
    "        out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose(layers.Layer):\n",
    "    def __init__(self, out_channel, size):\n",
    "        super(Conv2DTranspose, self).__init__()\n",
    "        self.transpose = layers.Conv2DTranspose(filters=out_channel, kernel_size=1, strides=size, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.transpose(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSUpsample(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size, size, interpolation = 'bilinear'):\n",
    "        super(CSUpsample, self).__init__()\n",
    "        self.upsample = Upsample(out_channel, size=size, interpolation = interpolation)\n",
    "        self.transpose = Conv2DTranspose(out_channel, size=size)\n",
    "        self.conv = Conv(out_channel, kernel_size = kernel_size, stride=1, padding='SAME')\n",
    "    \n",
    "    def call(self, x):\n",
    "        upsample, transpose = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        upsample = self.upsample(upsample)\n",
    "        transpose = self.transpose(transpose)\n",
    "\n",
    "        out = tf.concat([upsample, transpose], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(out_channels=6, kernel_size=3, stride=1)\n",
    "        self.msfe1 = MSFELayer(6, 12)\n",
    "\n",
    "        self.conv2 = Conv(out_channels=12, kernel_size=3, stride=2)\n",
    "        self.msfe2 = MSFELayer(12, 18)\n",
    "\n",
    "        self.conv3 = Conv(out_channels=18, kernel_size=3, stride=2)\n",
    "        self.msfe3 = MSFELayer(18, 21)\n",
    "\n",
    "        self.conv4 = Conv(out_channels=21, kernel_size=3, stride=2)\n",
    "        self.msfe4 = MSFELayer(21, 24)\n",
    "        # self.sppf = SPPFast(24)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1 = self.conv1(inputs) # 24, 32\n",
    "        p1_out = self.msfe1(p1)\n",
    "\n",
    "        p2 = self.conv2(p1_out) # 12, 16\n",
    "        p2_out = self.msfe2(p2)\n",
    "\n",
    "        p3 = self.conv3(p2_out) # 6, 8\n",
    "        p3_out = self.msfe3(p3)\n",
    "\n",
    "        p4 = self.conv4(p3_out) # 3, 4\n",
    "        p4_out = self.msfe4(p4)\n",
    "\n",
    "        return p1_out, p2_out, p3_out, p4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Neck, self).__init__()\n",
    "        self.conv1 = Conv(20, kernel_size=1, stride=1)\n",
    "        self.csupsample_c1 = CSUpsample(21, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c1 = MSFELayer(42, 20)\n",
    "\n",
    "        self.csupsample_c2 = CSUpsample(18, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c2 = MSFELayer(36, 30)\n",
    "\n",
    "        self.csupsample_c3 = CSUpsample(12, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c3 = MSFELayer(24, 12)\n",
    "\n",
    "\n",
    "#   • p1=tf.Tensor(shape=(None, 24, 32, 12), dtype=float32)\n",
    "#   • p2=tf.Tensor(shape=(None, 12, 16, 18), dtype=float32)\n",
    "#   • p3=tf.Tensor(shape=(None, 6, 8, 21), dtype=float32)\n",
    "#   • p4=tf.Tensor(shape=(None, 3, 4, 24), dtype=float32)\n",
    "\n",
    "    def call(self, p1, p2, p3, p4):\n",
    "        c3 = self.conv1(p4) # 3, 4      \n",
    "        c3 = self.csupsample_c1(c3)  # 6, 8\n",
    "        c3 = layers.concatenate([c3, p3]) \n",
    "        c3_out = self.msfe_c1(c3)\n",
    "\n",
    "        c2 = self.csupsample_c2(c3_out) # 12, 16\n",
    "        c2 = layers.concatenate([c2, p2])  \n",
    "        c2_out = self.msfe_c2(c2)\n",
    "\n",
    "        c1 = self.csupsample_c3(c2_out) # 24, 32\n",
    "        c1 = layers.concatenate([c1, p1]) \n",
    "        c1_out = self.msfe_c3(c1)\n",
    "\n",
    "        return c1_out, c2_out, c3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Head, self).__init__()\n",
    "        \n",
    "        self.csupsample1 = CSUpsample(20, kernel_size = 1, size = 2)\n",
    "        self.csupsample2 = CSUpsample(20, kernel_size = 1, size = 2)\n",
    "        # FPN layers\n",
    "        self.lateral_conv1 = layers.Conv2D(20, 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.lateral_conv2 = layers.Conv2D(20, 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.lateral_conv3 = layers.Conv2D(20, 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "        self.smooth_conv1 = layers.Conv2D(24, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv2 = layers.Conv2D(24, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv3 = layers.Conv2D(24, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "#   • c1=tf.Tensor(shape=(None, 24, 32, 12), dtype=float32)\n",
    "#   • c2=tf.Tensor(shape=(None, 12, 16, 12), dtype=float32)\n",
    "#   • c3=tf.Tensor(shape=(None, 6, 8, 20), dtype=float32)\n",
    "\n",
    "    def call(self, c1, c2, c3):\n",
    "        lateral_conv1 = self.lateral_conv1(c1)\n",
    "        lateral_conv2 = self.lateral_conv2(c2)\n",
    "        lateral_conv3 = self.lateral_conv3(c3)\n",
    "\n",
    "        fpn_out3 = lateral_conv3\n",
    "        fpn_out2 = layers.Add()([self.csupsample1(fpn_out3), lateral_conv2])\n",
    "        fpn_out1 = layers.Add()([self.csupsample2(fpn_out2), lateral_conv1])\n",
    "\n",
    "        fpn_out1 = self.smooth_conv1(fpn_out1)\n",
    "        fpn_out2 = self.smooth_conv2(fpn_out2)\n",
    "        fpn_out3 = self.smooth_conv3(fpn_out3)\n",
    "        \n",
    "        return fpn_out1, fpn_out2, fpn_out3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 1, num_anchors_per_location = 4):\n",
    "        super(DetectionModel, self).__init__()\n",
    "\n",
    "        self.backbone = BackBone()\n",
    "        self.neck = Neck()\n",
    "        self.head = Head()\n",
    "\n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(24, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            layers.Conv2D(24, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(num_anchors_per_location * 4, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1, p2, p3, p4 = self.backbone(inputs)\n",
    "        c1, c2, c3 = self.neck(p1, p2, p3, p4)\n",
    "        fpn_out1, fpn_out2, fpn_out3 = self.head(c1, c2, c3)\n",
    "\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        N = tf.shape(inputs)[0]\n",
    "        \n",
    "        for _, feature in enumerate([fpn_out1, fpn_out2, fpn_out3]):\n",
    "            cls_output = self.classification_head(feature)\n",
    "            reg_output = self.regression_head(feature)\n",
    "            \n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "\n",
    "            cls_outputs.append(cls_output)\n",
    "            reg_outputs.append(reg_output)\n",
    "\n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"detection_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " back_bone (BackBone)        multiple                  21604     \n",
      "                                                                 \n",
      " neck (Neck)                 multiple                  31143     \n",
      "                                                                 \n",
      " head (Head)                 multiple                  16880     \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, None, None, 4)     1584      \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, None, None, 16)    2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73291 (286.29 KB)\n",
      "Trainable params: 72301 (282.43 KB)\n",
      "Non-trainable params: 990 (3.87 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DetectionModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true_box, y_pred_box):\n",
    "#         difference = y_true_box - y_pred_box\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less_equal(absolute_difference, self._delta),\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5 * self._delta\n",
    "#         )\n",
    "#         return tf.reduce_sum(loss, axis=-1)  # 각 앵커에 대한 평균을 반환\n",
    "\n",
    "\n",
    "# class CombinedBoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta=2.0, weight_box=1.0, name=\"CombinedBoxLoss\"):\n",
    "#         super(CombinedBoxLoss, self).__init__(reduction=\"none\", name=name)\n",
    "#         self.box_loss = BoxLoss(delta=delta)\n",
    "#         self.weight_box = weight_box\n",
    "\n",
    "#     def call(self, y_true, y_pred, selected_mask=None):\n",
    "#         if selected_mask is None:\n",
    "#             selected_mask = tf.ones_like(y_true[..., 0])\n",
    "\n",
    "#         selected_box_labels = tf.boolean_mask(y_true, selected_mask)\n",
    "#         selected_box_predictions = tf.boolean_mask(y_pred, selected_mask)\n",
    "\n",
    "#         box_loss = self.box_loss(selected_box_labels, selected_box_predictions)\n",
    "\n",
    "#         combined_loss = self.weight_box * box_loss \n",
    "#         # return tf.reduce_mean(combined_loss, axis=-1)  # 각 앵커에 대한 평균을 반환\n",
    "#         return combined_loss\n",
    "\n",
    "\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, alpha=0.5, gamma=3.0, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.nn.sigmoid(y_pred)\n",
    "#         alpha_t = tf.where(y_true == 1, self.alpha, 1 - self.alpha)\n",
    "#         p_t = tf.where(y_true == 1, y_pred, 1 - y_pred)\n",
    "#         focal_loss = -alpha_t * tf.pow(1 - p_t, self.gamma) * tf.math.log(p_t + tf.keras.backend.epsilon())\n",
    "#         return tf.reduce_sum(focal_loss, axis=-1)\n",
    "\n",
    "# class BinaryCrossEntropyError(tf.losses.Loss):\n",
    "#     def __init__(self, reduction=\"auto\", name=\"ClassificationLoss\"):\n",
    "#         super(BinaryCrossEntropyError, self).__init__(reduction=reduction, name=name)\n",
    "    \n",
    "#     def call(self, y_true_cls, y_pred_cls):\n",
    "#         labels = tf.where(y_true_cls == 1, 1, 0)\n",
    "#         y_pred = tf.nn.sigmoid(y_pred_cls)\n",
    "#         bce_loss = tf.keras.losses.binary_crossentropy(\n",
    "#             y_true=tf.cast(labels, dtype=tf.float32),\n",
    "#             y_pred=y_pred,\n",
    "#         )\n",
    "#         return tf.reduce_sum(bce_loss)\n",
    "    \n",
    "# class CombinedLoss(tf.losses.Loss):\n",
    "#     def __init__(self, alpha=0.5, gamma=3.0, focal_loss_weight=0.7, mse_weight=0.3, name=\"CombinedLoss\"):\n",
    "#         super(CombinedLoss, self).__init__(name=name)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.focal_loss_weight = focal_loss_weight\n",
    "#         self.mse_weight = mse_weight\n",
    "#         self.focal_loss = FocalLoss(alpha=self.alpha, gamma=self.gamma)\n",
    "#         self._cls_loss = BinaryCrossEntropyError()\n",
    "#         # self.mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "#     def call(self, y_true_cls, y_pred_cls):\n",
    "#         focal_loss = self.focal_loss(y_true_cls, y_pred_cls)\n",
    "#         binary_loss = self._cls_loss(y_true_cls, y_pred_cls)\n",
    "#         # mse_loss = self.mse(y_true_cls, y_pred_cls)\n",
    "#         combined_loss = self.focal_loss_weight * focal_loss + self.mse_weight * binary_loss\n",
    "#         return combined_loss\n",
    "    \n",
    "\n",
    "# class Loss(tf.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, delta=2):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._cls_loss = CombinedLoss()\n",
    "#         self._box_loss = CombinedBoxLoss(delta)\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "        \n",
    "#         # Positive, Negative, Ignore 마스크 생성\n",
    "#         positive_mask = tf.cast(tf.math.equal(cls_labels, 1), dtype=tf.float32)\n",
    "#         negative_mask = tf.cast(tf.math.equal(cls_labels, -1), dtype=tf.float32)\n",
    "#         ignore_mask = tf.cast(tf.math.equal(cls_labels, -2), dtype=tf.float32)\n",
    "        \n",
    "#         # Positive 개수 계산\n",
    "#         num_positives = tf.reduce_sum(positive_mask, axis=-1)\n",
    "        \n",
    "#         # Negative와 Ignore 랜덤 선택\n",
    "#         negative_indices = tf.where(negative_mask)\n",
    "#         ignore_indices = tf.where(ignore_mask)\n",
    "        \n",
    "#         num_negatives = tf.cast(tf.reduce_min(tf.minimum(num_positives, tf.cast(tf.shape(negative_indices)[0], tf.float32))), tf.int32)\n",
    "#         num_ignores = tf.cast(tf.reduce_min(tf.minimum(num_positives, tf.cast(tf.shape(ignore_indices)[0], tf.float32))), tf.int32)\n",
    "        \n",
    "#         random_negative_indices = tf.random.shuffle(negative_indices)[:num_negatives]\n",
    "#         random_ignore_indices = tf.random.shuffle(ignore_indices)[:num_ignores]\n",
    "        \n",
    "#         # 선택된 Negative와 Ignore에 해당하는 마스크 생성\n",
    "#         selected_negative_mask = tf.scatter_nd(random_negative_indices, tf.ones(tf.shape(random_negative_indices)[0]), tf.cast(tf.shape(negative_mask), tf.int64))\n",
    "#         selected_ignore_mask = tf.scatter_nd(random_ignore_indices, tf.ones(tf.shape(random_ignore_indices)[0]), tf.cast(tf.shape(ignore_mask), tf.int64))\n",
    "        \n",
    "#         # 선택된 Positive, Negative, Ignore 마스크 결합\n",
    "#         selected_mask = tf.cast(\n",
    "#                     tf.math.logical_or(\n",
    "#                     tf.math.logical_or(\n",
    "#                     tf.cast(positive_mask, tf.bool),\n",
    "#                     tf.cast(selected_negative_mask, tf.bool)),\n",
    "#                 tf.cast(selected_ignore_mask, tf.bool)\n",
    "#                 ),\n",
    "#             dtype=tf.float32)\n",
    "        \n",
    "#         # BoxLoss 1: 모든 박스 계산\n",
    "#         box_loss_1 = self._box_loss(box_labels, box_predictions)\n",
    "        \n",
    "#         # BoxLoss 2: 선택된 마스크에 해당하는 박스 계산\n",
    "#         box_loss_2 = self._box_loss(box_labels, box_predictions, selected_mask)\n",
    "        \n",
    "#         # 선택된 마스크에 해당하는 ClassificationLoss 계산\n",
    "#         selected_cls_labels = tf.boolean_mask(cls_labels, selected_mask)\n",
    "#         selected_cls_predictions = tf.boolean_mask(cls_predictions, selected_mask)\n",
    "        \n",
    "#         cls_loss = self._cls_loss(selected_cls_labels, selected_cls_predictions)\n",
    "        \n",
    "#         normalizer = tf.reduce_sum(positive_mask, axis=-1) + 1e-6\n",
    "#         cls_loss = tf.math.divide_no_nan(tf.reduce_mean(cls_loss, axis=-1), normalizer)\n",
    "#         box_loss_2 = tf.math.divide_no_nan(tf.reduce_mean(box_loss_2, axis=-1), normalizer)\n",
    "\n",
    "#         cls_weight = 1.0\n",
    "#         box_weight_1 = 1.0\n",
    "#         box_weight_2 = 1.0\n",
    "#         loss = cls_weight * cls_loss + box_weight_2 * box_loss_2 + box_weight_1 * box_loss_1\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true_box, y_pred_box):\n",
    "        difference = y_true_box - y_pred_box\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "class CombinedBoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta=2.0, weight_box=1.0, name=\"CombinedBoxLoss\"):\n",
    "        super(CombinedBoxLoss, self).__init__(reduction=\"none\", name=name)\n",
    "        self.box_loss = BoxLoss(delta=delta)\n",
    "        self.weight_box = weight_box\n",
    "\n",
    "    def call(self, y_true, y_pred, selected_mask=None):\n",
    "        if selected_mask is None:\n",
    "            selected_mask = tf.ones_like(y_true[..., 0], dtype=tf.bool)\n",
    "\n",
    "        selected_box_labels = tf.boolean_mask(y_true, selected_mask)\n",
    "        selected_box_predictions = tf.boolean_mask(y_pred, selected_mask)\n",
    "\n",
    "        box_loss = self.box_loss(selected_box_labels, selected_box_predictions)\n",
    "        combined_loss = self.weight_box * box_loss\n",
    "        return combined_loss\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.5, gamma=3.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # y_pred = tf.nn.sigmoid(y_pred)\n",
    "        alpha_t = tf.where(y_true == 1, self.alpha, 1 - self.alpha)\n",
    "        p_t = tf.where(y_true == 1, y_pred, 1 - y_pred)\n",
    "        focal_loss = -alpha_t * tf.pow(1 - p_t, self.gamma) * tf.math.log(p_t + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_sum(focal_loss, axis=-1)\n",
    "\n",
    "class F1ScoreLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, beta=1, reduction='auto', **kwargs):\n",
    "        super().__init__(reduction=reduction, **kwargs)\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # y_pred = tf.nn.sigmoid(y_pred)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred, axis=-1)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred), axis=-1)\n",
    "\n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "        beta_squared = self.beta ** 2\n",
    "        f1_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "        return 1 - f1_score\n",
    "    \n",
    "# class Loss(tf.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, delta=2.0, alpha=0.5, gamma=2.0, negative_positive_ratio=2.0, beta=1.0, f1_weight=0.5,\n",
    "#                  cls_loss_weight=0.5, box_loss_weight=0.3, f1_loss_weight=0.2):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._cls_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "#         self._box_loss = CombinedBoxLoss(delta=delta)\n",
    "#         self._f1_loss = F1ScoreLoss(beta=beta)\n",
    "#         self._num_classes = num_classes\n",
    "#         self._negative_positive_ratio = negative_positive_ratio\n",
    "#         self._f1_weight = f1_weight\n",
    "#         self._cls_loss_weight = cls_loss_weight\n",
    "#         self._box_loss_weight = box_loss_weight\n",
    "#         self._f1_loss_weight = f1_loss_weight\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "\n",
    "#         positive_mask = tf.cast(tf.math.equal(cls_labels, 1), dtype=tf.bool)\n",
    "#         negative_mask = tf.cast(tf.math.equal(cls_labels, -1), dtype=tf.bool)\n",
    "#         ignore_mask = tf.cast(tf.math.equal(cls_labels, -2), dtype=tf.bool)\n",
    "\n",
    "#         num_positives = tf.reduce_sum(tf.cast(positive_mask, tf.float32), axis=1)\n",
    "#         num_negatives = tf.cast(self._negative_positive_ratio * tf.reduce_max(num_positives), tf.int32)\n",
    "\n",
    "#         negative_cls_loss = tf.where(negative_mask, self._cls_loss(cls_labels, cls_predictions), 0.)\n",
    "#         negative_cls_loss = tf.reshape(negative_cls_loss, [-1])\n",
    "#         _, top_k_indices = tf.math.top_k(\n",
    "#             negative_cls_loss, k=tf.minimum(num_negatives, tf.shape(negative_cls_loss)[0]), sorted=True\n",
    "#         )\n",
    "#         negative_indices = tf.where(negative_mask)\n",
    "#         random_negative_indices = tf.gather(negative_indices, top_k_indices)\n",
    "#         selected_negative_mask = tf.scatter_nd(\n",
    "#             random_negative_indices, tf.ones(tf.shape(top_k_indices)[0], dtype=tf.int32),\n",
    "#             tf.cast(tf.shape(negative_mask), tf.int64)\n",
    "#         )\n",
    "#         selected_negative_mask = tf.cast(selected_negative_mask, tf.bool)\n",
    "\n",
    "#         selected_mask = tf.math.logical_and(\n",
    "#             tf.math.logical_or(tf.cast(positive_mask, tf.bool), selected_negative_mask),\n",
    "#             tf.logical_not(ignore_mask)\n",
    "#         )\n",
    "\n",
    "#         box_loss_1 = self._box_loss(box_labels, box_predictions)\n",
    "#         box_loss_2 = self._box_loss(box_labels, box_predictions, tf.cast(selected_mask, tf.float32))\n",
    "#         selected_cls_labels = tf.boolean_mask(cls_labels, selected_mask)\n",
    "#         selected_cls_predictions = tf.boolean_mask(cls_predictions, selected_mask)\n",
    "\n",
    "#         cls_loss = self._cls_loss(selected_cls_labels, selected_cls_predictions)\n",
    "#         f1_loss = self._f1_loss(selected_cls_labels, selected_cls_predictions)\n",
    "\n",
    "#         num_total_samples = tf.reduce_sum(tf.ones_like(tf.cast(positive_mask, tf.float32)), axis=1)\n",
    "#         normalizer = num_total_samples + 1e-6\n",
    "#         cls_loss = tf.reduce_sum(cls_loss) / normalizer\n",
    "#         f1_loss = tf.reduce_sum(f1_loss) / normalizer\n",
    "#         box_loss_2 = tf.reduce_sum(box_loss_2) / normalizer\n",
    "\n",
    "#         loss = self._cls_loss_weight * cls_loss + self._box_loss_weight * (box_loss_1 + box_loss_2) + self._f1_loss_weight * f1_loss\n",
    "#         return loss\n",
    "\n",
    "class Loss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=1, delta=2.0, alpha=0.5, gamma=2.0, negative_positive_ratio=3.0, beta=1.0, f1_weight=0.5,\n",
    "                 cls_loss_weight=1.0, box_loss_weight=1.0, f1_loss_weight=1.0):\n",
    "        super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "        self._cls_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self._box_loss = CombinedBoxLoss(delta=delta)\n",
    "        self._f1_loss = F1ScoreLoss(beta=beta)\n",
    "        self._num_classes = num_classes\n",
    "        self._negative_positive_ratio = negative_positive_ratio\n",
    "        self._f1_weight = f1_weight\n",
    "        self._cls_loss_weight = cls_loss_weight\n",
    "        self._box_loss_weight = box_loss_weight\n",
    "        self._f1_loss_weight = f1_loss_weight\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "        box_labels = y_true[:, :, :4]\n",
    "        cls_labels = y_true[:, :, 4:]\n",
    "\n",
    "        positive_mask = tf.cast(tf.math.equal(cls_labels, 1), dtype=tf.bool)\n",
    "        negative_mask = tf.cast(tf.math.equal(cls_labels, -1), dtype=tf.bool)\n",
    "        ignore_mask = tf.cast(tf.math.equal(cls_labels, -2), dtype=tf.bool)\n",
    "\n",
    "        num_positives = tf.reduce_sum(tf.cast(positive_mask, tf.float32), axis=1)\n",
    "        num_negatives = tf.cast(self._negative_positive_ratio * tf.reduce_max(num_positives), tf.int32)\n",
    "\n",
    "        negative_cls_loss = tf.where(negative_mask, self._cls_loss(cls_labels, cls_predictions), 0.)\n",
    "        negative_cls_loss = tf.reshape(negative_cls_loss, [-1])\n",
    "        _, top_k_indices = tf.math.top_k(\n",
    "            negative_cls_loss, k=tf.minimum(num_negatives, tf.shape(negative_cls_loss)[0]), sorted=True\n",
    "        )\n",
    "        negative_indices = tf.where(negative_mask)\n",
    "        random_negative_indices = tf.gather(negative_indices, top_k_indices)\n",
    "        selected_negative_mask = tf.scatter_nd(\n",
    "            random_negative_indices, tf.ones(tf.shape(top_k_indices)[0], dtype=tf.int32),\n",
    "            tf.cast(tf.shape(negative_mask), tf.int64)\n",
    "        )\n",
    "        selected_negative_mask = tf.cast(selected_negative_mask, tf.bool)\n",
    "\n",
    "        selected_mask = tf.math.logical_and(\n",
    "            tf.math.logical_or(tf.cast(positive_mask, tf.bool), selected_negative_mask),\n",
    "            tf.logical_not(ignore_mask)\n",
    "        )\n",
    "\n",
    "        box_loss_1 = self._box_loss(box_labels, box_predictions)\n",
    "        box_loss_2 = self._box_loss(box_labels, box_predictions, tf.cast(selected_mask, tf.float32))\n",
    "        selected_cls_labels = tf.boolean_mask(cls_labels, selected_mask)\n",
    "        selected_cls_predictions = tf.boolean_mask(cls_predictions, selected_mask)\n",
    "\n",
    "        cls_loss = self._cls_loss(selected_cls_labels, selected_cls_predictions)\n",
    "        f1_loss = self._f1_loss(selected_cls_labels, selected_cls_predictions)\n",
    "\n",
    "        num_total_samples = tf.reduce_sum(tf.ones_like(tf.cast(positive_mask, tf.float32)), axis=1)\n",
    "        normalizer = num_total_samples + 1e-6\n",
    "        cls_loss = tf.reduce_mean(cls_loss) / normalizer\n",
    "        f1_loss = tf.reduce_mean(f1_loss) / normalizer\n",
    "        box_loss_2 = tf.reduce_mean(box_loss_2) / normalizer\n",
    "\n",
    "        loss = self._cls_loss_weight * cls_loss + self._box_loss_weight * (box_loss_1 + box_loss_2) + self._f1_loss_weight * f1_loss\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mAP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, iou_threshold=0.5, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "        super(mAP, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.anchors = anchors\n",
    "        self.box_variance = box_variance\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "        # Decode true and predicted boxes\n",
    "        true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "        pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        \n",
    "        # Get predicted class probabilities and labels\n",
    "        # pred_probs = tf.nn.sigmoid(y_pred[..., 4:])\n",
    "        pred_probs = y_pred[..., 4:]\n",
    "        pred_labels = tf.argmax(pred_probs, axis=-1)\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            cls_true = tf.equal(y_true[..., cls + 4], 1)\n",
    "            cls_pred = tf.equal(pred_labels, cls)\n",
    "            \n",
    "            iou = self.iou(true_boxes, pred_boxes)\n",
    "            \n",
    "            cls_true_positives = tf.reduce_sum(tf.cast(tf.logical_and(cls_true, tf.logical_and(cls_pred, tf.greater_equal(iou, self.iou_threshold))), tf.float32))\n",
    "            cls_false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.logical_not(cls_true), tf.logical_and(cls_pred, tf.greater_equal(iou, self.iou_threshold))), tf.float32))  \n",
    "            cls_false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(cls_true, tf.logical_and(tf.logical_not(cls_pred), tf.less(iou, self.iou_threshold))), tf.float32))\n",
    "            \n",
    "            self.true_positives.assign(self.true_positives + tf.one_hot(cls, depth=self.num_classes) * cls_true_positives)\n",
    "            self.false_positives.assign(self.false_positives + tf.one_hot(cls, depth=self.num_classes) * cls_false_positives)\n",
    "            self.false_negatives.assign(self.false_negatives + tf.one_hot(cls, depth=self.num_classes) * cls_false_negatives)\n",
    "\n",
    "    def result(self):\n",
    "        per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros_like(self.true_positives)) \n",
    "        self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "        self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "    def decode_predictions(self, labels, anchors):\n",
    "        anchor_x = anchors[..., 0]\n",
    "        anchor_y = anchors[..., 1] \n",
    "        anchor_w = anchors[..., 2]\n",
    "        anchor_h = anchors[..., 3]\n",
    "\n",
    "        cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "        cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "        height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return decoded_boxes\n",
    "\n",
    "    def iou(self, y_true, y_pred):\n",
    "        x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "        y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "        x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "        y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "\n",
    "        intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "        area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "        union = area_true + area_pred - intersection\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0002\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "initial_learning_rate = 0.005\n",
    "decay_steps = 10\n",
    "decay_rate = 0.95\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "# import tfr\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "model = DetectionModel(num_classes)\n",
    "loss_fn = Loss(num_classes=1)\n",
    "# optimizer = tf.optimizers.Adam(clipnorm = 1.0)\n",
    "\n",
    "\n",
    "# map_metric = MeanAveragePrecision(num_classes=num_classes, anchors=anchors)\n",
    "# iou_metric = IntersectionOverUnion(num_classes=num_classes, anchors=anchors)\n",
    "\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)\n",
    "# iou_metric = MultiBoxIoUMetric(anchors=anchors)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer=optimizer, \n",
    "#               loss=[loss_fn],\n",
    "#               metrics=[Precision()])\n",
    "\n",
    "# \n",
    "model.compile(optimizer='adam', \n",
    "              loss=[loss_fn],\n",
    "              metrics=['accuracy', mAP(num_classes = num_classes, anchors = anchors), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (4, 24, 32, 1)\n",
      "Labels shape: (4, 4032, 5)\n",
      "Images max: 255.0\n",
      "Images min: 1.0\n",
      "165\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "new_batch_size = 4\n",
    "\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "# val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "# for images, labels in val_dataset.take(1):\n",
    "#     print(f\"Images shape: {images.shape}\")\n",
    "#     print(f\"Labels shape: {labels.shape}\")\n",
    "#     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "#     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "\n",
    "val = 0\n",
    "for _, _, _ in val_dataset:\n",
    "    val += 1\n",
    "print(val)\n",
    "\n",
    "\n",
    "train = 0\n",
    "for _, _ in train_dataset:\n",
    "    train += 1\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 10:01:06.036352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-04-16 10:01:08.637482: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14383979785595732346\n",
      "2024-04-16 10:01:08.637525: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2849372726537143423\n",
      "2024-04-16 10:01:08.637551: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9980486516571443000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node Loss/TopKV2 defined at (most recent call last):\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_3006078/3394127767.py\", line 3, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/tmp/ipykernel_3006078/4198690294.py\", line 160, in call\n\nDetected at node Loss/TopKV2 defined at (most recent call last):\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_3006078/3394127767.py\", line 3, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/tmp/ipykernel_3006078/4198690294.py\", line 160, in call\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  input must have at least k columns. Had 1, needed 843\n\t [[{{node Loss/TopKV2}}]]\n\t [[Loss/ones_like/_28]]\n  (1) INVALID_ARGUMENT:  input must have at least k columns. Had 1, needed 843\n\t [[{{node Loss/TopKV2}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_183904]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# validation_data = val_dataset,\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensor/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Loss/TopKV2 defined at (most recent call last):\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_3006078/3394127767.py\", line 3, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/tmp/ipykernel_3006078/4198690294.py\", line 160, in call\n\nDetected at node Loss/TopKV2 defined at (most recent call last):\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_3006078/3394127767.py\", line 3, in <module>\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/home/gpuadmin/anaconda3/envs/tensor/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/tmp/ipykernel_3006078/4198690294.py\", line 160, in call\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  input must have at least k columns. Had 1, needed 843\n\t [[{{node Loss/TopKV2}}]]\n\t [[Loss/ones_like/_28]]\n  (1) INVALID_ARGUMENT:  input must have at least k columns. Had 1, needed 843\n\t [[{{node Loss/TopKV2}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_183904]"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    # validation_data = val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=lr_callback,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, label in val_dataset.take(10):\n",
    "#     # predictions = inference_model.predict(tf.expand_dims(img[0], axis=0))  # img에 첫 번째 차원을 추가\n",
    "#     predictions = model.predict(tf.expand_dims(img[0], axis=0))  # img에 첫 번째 차원을 추가\n",
    "#     print(predictions[0, :10, :])\n",
    "#     # positive_count = tf.reduce_sum(tf.cast(tf.equal(predictions[:, :, 4], 1.0), tf.int32))\n",
    "#     positive_count = tf.reduce_sum(tf.cast(tf.greater(predictions[:, :, 4], -1.0), tf.int32))\n",
    "#     # ignore_count = tf.reduce_sum(tf.cast(tf.less(predictions[:, :, 4], -2.0), tf.int32))\n",
    "\n",
    "#     print(\"Positive 개수:\", positive_count.numpy())\n",
    "#     # print(\"Negative 개수:\", negative_count.numpy())\n",
    "#     # print(\"Ignore 개수:\", ignore_count.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # decode_predictions 함수 정의\n",
    "# def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "#     decoded_boxes = []\n",
    "#     for label_idx, label in enumerate(labels):\n",
    "#         if label[4] > -1.0:  # 양성 레이블 조건 확인\n",
    "#             dx, dy, dw, dh = label[:4]\n",
    "#             anchor = anchors[label_idx]\n",
    "#             anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "#             cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "#             cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "#             width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "#             height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "#             x_min = cx - width / 2\n",
    "#             y_min = cy - height / 2\n",
    "#             decoded_box = [x_min, y_min, width, height]\n",
    "#             decoded_boxes.append(decoded_box)\n",
    "#     return decoded_boxes\n",
    "\n",
    "# # draw_positive_bounding_boxes 함수 정의\n",
    "# def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "#     plt.imshow(image)\n",
    "#     ax = plt.gca()\n",
    "#     for box in decoded_boxes:\n",
    "#         x_min, y_min, width, height = box\n",
    "#         rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#     plt.show()\n",
    "\n",
    "# # 앵커 박스 및 디코딩 로직 사용 예시\n",
    "# # 주의: AnchorBox 클래스의 구현과 train_dataset의 정의가 필요합니다.\n",
    "\n",
    "# # 예를 들어, 앵커 박스 생성 및 train_dataset에서의 사용 예제는 다음과 같습니다:\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시, 실제 사용 시에는 해당 구현에 맞게 조정 필요\n",
    "\n",
    "# for batch in train_dataset.take(1):\n",
    "#     image = batch[0][0].numpy()\n",
    "#     labels = batch[1][0].numpy()\n",
    "#     decoded_boxes = decode_predictions(labels, anchors)\n",
    "#     draw_positive_bounding_boxes(image, decoded_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가정: train_dataset은 이미 tf.data.Dataset 객체로 생성되어 있음\n",
    "# new_batch_size = 9\n",
    "\n",
    "# # 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "# val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "# val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, _, _ in val_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.6, top_n=10):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "\n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "\n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i = scores.pop(0)\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "\n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(10):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePredictions(tf.keras.layers.Layer):\n",
    "    def __init__(self, confidence_threshold=0.5, iou_threshold=0.5, top_k=100, num_classes=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.top_k = top_k\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def call(self, inputs):\n",
    "        predictions = inputs\n",
    "\n",
    "        # 앵커 박스 생성\n",
    "        anchor_box = AnchorBox()\n",
    "        anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "        # 스코어 필터링\n",
    "        scores = predictions[..., -1]\n",
    "        score_mask = scores > self.confidence_threshold\n",
    "        filtered_predictions = tf.boolean_mask(predictions, score_mask)\n",
    "        filtered_anchors = tf.boolean_mask(anchors, tf.reshape(score_mask, [-1]))\n",
    "\n",
    "        # NMS 적용\n",
    "        boxes = self.decode_boxes(filtered_predictions, filtered_anchors)\n",
    "        nms_indices = tf.image.non_max_suppression(boxes, tf.boolean_mask(scores, score_mask), max_output_size=self.top_k, iou_threshold=self.iou_threshold)\n",
    "        decoded_boxes = tf.gather(boxes, nms_indices)\n",
    "        decoded_scores = tf.gather(tf.boolean_mask(scores, score_mask), nms_indices)\n",
    "\n",
    "        # 바운딩 박스와 스코어 합치기\n",
    "        decoded_predictions = tf.concat([decoded_boxes, tf.expand_dims(decoded_scores, axis=-1)], axis=-1)\n",
    "\n",
    "        return decoded_predictions\n",
    "\n",
    "    def decode_boxes(self, predictions, anchors):\n",
    "        box_variance = [0.1, 0.1, 0.2, 0.2]\n",
    "        dx = predictions[..., 0]\n",
    "        dy = predictions[..., 1]\n",
    "        dw = predictions[..., 2]\n",
    "        dh = predictions[..., 3]\n",
    "        anchor_x = anchors[..., 0]\n",
    "        anchor_y = anchors[..., 1]\n",
    "        anchor_w = anchors[..., 2]\n",
    "        anchor_h = anchors[..., 3]\n",
    "\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = tf.exp(dh * box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 모델 생성\n",
    "image = tf.keras.Input(shape=[24, 32, 1], name=\"image\")\n",
    "predictions = model(image, training=False)\n",
    "detections = DecodePredictions(confidence_threshold=0.5)(predictions)\n",
    "inference_model = tf.keras.Model(inputs=image, outputs=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(10):    \n",
    "    predictions = inference_model.predict(tf.expand_dims(img[0], axis=0))  # 첫 번째 이미지에 대한 예측 결과\n",
    "    print(predictions)\n",
    "    draw_bounding_boxes(img[0].numpy(), predictions, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# custom_objects = {\n",
    "#     'DepthwiseSeparableConv': DepthwiseSeparableConv,\n",
    "#     'DepthwiseConv': DepthwiseConv,\n",
    "#     'Conv': Conv,\n",
    "#     'Bottleneck': Bottleneck,\n",
    "#     'CSPDenseLayer': CSPDenseLayer,\n",
    "#     'ChannelAttention': ChannelAttention,\n",
    "#     'SpatialAttention': SpatialAttention,\n",
    "#     'CBAM': CBAM,\n",
    "#     'SPPF': SPPFast,\n",
    "#     'BackBone': BackBone,\n",
    "#     'NeckLayer': NeckLayer,\n",
    "#     'HeadLayer': HeadLayer,\n",
    "#     'CustomModel': CustomModel,\n",
    "#     'DecodePredictions': DecodePredictions\n",
    "# }\n",
    "\n",
    "export_path = 'ObjectDetection/model_v6_backup_plan'\n",
    "inference_model.save(export_path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# custom_objects = {\n",
    "#     'DepthwiseSeparableConv': DepthwiseSeparableConv,\n",
    "#     'DepthwiseConv': DepthwiseConv,\n",
    "#     'Conv': Conv,\n",
    "#     'Bottleneck': Bottleneck,\n",
    "#     'CSPDenseLayer': CSPDenseLayer,\n",
    "#     'ChannelAttention': ChannelAttention,\n",
    "#     'SpatialAttention': SpatialAttention,\n",
    "#     'CBAM': CBAM,\n",
    "#     'SPPF': SPPFast,\n",
    "#     'BackBone': BackBone,\n",
    "#     'NeckLayer': NeckLayer,\n",
    "#     'HeadLayer': HeadLayer,\n",
    "#     'CustomModel': CustomModel,\n",
    "#     'DecodePredictions': DecodePredictions\n",
    "# }\n",
    "\n",
    "# export_path = 'ObjectDetection/model_v6_backup_plan'\n",
    "# loaded_model = tf.keras.models.load_model(export_path, custom_objects=custom_objects, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "# for img, _, _ in val_dataset.take(1):    \n",
    "#     predictions = loaded_model.predict(tf.expand_dims(img[0], axis=0))  # 첫 번째 이미지에 대한 예측 결과\n",
    "#     print(predictions)\n",
    "#     draw_bounding_boxes(img[0].numpy(), predictions, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "saved_model_dir = 'ObjectDetection/model_v6_backup_plan'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# 입력과 출력의 데이터 타입을 설정\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open('ObjectDetection/tflite/model_v6.6.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Lite 모델 로드\n",
    "tflite_model_path = 'ObjectDetection/tflite/model_v6.6.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "for img, _, _ in val_dataset.take(50):\n",
    "    # 입력 이미지 전처리\n",
    "    input_data = tf.expand_dims(img[0], axis=0)\n",
    "    input_data = input_data.numpy()\n",
    "    \n",
    "    # 모델 추론\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "    # print(predictions)\n",
    "    predictions[:, -1]\n",
    "    \n",
    "    scores = predictions[:, -1]\n",
    "\n",
    "    # scores가 0.5 이상인 인덱스를 찾습니다.\n",
    "    indices = tf.where(scores >= 0.5)\n",
    "\n",
    "    # 해당 인덱스에 해당하는 predictions만 필터링합니다.\n",
    "    filtered_predictions = tf.gather(predictions, indices[:, 0])\n",
    "\n",
    "    # 결과 후처리 및 시각화\n",
    "    draw_bounding_boxes(img[0].numpy(), filtered_predictions, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q! 이거 봐라 개쩔꺼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def iou(box1, box2):\n",
    "#     x1, y1, x2, y2 = box1\n",
    "#     x3, y3, x4, y4 = box2\n",
    "    \n",
    "#     x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "#     y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    \n",
    "#     intersection = x_overlap * y_overlap\n",
    "#     area1 = (x2 - x1) * (y2 - y1)\n",
    "#     area2 = (x4 - x3) * (y4 - y3)\n",
    "#     union = area1 + area2 - intersection\n",
    "    \n",
    "#     return intersection / union\n",
    "\n",
    "# def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.9, top_n=9000):\n",
    "#     decoded_boxes = []\n",
    "#     scores = []\n",
    "    \n",
    "#     for i, prediction in enumerate(predictions):\n",
    "#         score = prediction[-1]\n",
    "#         if score > score_threshold:\n",
    "#             scores.append((score, i))\n",
    "    \n",
    "#     # 점수에 따라 내림차순 정렬\n",
    "#     scores.sort(reverse=True)\n",
    "    \n",
    "#     # 상위 N개 선택\n",
    "#     scores = scores[:top_n]\n",
    "    \n",
    "#     # NMS 적용\n",
    "#     for score, i in scores:\n",
    "#         prediction = predictions[i]\n",
    "#         dx, dy, dw, dh = prediction[:4]\n",
    "#         anchor = anchors[i]\n",
    "#         anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        \n",
    "#         cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "#         width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "#         height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        \n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         decoded_box = [x_min, y_min, x_min + width, y_min + height]\n",
    "        \n",
    "#         keep = True\n",
    "#         for other_box in decoded_boxes:\n",
    "#             if iou(decoded_box, other_box) >= iou_threshold:\n",
    "#                 keep = False\n",
    "#                 break\n",
    "        \n",
    "#         if keep:\n",
    "#             decoded_boxes.append(decoded_box)\n",
    "    \n",
    "#     return decoded_boxes\n",
    "\n",
    "# def draw_bounding_boxes(image, boxes):\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     plt.imshow(image)\n",
    "#     ax = plt.gca()\n",
    "#     for box in boxes:\n",
    "#         x_min, y_min, x_max, y_max = box\n",
    "#         rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "# for img, _, _ in val_dataset:    \n",
    "#     predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "#     decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "#     draw_bounding_boxes(img[0].numpy(), decoded_boxes)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    \n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    \n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.9, top_n=9000):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "    \n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "    \n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "    \n",
    "    # NMS 적용\n",
    "    for score, i in scores:\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        \n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        \n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height]\n",
    "        \n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box, other_box) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        \n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "    \n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, save_path=None):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "for i, (img, _, _) in enumerate(val_dataset):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    save_path = f\"prediction_img/output_{i}.png\"  # 이미지 저장 경로 지정\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, save_path=save_path)  # 디코딩된 바운딩 박스를 이미지에 그리고 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
