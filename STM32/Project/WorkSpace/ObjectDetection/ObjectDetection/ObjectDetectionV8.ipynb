{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 사용할 GPU를 설정 (여기서는 GPU 0번만 사용)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # GPU 0만 TensorFlow에서 사용하도록 설정\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        # GPU 메모리 성장 허용 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # GPU가 이미 사용 중이라면 예외 발생\n",
    "        print(e)\n",
    "        \n",
    "# TensorFlow가 실제로 GPU를 사용하는지 확인하기 위한 간단한 테스트\n",
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 2)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.1)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "    \n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    \n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "    class_id = cls[idx]\n",
    "\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "for _, _, _ in val_dataset:\n",
    "    val += 1\n",
    "print(val)\n",
    "\n",
    "\n",
    "train = 0\n",
    "for _, _, _ in train_dataset:\n",
    "    train += 1\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0] * RES_WIDTH,\n",
    "    \t bbox[:,1] * RES_HEIGHT,\n",
    "    \t bbox[:,2] * RES_WIDTH,\n",
    "    \t bbox[:,3] * RES_HEIGHT\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def compute_anchor_boxes(bboxes, img_width, img_height):\n",
    "    all_bboxes = []\n",
    "    for image_bboxes in bboxes:\n",
    "        # 정규화된 좌표를 픽셀 단위 좌표로 변환\n",
    "        pixel_bboxes = np.copy(image_bboxes)\n",
    "        pixel_bboxes[:, 0] *= img_width\n",
    "        pixel_bboxes[:, 1] *= img_height\n",
    "        pixel_bboxes[:, 2] *= img_width\n",
    "        pixel_bboxes[:, 3] *= img_height\n",
    "        all_bboxes.extend(pixel_bboxes)\n",
    "    \n",
    "    all_bboxes = np.array(all_bboxes)\n",
    "    \n",
    "    # 높이가 0인 바운딩 박스 제거\n",
    "    valid_bboxes = all_bboxes[np.logical_and(all_bboxes[:, 2] > all_bboxes[:, 0], all_bboxes[:, 3] > all_bboxes[:, 1])]\n",
    "    \n",
    "    box_sizes = valid_bboxes[:, 2:] - valid_bboxes[:, :2]\n",
    "    box_ratios = box_sizes[:, 0] / box_sizes[:, 1]\n",
    "    \n",
    "    data = np.column_stack((box_sizes[:, 0], box_sizes[:, 1], box_ratios))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=4, random_state=0).fit(data)\n",
    "    \n",
    "    anchor_sizes = kmeans.cluster_centers_[:, :2]\n",
    "    anchor_ratios = kmeans.cluster_centers_[:, 2]\n",
    "    \n",
    "    return anchor_sizes, anchor_ratios\n",
    "\n",
    "bboxes = []\n",
    "for image, image_bboxes, label in train_dataset:\n",
    "    bboxes.append(image_bboxes.numpy())\n",
    "\n",
    "# 이미지 너비와 높이 설정\n",
    "img_width = 32\n",
    "img_height = 24\n",
    "\n",
    "anchor_sizes, anchor_ratios = compute_anchor_boxes(bboxes, img_width, img_height)\n",
    "print(\"anchor_sizes (pixels): \", anchor_sizes)\n",
    "print(\"anchor_ratios: \", anchor_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.55, 0.8, 1.0]        \n",
    "        self.scales = [2** x for x in [1]]\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [5.0, 4.5, 3.5]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios:\n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis=-1),\n",
    "                    [1, 1, 2]\n",
    "                )\n",
    "                dims = tf.cast(dims, tf.float32)  # 데이터 타입을 float32로 변환\n",
    "                for scale in self.scales:\n",
    "                    anchor_dims.append(scale * dims)\n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
    "        return anchor_dims_all\n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0] / RES_WIDTH\n",
    "ymin = anchor[:, 1] / RES_HEIGHT\n",
    "xmax = anchor[:, 2] / RES_WIDTH\n",
    "ymax = anchor[:, 3] / RES_HEIGHT\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x * RES_WIDTH, top_left_y * RES_HEIGHT), width * RES_WIDTH, height * RES_HEIGHT, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelEncoder:\n",
    "#     def __init__(self):\n",
    "#         self._anchor_box = AnchorBox()\n",
    "#         self._box_variance = tf.convert_to_tensor(\n",
    "#             [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "#     def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "#         iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "#         max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "\n",
    "#         matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "#         positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "#         negative_mask = tf.less(max_iou, ignore_iou)\n",
    "\n",
    "#         ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "#         return (\n",
    "#             matched_gt_idx,\n",
    "#             tf.cast(positive_mask, dtype = tf.float32),\n",
    "#             tf.cast(ignore_mask, dtype = tf.float32),\n",
    "#         )\n",
    "    \n",
    "#     def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "#         box_target = tf.concat(\n",
    "#             [\n",
    "#                 (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "#                 tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "#             ],\n",
    "#             axis = -1,\n",
    "#         )\n",
    "#         box_target = box_target / self._box_variance\n",
    "#         return box_target\n",
    "    \n",
    "\n",
    "#     def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "#         anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "#         # 앵커 박스 정규화\n",
    "#         xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "#         ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "#         xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "#         ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "\n",
    "#         # 정규화된 좌표를 스택으로 결합\n",
    "#         normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "#         cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "#         matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "#             normalized_anchor, gt_boxes\n",
    "#         )\n",
    "\n",
    "#         matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "\n",
    "        \n",
    "#         box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "\n",
    "#         matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "\n",
    "#         cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "#         cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "\n",
    "#         cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "#         num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "#         print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "#         label = tf.concat([box_target, cls_target], axis=-1)\n",
    "#         return label\n",
    "\n",
    "#     def encode_batch(self, batch_images, gt_boxes, cls_ids):       \n",
    "#         images_shape = tf.shape(batch_images)\n",
    "#         batch_size = images_shape[0]\n",
    "\n",
    "#         labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "#         for i in range(batch_size):\n",
    "#             label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "#             labels = labels.write(i, label)\n",
    "#         return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou=0.5):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
    "        return matched_gt_idx, max_iou\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "        box_target = box_target / self._box_variance\n",
    "        return box_target\n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # Normalize anchor boxes\n",
    "        xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "        ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "        xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "        ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        matched_gt_idx, iou_scores = self._match_anchor_boxes(normalized_anchor, gt_boxes)\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        \n",
    "        # Use IoU scores as labels for classification\n",
    "        cls_target = iou_scores\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            labels = labels.write(i, label)\n",
    "        return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, labels = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(labels.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    label_idx = 0\n",
    "    for label in labels:\n",
    "        # if label[4] == 1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        # elif label[4] == -1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        dx, dy, dw, dh = label[:4]\n",
    "        anchor = anchors[label_idx]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, width, height]\n",
    "        # print(np.array(decoded_box))\n",
    "        if label[4] == 1.0:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "        label_idx += 1\n",
    "        # if len(np.array(decoded_boxes)) > 1: \n",
    "            # break\n",
    "    print(\"Positive\",len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes    \n",
    "    # print(np.array(decoded_boxes))\n",
    "    \n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    # print(len(decoded_boxes))\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i+=1\n",
    "        # print(box)\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    # print(i)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(1):\n",
    "    image = batch[0][0].numpy()\n",
    "    labels = batch[1][0].numpy()  # 여기서 labels는 [오프셋x, 오프셋y, 스케일w, 스케일h, 클래스, 앵커 박스 인덱스]를 포함한다고 가정\n",
    "    # print(labels)\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -2.0), tf.int32))\n",
    "    # positive_count = tf.reduce_sum(tf.cast(tf.greater(labels[:, 4], 0.5), tf.int32))\n",
    "    # negative_count = tf.reduce_sum(tf.cast(tf.less_equal(labels[:, 4], 0.5), tf.int32))\n",
    "    # ignore_count = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater(labels[:, 4], 0.1), tf.less_equal(labels[:, 4], 0.5)), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(labels, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = layers.DepthwiseConv2D(kernel_size=kernel_size, padding='same' if padding else 'valid', depth_multiplier=1, strides=stride, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.pointwise = layers.Conv2D(out_channels, kernel_size=1, strides=1, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class DepthwiseConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv, self).__init__()\n",
    "        self.depthwise = DepthwiseSeparableConv(out_channels, kernel_size, stride, padding)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=2, padding='SAME'):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding=padding, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bottleneck(layers.Layer):\n",
    "#     def __init__(self, out_channels, stride=1):\n",
    "#         super(Bottleneck, self).__init__()\n",
    "#         self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "#         self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         identity = x\n",
    "#         out = self.conv_0(x)\n",
    "#         out = self.conv_1(out)\n",
    "#         out += identity\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = Conv(out_channels, kernel_size=1, stride=stride, padding='same')\n",
    "        self.conv_1 = Conv(out_channels, kernel_size=3, stride=stride, padding='same')\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.conv_1(out)\n",
    "        out += identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "class SPPFast(layers.Layer):\n",
    "    def __init__(self, filters: int, pool_kernel_sizes: List[int] = [1, 2, 3], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.pool_kernel_sizes = pool_kernel_sizes\n",
    "        self.global_pool = layers.GlobalAveragePooling2D()\n",
    "        self.conv = layers.Conv2D(filters, kernel_size=1, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        height, width = tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "        # 글로벌 평균 풀링과 업샘플링\n",
    "        global_features = self.global_pool(inputs)\n",
    "        global_features = tf.expand_dims(tf.expand_dims(global_features, 1), 1)\n",
    "        global_features = tf.image.resize(global_features, [height, width])\n",
    "        # 다양한 크기의 MaxPooling\n",
    "        pooled_outputs = [\n",
    "            layers.MaxPooling2D(pool_size=kernel_size, strides=1, padding='SAME')(inputs)\n",
    "            for kernel_size in self.pool_kernel_sizes\n",
    "        ]\n",
    "        # 업샘플링 및 컨캐터네이션\n",
    "        pooled_outputs = [\n",
    "            tf.image.resize(pooled, [height, width])\n",
    "            for pooled in pooled_outputs\n",
    "        ]\n",
    "        pooled_outputs.append(global_features)\n",
    "        pooled_outputs.append(inputs)\n",
    "        spp_output = tf.concat(pooled_outputs, axis=-1)\n",
    "        # 컨볼루션 적용\n",
    "        spp_output = self.conv(spp_output)\n",
    "        return spp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding='SAME'):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv1 = Conv(out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.maxpool1 = layers.MaxPooling2D(pool_size=1, strides=1, padding='SAME')\n",
    "        self.maxpool2 = layers.MaxPooling2D(pool_size=3, strides=1, padding='SAME')\n",
    "        self.maxpool3 = layers.MaxPooling2D(pool_size=5, strides=1, padding='SAME')\n",
    "        self.conv2 = Conv(out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "    \n",
    "        pool1 = self.maxpool1(x)\n",
    "        pool2 = self.maxpool2(x)\n",
    "        pool3 = self.maxpool3(x)\n",
    "\n",
    "        concatenated = tf.concat([x, pool1, pool2, pool3], axis=-1)\n",
    "\n",
    "        out = self.conv2(concatenated)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MultiStageFeatureExtractionLayer\n",
    "# class MSFELayer(layers.Layer):\n",
    "#     def __init__(self, sperate_input_channel, out_channel):\n",
    "#         super(MSFELayer, self).__init__()\n",
    "#         # self.sppf = SPPFast(sperate_input_channel)\n",
    "#         self.sppf = SPPF(sperate_input_channel)\n",
    "#         self.cbam = CBAM()\n",
    "#         # self.bottleneck = Bottleneck(sperate_input_channel // 3)\n",
    "#         self.conv1 = Conv(sperate_input_channel, kernel_size=1, stride=1, padding='SAME')\n",
    "#         self.conv_out = Conv(out_channel, kernel_size=3, stride=1, padding='SAME')\n",
    "\n",
    "#     def call(self, x):\n",
    "#         sppf, cbam, conv = tf.split(x, num_or_size_splits=3, axis=-1)\n",
    "#         sppf = self.sppf(sppf)\n",
    "#         cbam = self.cbam(cbam)\n",
    "#         # bottle = self.bottleneck(bottle)\n",
    "#         conv = self.conv1(conv)\n",
    "#         out = tf.concat([sppf, cbam, conv], axis = -1)\n",
    "#         out = self.conv_out(out)\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiStageFeatureExtractionLayer\n",
    "class MSFELayer(layers.Layer):\n",
    "    def __init__(self, sperate_input_channel, out_channel):\n",
    "        super(MSFELayer, self).__init__()\n",
    "        # self.sppf = SPPF(sperate_input_channel)\n",
    "        self.cbam = CBAM()\n",
    "        self.bottleneck = Bottleneck(sperate_input_channel)\n",
    "        # self.conv1 = Conv(sperate_input_channel, kernel_size=1, stride=1, padding='SAME')\n",
    "        self.conv_out = Conv(out_channel, kernel_size=3, stride=1, padding='SAME')\n",
    "\n",
    "    def call(self, x):\n",
    "        # bottle, cbam = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        # sppf = self.sppf(x)\n",
    "        cbam = self.cbam(x)\n",
    "        bottle = self.bottleneck(x)\n",
    "        \n",
    "        # conv = self.conv1(conv)\n",
    "        out = tf.concat([bottle, cbam], axis = -1)\n",
    "        out = self.conv_out(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "        # self.conv = layers.Conv2D(out_channel, kernel_size = 1, strides = 1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "    def call(self, inputs):\n",
    "        out = self.upsample(inputs)\n",
    "        # out = self.conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DTranspose(layers.Layer):\n",
    "    def __init__(self, out_channel, size):\n",
    "        super(Conv2DTranspose, self).__init__()\n",
    "        self.transpose = layers.Conv2DTranspose(filters=out_channel, kernel_size=3, strides=size, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.transpose(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSUpsample(layers.Layer):\n",
    "    def __init__(self, out_channel, kernel_size, size, interpolation = 'bilinear'):\n",
    "        super(CSUpsample, self).__init__()\n",
    "        self.upsample = Upsample(size=size, interpolation = interpolation)\n",
    "        self.transpose = Conv2DTranspose(out_channel * 2, size=size)\n",
    "        self.conv = Conv(out_channel, kernel_size = kernel_size, stride=1, padding='SAME')\n",
    "    \n",
    "    def call(self, x):\n",
    "        upsample, transpose = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        upsample = self.upsample(upsample)\n",
    "        transpose = self.transpose(transpose)\n",
    "\n",
    "        out = tf.concat([upsample, transpose], axis = -1)\n",
    "        out = self.conv(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(out_channels=8, kernel_size=3, stride=1) # 24, 32\n",
    "        self.msfe1 = MSFELayer(8, 12)\n",
    "\n",
    "        self.conv2 = Conv(out_channels=12, kernel_size=3, stride=2) # 12, 16\n",
    "        self.msfe2 = MSFELayer(12, 20)\n",
    "\n",
    "        self.conv3 = Conv(out_channels=20, kernel_size=3, stride=2) # 6, 8\n",
    "        self.msfe3 = MSFELayer(20, 28)\n",
    "\n",
    "        self.conv4 = Conv(out_channels=28, kernel_size=3, stride=2) # 3, 4\n",
    "        self.msfe4 = MSFELayer(28, 36)\n",
    "        # self.sppf = SPPFast(24)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1 = self.conv1(inputs) \n",
    "        p1_out = self.msfe1(p1) # 24, 32, 18\n",
    "\n",
    "        p2 = self.conv2(p1_out)\n",
    "        p2_out = self.msfe2(p2) # 12, 16, 21\n",
    "\n",
    "        p3 = self.conv3(p2_out) \n",
    "        p3_out = self.msfe3(p3) # 6, 8, 24\n",
    "\n",
    "        p4 = self.conv4(p3_out)\n",
    "        p4_out = self.msfe4(p4) # 3, 4, 27\n",
    "\n",
    "        # return p1_out, p2_out, p3_out, p4_out\n",
    "        return p1_out, p2_out, p3_out, p4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Neck, self).__init__()\n",
    "        self.conv1 = Conv(24, kernel_size=1, stride=1)\n",
    "        self.csupsample_c1 = CSUpsample(12, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c1 = MSFELayer(36, 18)\n",
    "\n",
    "        self.csupsample_c2 = CSUpsample(18, kernel_size=1, size=(2, 2))\n",
    "        self.msfe_c2 = MSFELayer(36, 16)\n",
    "        self.conv2_out = Conv(16, kernel_size=1, stride=1)\n",
    "\n",
    "        self.csupsample_c3 = CSUpsample(12, kernel_size=1, size=(2, 2))\n",
    "        # self.msfe_c3_out = MSFELayer(30, 12)\n",
    "\n",
    "#   • p1=tf.Tensor(shape=(None, 24, 32, 18), dtype=float32)\n",
    "#   • p2=tf.Tensor(shape=(None, 12, 16, 18), dtype=float32)\n",
    "#   • p3=tf.Tensor(shape=(None, 6, 8, 24), dtype=float32)\n",
    "#   • p4=tf.Tensor(shape=(None, 3, 4, 27), dtype=float32)\n",
    "\n",
    "    def call(self, p1, p2, p3, p4):\n",
    "        c3 = self.conv1(p4)          # 3, 4, 24   \n",
    "        c3 = self.csupsample_c1(c3)  # 6, 8, 12\n",
    "        c3 = layers.concatenate([c3, p3]) # 6, 8, 36\n",
    "        c3_out = self.msfe_c1(c3)    # 6, 8, 18\n",
    "    \n",
    "        c2 = self.csupsample_c2(c3_out) # 12, 16, 18\n",
    "        c2 = layers.concatenate([c2, p2])  # 12, 16, 36\n",
    "        c2 = self.msfe_c2(c2)              # 12, 16, 16\n",
    "        c2_out = self.conv2_out(c2)        # 12, 16, 16\n",
    "\n",
    "        c1 = self.csupsample_c3(c2_out)       # 24, 32, 12\n",
    "        c1_out = layers.concatenate([c1, p1]) # 24, 32, 30\n",
    "\n",
    "        return c1_out, c2_out, c3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Head, self).__init__()\n",
    "        self.msfe1_out = MSFELayer(30, 18)\n",
    "        \n",
    "        self.conv2 = Conv(out_channels=14, kernel_size=3, stride=2)  # 12, 16\n",
    "        self.msfe2 = MSFELayer(30, 21)\n",
    "        \n",
    "        self.conv3 = Conv(out_channels=18, kernel_size=3, stride=2)  # 6, 8\n",
    "        self.msfe3 = MSFELayer(36, 24)\n",
    "        \n",
    "    def call(self, c1_out, c2_out, c3_out):\n",
    "        h1_out = self.msfe1_out(c1_out)\n",
    "        \n",
    "        h2 = self.conv2(h1_out)  # 12, 16, 16 \n",
    "        h2 = layers.concatenate([h2, c2_out])  # 12, 16, 30\n",
    "        h2_out = self.msfe2(h2)\n",
    "\n",
    "        h3 = self.conv3(h2_out)\n",
    "        h3 = layers.concatenate([h3, c3_out])  # 6, 8, 36\n",
    "        h3_out = self.msfe3(h3)\n",
    "\n",
    "        return h1_out, h2_out, h3_out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPPN(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(FPPN, self).__init__()\n",
    "        self.csupsample1 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csupsample2 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csupsample3 = layers.Conv2DTranspose(filters=36, kernel_size=3, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        # FPN layers\n",
    "        self.lateral_conv1 = MSFELayer(12, 36)\n",
    "        self.lateral_conv2 = MSFELayer(20, 36)\n",
    "        self.lateral_conv3 = MSFELayer(28, 36)\n",
    "        self.lateral_conv4 = MSFELayer(36, 36)\n",
    "        \n",
    "        self.smooth_conv1 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv2 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        self.smooth_conv3 = layers.Conv2D(36, 3, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False)\n",
    "        \n",
    "#   • c1=tf.Tensor(shape=(None, 24, 32, 12), dtype=float32)\n",
    "#   • c2=tf.Tensor(shape=(None, 12, 16, 12), dtype=float32)\n",
    "#   • c3=tf.Tensor(shape=(None, 6, 8, 20), dtype=float32)\n",
    "\n",
    "    def call(self, p1_out, p2_out, p3_out, p4_out):\n",
    "        lateral_conv1 = self.lateral_conv1(p1_out)\n",
    "        lateral_conv2 = self.lateral_conv2(p2_out)\n",
    "        lateral_conv3 = self.lateral_conv3(p3_out)\n",
    "        lateral_conv4 = self.lateral_conv4(p4_out)\n",
    "\n",
    "        fpn_out4 = lateral_conv4\n",
    "        fpn_out3 = layers.Add()([self.csupsample1(fpn_out4), lateral_conv3])\n",
    "        fpn_out2 = layers.Add()([self.csupsample2(fpn_out3), lateral_conv2])\n",
    "        fpn_out1 = layers.Add()([self.csupsample3(fpn_out2), lateral_conv1])\n",
    "\n",
    "        fpn_out1 = self.smooth_conv1(fpn_out1)\n",
    "        fpn_out2 = self.smooth_conv2(fpn_out2)\n",
    "        fpn_out3 = self.smooth_conv3(fpn_out3)\n",
    "        \n",
    "        return fpn_out1, fpn_out2, fpn_out3    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes = 1, num_anchors_per_location = 3):\n",
    "        super(DetectionModel, self).__init__()\n",
    "\n",
    "        self.backbone = BackBone()\n",
    "        self.neck = Neck()\n",
    "        self.head = Head()\n",
    "        self.fppn = FPPN()\n",
    "        self.msfe1 = MSFELayer(36, 72)\n",
    "        # self.conv1 = Conv(36, stride=1)\n",
    "\n",
    "        self.msfe2 = MSFELayer(36, 72)\n",
    "        self.conv2 = Conv(36, stride=1)\n",
    "        \n",
    "        \n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            # layers.Conv2D(36, 3, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            self.msfe1,\n",
    "            # layers.Dropout(0.1),\n",
    "            # layers.Conv2D(36, 3, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            # self.conv1,\n",
    "            # layers.Dropout(0.1),\n",
    "            # layers.BatchNormalization(),\n",
    "            # layers.Activation('relu'),\n",
    "            layers.Conv2D(num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            # layers.Dropout(0.1),\n",
    "            layers.Activation('sigmoid')\n",
    "        ])\n",
    "        \n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            # layers.Conv2D(36, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            # layers.Conv2D(36, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "            self.msfe2,\n",
    "            # self.conv2,\n",
    "            layers.Conv2D(num_anchors_per_location * 4, 1, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), use_bias=False),\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        p1_out, p2_out, p3_out, p4_out = self.backbone(inputs)\n",
    "        # c1, c2, c3 = self.neck(p1, p2, p3, p4)\n",
    "        # h1_out, h2_out, h3_out = self.head(c1, c2, c3)\n",
    "        fpn_out1, fpn_out2, fpn_out3 = self.fppn(p1_out, p2_out, p3_out, p4_out)\n",
    "\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        N = tf.shape(inputs)[0]\n",
    "        \n",
    "        for _, feature in enumerate([fpn_out1, fpn_out2, fpn_out3]):\n",
    "            cls_output = self.classification_head(feature)\n",
    "            reg_output = self.regression_head(feature)\n",
    "            \n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "\n",
    "            cls_outputs.append(cls_output)\n",
    "            reg_outputs.append(reg_output)\n",
    "\n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DetectionModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CIoULoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta=2.0, anchors=None, name=\"CIoULoss\"):\n",
    "#         super(CIoULoss, self).__init__(reduction=\"none\", name=name)\n",
    "#         self._delta = delta\n",
    "#         self.anchors = anchors\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         # Decode true and predicted boxes\n",
    "#         true_boxes = self.decode_predictions(y_true, self.anchors)\n",
    "#         pred_boxes = self.decode_predictions(y_pred, self.anchors)\n",
    "\n",
    "#         # Calculate IoU\n",
    "#         iou = self.iou(true_boxes, pred_boxes)\n",
    "\n",
    "#         # Calculate center distances\n",
    "#         center_true = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) / 2\n",
    "#         center_pred = (pred_boxes[..., 0:2] + pred_boxes[..., 2:4]) / 2\n",
    "#         center_distance = tf.reduce_sum(tf.square(center_true - center_pred), axis=-1)\n",
    "\n",
    "#         # Calculate diagonal lengths\n",
    "#         diag_true = tf.square(true_boxes[..., 2:4] - true_boxes[..., 0:2])\n",
    "#         diag_pred = tf.square(pred_boxes[..., 2:4] - pred_boxes[..., 0:2])\n",
    "#         diag_sum = diag_true + diag_pred\n",
    "\n",
    "#         # Calculate aspect ratio\n",
    "#         aspect_ratio_true = diag_true[..., 0] / diag_true[..., 1]\n",
    "#         aspect_ratio_pred = diag_pred[..., 0] / diag_pred[..., 1]\n",
    "#         aspect_ratio = tf.square(tf.maximum(aspect_ratio_true / aspect_ratio_pred, aspect_ratio_pred / aspect_ratio_true))\n",
    "\n",
    "#         # Calculate CIOU\n",
    "#         ciou = iou - (center_distance / tf.reduce_sum(diag_sum, axis=-1)) - (aspect_ratio / tf.reduce_sum(diag_sum, axis=-1))\n",
    "#         ciou_loss = 1 - tf.clip_by_value(ciou, 0.0, 1.0 - self._delta)\n",
    "\n",
    "#         return ciou_loss\n",
    "\n",
    "#     @staticmethod\n",
    "#     def iou(y_true, y_pred):\n",
    "#         # Calculate intersection\n",
    "#         x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "#         y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "#         x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "#         y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "        \n",
    "#         intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        \n",
    "#         # Calculate union\n",
    "#         area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "#         area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "#         union = area_true + area_pred - intersection\n",
    "        \n",
    "#         # Calculate IoU\n",
    "#         iou = intersection / (union + 1e-6)\n",
    "        \n",
    "#         return iou\n",
    "\n",
    "#     def decode_predictions(self, labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "#         anchor_x = anchors[..., 0]\n",
    "#         anchor_y = anchors[..., 1]\n",
    "#         anchor_w = anchors[..., 2]\n",
    "#         anchor_h = anchors[..., 3]\n",
    "\n",
    "#         cx = labels[..., 0] * box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = labels[..., 1] * box_variance[1] * anchor_h + anchor_y\n",
    "#         width = tf.exp(labels[..., 2] * box_variance[2]) * anchor_w\n",
    "#         height = tf.exp(labels[..., 3] * box_variance[3]) * anchor_h\n",
    "\n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         x_max = x_min + width\n",
    "#         y_max = y_min + height\n",
    "\n",
    "#         decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "#         return decoded_boxes\n",
    "    \n",
    "# class BoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true_box, y_pred_box):\n",
    "#         difference = y_true_box - y_pred_box\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less_equal(absolute_difference, self._delta),\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5 * self._delta\n",
    "#         )\n",
    "#         return tf.reduce_mean(loss, axis=-1)  # 각 앵커에 대한 평균을 반환\n",
    "\n",
    "\n",
    "# class CombinedCIoUBoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta=2.0, anchors=None, weight_ciou=0.5, weight_box=0.5, name=\"CombinedCIoUBoxLoss\"):\n",
    "#         super(CombinedCIoUBoxLoss, self).__init__(reduction=\"none\", name=name)\n",
    "#         self.ciou_loss = CIoULoss(delta=delta, anchors=anchors)\n",
    "#         self.box_loss = BoxLoss(delta=delta)\n",
    "#         self.weight_ciou = weight_ciou\n",
    "#         self.weight_box = weight_box\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         # CIoU and Box loss calculations\n",
    "#         ciou_loss = self.ciou_loss(y_true, y_pred)\n",
    "#         box_loss = self.box_loss(y_true, y_pred)\n",
    "\n",
    "#         # combined_loss = self.weight_ciou * ciou_loss + self.weight_box * box_loss\n",
    "#         return tf.reduce_mean(box_loss, axis=-1)  # 각 앵커에 대한 평균을 반환\n",
    "\n",
    "\n",
    "\n",
    "# class ClassificationLoss(tf.losses.Loss):\n",
    "#     def __init__(self):\n",
    "#         super(ClassificationLoss, self).__init__(reduction=\"none\", name=\"ClassificationLoss\")\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         mae = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "#         loss = mae(y_true, tf.nn.sigmoid(y_pred))\n",
    "#         return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "\n",
    "# class BinaryCrossEntropyError(tf.losses.Loss):\n",
    "#     def __init__(self, reduction=\"auto\", name=\"ClassificationLoss\"):\n",
    "#         super(BinaryCrossEntropyError, self).__init__(reduction=reduction, name=name)\n",
    "    \n",
    "#     def call(self, y_true_cls, y_pred_cls):\n",
    "#         labels = tf.where(y_true_cls == 1, 1, 0)\n",
    "#         bce_loss = tf.keras.losses.binary_crossentropy(\n",
    "#             y_true=tf.cast(labels, dtype=tf.float32),\n",
    "#             y_pred=y_pred_cls,\n",
    "#             from_logits=True\n",
    "#         )\n",
    "#         return tf.reduce_mean(bce_loss, axis=-1)\n",
    "\n",
    "\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, alpha=0.75, gamma=5.0, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.nn.sigmoid(y_pred)\n",
    "#         alpha_t = tf.where(y_true == 1, self.alpha, 1 - self.alpha)\n",
    "#         p_t = tf.where(y_true == 1, y_pred, 1 - y_pred)\n",
    "#         focal_loss = -alpha_t * tf.pow(1 - p_t, self.gamma) * tf.math.log(p_t + tf.keras.backend.epsilon())\n",
    "#         return tf.reduce_mean(focal_loss, axis=-1)\n",
    "\n",
    "\n",
    "# class RecallLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, threshold=0.5, epsilon=1e-7, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.threshold = threshold\n",
    "#         self.epsilon = epsilon\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.nn.sigmoid(y_pred)\n",
    "#         y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "#         tp = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "#         fn = tf.reduce_sum(y_true * (1 - y_pred), axis=-1)\n",
    "#         recall = tp / (tp + fn + self.epsilon)\n",
    "#         return 1 - recall\n",
    "\n",
    "\n",
    "\n",
    "# class ClassBalancedLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, beta=0.9999, name=\"ClassBalancedLoss\"):\n",
    "#         super().__init__(reduction=\"none\", name=name)\n",
    "#         self.beta = beta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         # 레이블 값을 정수 인덱스로 변환\n",
    "#         cls_labels = tf.cast(y_true, tf.int32)\n",
    "#         cls_labels = tf.where(cls_labels == -2, 0, cls_labels)\n",
    "#         cls_labels = tf.where(cls_labels == -1, 1, cls_labels)\n",
    "#         cls_labels = tf.where(cls_labels == 1, 2, cls_labels)\n",
    "\n",
    "#         # 클래스별 샘플 수 계산\n",
    "#         num_classes = y_pred.shape[-1]\n",
    "#         samples_per_cls = tf.math.bincount(cls_labels, minlength=num_classes)\n",
    "\n",
    "#         # 유효한 클래스만 선택\n",
    "#         valid_classes = tf.where(samples_per_cls > 0)[:, 0]\n",
    "#         valid_samples_per_cls = tf.gather(samples_per_cls, valid_classes)\n",
    "\n",
    "#         # 크로스 엔트로피 손실 계산\n",
    "#         cls_labels_one_hot = tf.one_hot(cls_labels, depth=num_classes)\n",
    "#         cls_labels_valid = tf.gather(cls_labels_one_hot, valid_classes, axis=1)\n",
    "#         cls_labels_valid = tf.squeeze(cls_labels_valid, axis=[-2, -1])\n",
    "#         cls_predictions_valid = tf.gather(y_pred, valid_classes, axis=1)\n",
    "#         cls_predictions_valid = tf.squeeze(cls_predictions_valid, axis=-1)\n",
    "\n",
    "#         loss = tf.keras.losses.categorical_crossentropy(cls_labels_valid, cls_predictions_valid, from_logits=True)\n",
    "\n",
    "#         # 클래스 가중치 계산\n",
    "#         effective_num = 1.0 - tf.pow(self.beta, tf.cast(valid_samples_per_cls, tf.float32))\n",
    "#         class_weights = (1.0 - self.beta) / effective_num\n",
    "#         class_weights = tf.expand_dims(class_weights, axis=0)  # 배치 차원 추가\n",
    "#         class_weights = tf.broadcast_to(class_weights, tf.shape(loss)[1:])  # loss의 형상과 일치시킴 (배치 차원 제외)\n",
    "\n",
    "#         # 가중 손실 계산\n",
    "#         weighted_loss = tf.reduce_sum(loss * class_weights, axis=-1)\n",
    "\n",
    "#         return weighted_loss\n",
    "\n",
    "\n",
    "# class CombinedLoss(tf.losses.Loss):\n",
    "#     def __init__(self, alpha=0.75, gamma=5.0, focal_loss_weight=0.5, recall_loss_weight=0.0, name=\"CombinedLoss\"):\n",
    "#         super(CombinedLoss, self).__init__(name=name)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.focal_loss_weight = focal_loss_weight\n",
    "#         self.recall_loss_weight = recall_loss_weight\n",
    "#         self.classification_loss = FocalLoss(alpha=self.alpha, gamma=self.gamma)\n",
    "#         self.mae = ClassificationLoss()\n",
    "#         self.recall_loss = RecallLoss()\n",
    "#         self.binary_error = BinaryCrossEntropyError()\n",
    "#         # self.class_balanced_loss = ClassBalancedLoss()\n",
    "\n",
    "#     def call(self, y_true_cls, y_pred_cls):\n",
    "#         focal_loss = self.classification_loss(y_true_cls, y_pred_cls)\n",
    "#         binary_loss = self.binary_error(y_true_cls, y_pred_cls)\n",
    "#         recall_loss = self.recall_loss(y_true_cls, y_pred_cls)\n",
    "#         mae = self.mae(y_true_cls, y_pred_cls)\n",
    "#         # class_balanced_loss = self.class_balanced_loss(y_true_cls, y_pred_cls)\n",
    "#         combined_loss = (\n",
    "#             self.focal_loss_weight * focal_loss +\n",
    "#             (1 - self.focal_loss_weight - self.recall_loss_weight) * mae\n",
    "#             # class_balanced_loss\n",
    "#         )\n",
    "#         return combined_loss\n",
    "\n",
    "\n",
    "# class Loss(tf.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, gamma=3.0, delta=3, anchors=None):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._cls_loss = CombinedLoss()\n",
    "#         self._box_loss = CombinedCIoUBoxLoss(delta, anchors)  # anchors 전달\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "#         # positive_mask = tf.cast(tf.math.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "#         # ignore_mask = tf.cast(tf.math.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "\n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "        \n",
    "#         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "#         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "\n",
    "#         # cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n",
    "#         # box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "\n",
    "\n",
    "#         cls_weight = 1.0\n",
    "#         box_weight = 1.0\n",
    "#         loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class FocalLoss(tf.keras.losses.Loss):\n",
    "# #     def __init__(self, alpha=0.75, gamma=5.0, threshold=0.5, **kwargs):\n",
    "# #         super(FocalLoss, self).__init__(**kwargs)\n",
    "# #         self.alpha = alpha\n",
    "# #         self.gamma = gamma\n",
    "# #         self.threshold = threshold\n",
    "    \n",
    "# #     def call(self, y_true, y_pred):\n",
    "# #         y_true = tf.cast(y_true, tf.float32)\n",
    "# #         alpha_factor = self.alpha * tf.ones_like(y_true)\n",
    "# #         alpha_t = tf.where(tf.greater(y_true, self.threshold), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "# #         p_t = tf.where(tf.greater(y_true, self.threshold), y_pred, 1 - y_pred)\n",
    "# #         fl = -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
    "\n",
    "# #         return tf.reduce_sum(fl)\n",
    "\n",
    "# class BoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         difference = y_true - y_pred\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less_equal(absolute_difference, self._delta),\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5 * self._delta\n",
    "#         )\n",
    "#         return tf.reduce_sum(loss, axis=-1)\n",
    "    \n",
    "\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, alpha=0.75, gamma=5.0, threshold=0.6, **kwargs):\n",
    "#         super(FocalLoss, self).__init__(**kwargs)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.threshold = threshold\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true_binary = tf.cast(y_true >= 0.5, tf.float32)\n",
    "#         alpha_factor = self.alpha * tf.ones_like(y_true_binary)\n",
    "#         alpha_t = tf.where(tf.equal(y_true_binary, 1.0), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "#         p_t = tf.where(tf.equal(y_true_binary, 1.0), y_pred, 1 - y_pred)\n",
    "        \n",
    "#         # Condition 1: y_true = 1 and p_t < threshold\n",
    "#         condition1 = tf.logical_and(tf.equal(y_true_binary, 1.0), tf.less(p_t, 0.5))\n",
    "        \n",
    "#         # Condition 2: y_true = 0 and p_t >= threshold\n",
    "#         condition2 = tf.logical_and(tf.equal(y_true_binary, 0.0), tf.greater_equal(p_t, 0.5))\n",
    "        \n",
    "#         # Condition 3: y_true = 1 and p_t >= threshold\n",
    "#         condition3 = tf.logical_and(tf.equal(y_true_binary, 1.0), tf.greater_equal(p_t, self.threshold))\n",
    "\n",
    "#         # Condition 4: y_true = 0 and p_t < threshold\n",
    "#         condition4 = tf.logical_and(tf.equal(y_true_binary, 0.0), tf.less(p_t, 0.5))\n",
    "        \n",
    "#         fl = tf.where(condition1, -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "#                       tf.where(condition2, -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "#                                tf.where(condition3, 0.0,\n",
    "#                                         tf.where(condition4, 0.0,\n",
    "#                                                  -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))))))\n",
    "\n",
    "#         return tf.reduce_sum(fl)\n",
    "\n",
    "# class FocalLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, alpha=0.75, gamma=5.0, threshold=0.51, **kwargs):\n",
    "#         super(FocalLoss, self).__init__(**kwargs)\n",
    "#         self.alpha = alpha\n",
    "#         self.gamma = gamma\n",
    "#         self.threshold = threshold\n",
    "    \n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         alpha_factor = self.alpha * tf.ones_like(y_true)\n",
    "#         alpha_t = tf.where(tf.greater(y_true, self.threshold), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "#         p_t = tf.where(tf.greater(y_true, self.threshold), y_pred, 1 - y_pred)\n",
    "#         fl = -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
    "\n",
    "#         return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "# class PrecisionFocusedLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, threshold=0.5, **kwargs): \n",
    "#         super().__init__(**kwargs)\n",
    "#         self.threshold = threshold\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "#         y_true_binary = tf.cast(y_true >= 0.5, tf.float32)\n",
    "\n",
    "#         tp = tf.reduce_sum(y_true_binary * y_pred_binary)\n",
    "#         fp = tf.reduce_sum((1 - y_true_binary) * y_pred_binary)\n",
    "\n",
    "#         precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "#         return 1 - precision\n",
    "\n",
    "\n",
    "\n",
    "# class IoUF1ScoreLoss(tf.keras.losses.Loss):\n",
    "#     def __init__(self, threshold=0.5, beta=0.1, reduction='auto', **kwargs):\n",
    "#         super().__init__(reduction=reduction, **kwargs)\n",
    "#         self.threshold = threshold\n",
    "#         self.beta = beta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_true_binary = tf.cast(y_true >= self.threshold, tf.float32)\n",
    "#         y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "#         tp = tf.reduce_sum(y_true_binary * y_pred_binary, axis=-1)\n",
    "#         fp = tf.reduce_sum((1 - y_true_binary) * y_pred_binary, axis=-1)\n",
    "#         fn = tf.reduce_sum(y_true_binary * (1 - y_pred_binary), axis=-1)\n",
    "\n",
    "#         precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "#         recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "#         beta_squared = self.beta ** 2\n",
    "#         f1_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "#         return 1 - f1_score\n",
    "\n",
    "    \n",
    "# # class Loss(tf.losses.Loss):\n",
    "# #     def __init__(self, num_classes=1, alpha=0.75, gamma=5, delta=3):\n",
    "# #         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "# #         self._box_loss = BoxLoss(delta=delta)\n",
    "# #         # self._pre_loss = PrecisionFocusedLoss()\n",
    "# #         self._cls_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "# #         self._f1_loss = IoUF1ScoreLoss()\n",
    "# #         self._num_classes = num_classes\n",
    "\n",
    "# #     def call(self, y_true, y_pred):\n",
    "# #         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "# #         box_labels = y_true[:, :, :4]\n",
    "# #         box_predictions = y_pred[:, :, :4]\n",
    "\n",
    "# #         cls_labels = y_true[:, :, 4:]\n",
    "# #         cls_predictions = y_pred[:, :, 4:]\n",
    "        \n",
    "# #         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "# #         f1_loss = self._f1_loss(cls_labels, cls_predictions)\n",
    "# #         # pre_loss = self._pre_loss(cls_labels, cls_predictions)\n",
    "# #         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "        \n",
    "# #         cls_loss = 0.3 * cls_loss + 0.7 * f1_loss\n",
    "\n",
    "# #         cls_weight = 0.7\n",
    "# #         box_weight = 0.3\n",
    "# #         loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "# #         return loss\n",
    "\n",
    "# class Loss(tf.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, alpha=0.75, gamma=5, delta=2):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._box_loss = BoxLoss(delta=delta)\n",
    "#         self._pre_loss = PrecisionFocusedLoss()\n",
    "#         self._cls_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "#         # self._f1_loss = IoUF1ScoreLoss()\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "        \n",
    "#         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "#         f1_loss = self._f1_loss(cls_labels, cls_predictions)\n",
    "#         pre_loss = self._pre_loss(cls_labels, cls_predictions)\n",
    "#         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "        \n",
    "#         cls_loss = 0.4 * cls_loss + 0.6 * _pre_loss\n",
    "\n",
    "#         cls_weight = 0.6\n",
    "#         box_weight = 0.4\n",
    "#         loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class ConditionalFocalLoss(tf.keras.losses.Loss): # Recall (0.55 best)\n",
    "    def __init__(self, alpha=0.75, gamma=5.0, threshold=0.55, **kwargs):\n",
    "        super(ConditionalFocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= 0.5, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true_binary)\n",
    "        alpha_t = tf.where(tf.equal(y_true_binary, 1.0), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.equal(y_true_binary, 1.0), y_pred, 1 - y_pred)\n",
    "        \n",
    "        # Condition 1: y_true = 1 and p_t < threshold\n",
    "        condition1 = tf.logical_and(tf.equal(y_true_binary, 1.0), tf.less(p_t, 0.5))\n",
    "        \n",
    "        # Condition 2: y_true = 0 and p_t >= threshold\n",
    "        condition2 = tf.logical_and(tf.equal(y_true_binary, 0.0), tf.greater_equal(p_t, 0.5))\n",
    "        \n",
    "        # Condition 3: y_true = 1 and p_t >= threshold\n",
    "        condition3 = tf.logical_and(tf.equal(y_true_binary, 1.0), tf.greater_equal(p_t, self.threshold))\n",
    "\n",
    "        # Condition 4: y_true = 0 and p_t < threshold\n",
    "        condition4 = tf.logical_and(tf.equal(y_true_binary, 0.0), tf.less(p_t, 0.5))\n",
    "        \n",
    "        fl = tf.where(condition1, -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "                      tf.where(condition2, -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0)),\n",
    "                               tf.where(condition3, 0.0,\n",
    "                                        tf.where(condition4, 0.0,\n",
    "                                                 -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))))))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class FocalLoss(tf.keras.losses.Loss):  # Precision (0.55 best)\n",
    "    def __init__(self, alpha=0.75, gamma=5.0, threshold=0.55, **kwargs):\n",
    "        super(FocalLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_factor = self.alpha * tf.ones_like(y_true)\n",
    "        alpha_t = tf.where(tf.greater(y_true, self.threshold), alpha_factor, 1 - alpha_factor)\n",
    "        \n",
    "        p_t = tf.where(tf.greater(y_true, self.threshold), y_pred, 1 - y_pred)\n",
    "        fl = -alpha_t * tf.pow(1.0 - p_t, self.gamma) * tf.math.log(tf.clip_by_value(p_t, 1e-8, 1.0))\n",
    "\n",
    "        return tf.reduce_sum(fl)\n",
    "\n",
    "\n",
    "class IoUF1ScoreLoss(tf.keras.losses.Loss):  # Precision\n",
    "    def __init__(self, threshold=0.5, beta=3, reduction='auto', **kwargs):\n",
    "        super().__init__(reduction=reduction, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true_binary = tf.cast(y_true >= self.threshold, tf.float32)\n",
    "        y_pred_binary = tf.cast(y_pred >= self.threshold, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true_binary * y_pred_binary, axis=-1)\n",
    "        fp = tf.reduce_sum((1 - y_true_binary) * y_pred_binary, axis=-1)\n",
    "        fn = tf.reduce_sum(y_true_binary * (1 - y_pred_binary), axis=-1)\n",
    "\n",
    "        precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "        recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "\n",
    "        beta_squared = self.beta ** 2\n",
    "        f1_score = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "        return 1 - f1_score\n",
    "\n",
    "\n",
    "class Loss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=1, alpha=0.75, gamma=5, delta=2):\n",
    "        super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "        self._box_loss = BoxLoss(delta=delta)\n",
    "        self._conditional_loss = ConditionalFocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self._cls_loss = FocalLoss(alpha=alpha, gamma=gamma)\n",
    "        self._f1_loss = IoUF1ScoreLoss()\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "\n",
    "        cls_labels = y_true[:, :, 4:]\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "        \n",
    "        cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "        f1_loss = self._f1_loss(cls_labels, cls_predictions)\n",
    "        conditional_loss = self._conditional_loss(cls_labels, cls_predictions)\n",
    "        box_loss = self._box_loss(box_labels, box_predictions)\n",
    "        \n",
    "        cls_loss = 0.6 * cls_loss + 0.2 * f1_loss + 0.2 * conditional_loss\n",
    "\n",
    "        cls_weight = 0.7\n",
    "        box_weight = 0.3\n",
    "        loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class mAP(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, num_classes, iou_threshold=0.5, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "#         super(mAP, self).__init__(name=name, **kwargs)\n",
    "#         self.num_classes = num_classes\n",
    "#         self.iou_threshold = iou_threshold\n",
    "#         self.anchors = anchors\n",
    "#         self.box_variance = box_variance\n",
    "#         self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "#         self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "#         self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         y_pred = tf.cast(y_pred, tf.float32)\n",
    "        \n",
    "#         true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "#         pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        \n",
    "#         pred_probs = tf.nn.sigmoid(y_pred[..., 4])\n",
    "        \n",
    "#         iou = self.iou(true_boxes, pred_boxes)\n",
    "        \n",
    "#         true_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.greater_equal(pred_probs, self.iou_threshold), tf.greater_equal(iou, self.iou_threshold))), tf.float32))\n",
    "#         false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.less(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.greater_equal(pred_probs, self.iou_threshold), tf.greater_equal(iou, self.iou_threshold))), tf.float32))  \n",
    "#         false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.greater_equal(y_true[..., 4], self.iou_threshold), tf.logical_and(tf.less(pred_probs, self.iou_threshold), tf.less(iou, self.iou_threshold))), tf.float32))\n",
    "        \n",
    "#         self.true_positives.assign(self.true_positives + true_positives)\n",
    "#         self.false_positives.assign(self.false_positives + false_positives)\n",
    "#         self.false_negatives.assign(self.false_negatives + false_negatives)\n",
    "\n",
    "#     def result(self):\n",
    "#         per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "#         return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "#     def reset_state(self):\n",
    "#         self.true_positives.assign(tf.zeros_like(self.true_positives)) \n",
    "#         self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "#         self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "#     def decode_predictions(self, labels, anchors):\n",
    "#         anchor_x = anchors[..., 0]\n",
    "#         anchor_y = anchors[..., 1] \n",
    "#         anchor_w = anchors[..., 2]\n",
    "#         anchor_h = anchors[..., 3]\n",
    "\n",
    "#         cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "#         width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "#         height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         x_max = x_min + width\n",
    "#         y_max = y_min + height\n",
    "\n",
    "#         decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "#         return decoded_boxes\n",
    "\n",
    "#     def iou(self, y_true, y_pred):\n",
    "#         x1 = tf.maximum(y_true[..., 0], y_pred[..., 0])\n",
    "#         y1 = tf.maximum(y_true[..., 1], y_pred[..., 1])\n",
    "#         x2 = tf.minimum(y_true[..., 2], y_pred[..., 2])\n",
    "#         y2 = tf.minimum(y_true[..., 3], y_pred[..., 3])\n",
    "\n",
    "#         intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "#         area_true = (y_true[..., 2] - y_true[..., 0]) * (y_true[..., 3] - y_true[..., 1])\n",
    "#         area_pred = (y_pred[..., 2] - y_pred[..., 0]) * (y_pred[..., 3] - y_pred[..., 1])\n",
    "#         union = area_true + area_pred - intersection\n",
    "#         iou = intersection / (union + 1e-6)\n",
    "#         return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class Recall(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Recall', threshold=0.5, **kwargs):\n",
    "        super(Recall, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.actual_positives = self.add_weight(name='actual_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        \n",
    "        actual_positives = tf.cast(labels, self.dtype)\n",
    "        self.actual_positives.assign_add(tf.reduce_sum(actual_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.actual_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class Precision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='Precision', threshold=0.5, **kwargs):\n",
    "        super(Precision, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.predicted_positives = self.add_weight(name='predicted_positives', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # IoU 기준으로 레이블 결정 (0.5 기준)\n",
    "        labels = tf.cast(y_true[:, :, 4:] >= self.threshold, tf.int32)\n",
    "        probabilities = y_pred[:, :, 4:]\n",
    "        pred_positives = tf.cast(probabilities > self.threshold, self.dtype)\n",
    "\n",
    "        true_positives = tf.logical_and(labels == 1, tf.cast(pred_positives, tf.bool))\n",
    "        true_positives = tf.cast(true_positives, self.dtype)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(true_positives))\n",
    "        self.predicted_positives.assign_add(tf.reduce_sum(pred_positives))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives / (self.predicted_positives + tf.keras.backend.epsilon())\n",
    "\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='F1Score', threshold=0.5, **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.precision = Precision(threshold=threshold)\n",
    "        self.recall = Recall(threshold=threshold)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        f1_score = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "        return f1_score\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision.reset_state()\n",
    "        self.recall.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class mAP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, iou_threshold=0.5, score_threshold=0.5, max_detections_per_class=1, max_total_detections=20, anchors=None, box_variance=[0.1, 0.1, 0.2, 0.2], name='mAP', **kwargs):\n",
    "        super(mAP, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.score_threshold = score_threshold\n",
    "        self.max_detections_per_class = max_detections_per_class\n",
    "        self.max_total_detections = max_total_detections\n",
    "        self.anchors = anchors\n",
    "        self.box_variance = box_variance\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Decode predictions and true boxes\n",
    "        true_boxes = self.decode_predictions(y_true[..., :4], self.anchors)\n",
    "        true_labels = tf.cast(y_true[..., 4], tf.int32)\n",
    "        pred_boxes = self.decode_predictions(y_pred[..., :4], self.anchors)\n",
    "        pred_scores = y_pred[..., 4:]\n",
    "\n",
    "        # Batch size for dynamic handling\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "\n",
    "        # Initialize containers for updates\n",
    "        tp_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "        fp_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "        fn_updates = tf.zeros((self.num_classes,), dtype=tf.int32)\n",
    "\n",
    "        # Iterate through the batch\n",
    "        for i in range(batch_size):\n",
    "            single_true_boxes = true_boxes[i]\n",
    "            single_true_labels = true_labels[i]\n",
    "            single_pred_boxes = tf.expand_dims(pred_boxes[i], axis=2)  # NMS expects [N, num_boxes, 1, 4]\n",
    "            single_pred_scores = pred_scores[i]  # Scores from the model\n",
    "\n",
    "            # Perform NMS\n",
    "            selected_indices, selected_scores, num_detections = tf.image.combined_non_max_suppression(\n",
    "                boxes=single_pred_boxes,\n",
    "                scores=single_pred_scores,\n",
    "                max_output_size_per_class=self.max_detections_per_class,\n",
    "                max_total_size=self.max_total_detections,\n",
    "                iou_threshold=self.iou_threshold,\n",
    "                score_threshold=self.score_threshold,\n",
    "                pad_per_class=False,\n",
    "                clip_boxes=False\n",
    "            )\n",
    "\n",
    "            # Filter only detected indices\n",
    "            detected_boxes = tf.gather(single_pred_boxes[:, :, 0], selected_indices)\n",
    "            detected_scores = selected_scores\n",
    "            detected_classes = tf.cast(tf.argmax(detected_scores, axis=-1), tf.int32)\n",
    "\n",
    "            # Count true positives, false positives, and false negatives\n",
    "            for c in range(self.num_classes):\n",
    "                class_mask = tf.equal(single_true_labels, c)\n",
    "                class_true_boxes = tf.boolean_mask(single_true_boxes, class_mask)\n",
    "                class_detected_mask = tf.equal(detected_classes, c)\n",
    "                class_detected_boxes = tf.boolean_mask(detected_boxes, class_detected_mask)\n",
    "\n",
    "                # Compute IOU between true and detected boxes for this class\n",
    "                ious = self.iou(tf.expand_dims(class_true_boxes, axis=1), tf.expand_dims(class_detected_boxes, axis=0))\n",
    "                max_iou = tf.reduce_max(ious, axis=0)\n",
    "                iou_mask = max_iou > self.iou_threshold\n",
    "\n",
    "                # Update TP, FP based on IOU mask\n",
    "                tp_updates = tp_updates + tf.reduce_sum(tf.cast(iou_mask, tf.int32))\n",
    "                fp_updates = fp_updates + tf.reduce_sum(tf.cast(tf.logical_not(iou_mask), tf.int32))\n",
    "                fn_updates = fn_updates + (tf.shape(class_true_boxes)[0] - tf.reduce_sum(tf.cast(iou_mask, tf.int32)))\n",
    "\n",
    "        # Assign updated values to the metric variables\n",
    "        self.true_positives.assign_add(tf.cast(tp_updates, dtype=self.dtype))\n",
    "        self.false_positives.assign_add(tf.cast(fp_updates, dtype=self.dtype))\n",
    "        self.false_negatives.assign_add(tf.cast(fn_updates, dtype=self.dtype))\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        per_class_ap = self.true_positives / (self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        return tf.reduce_mean(per_class_ap)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros_like(self.true_positives))\n",
    "        self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "        self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "    def decode_predictions(self, labels, anchors, batch_size = 9):\n",
    "        anchors = tf.tile(anchors[None, ...], [batch_size, 1, 1])\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = tf.split(anchors, 4, axis=-1)\n",
    "        anchor_w = tf.squeeze(anchor_w, axis=-1)\n",
    "        anchor_h = tf.squeeze(anchor_h, axis=-1)\n",
    "        anchor_x = tf.squeeze(anchor_x, axis=-1)\n",
    "        anchor_y = tf.squeeze(anchor_y, axis=-1)\n",
    "\n",
    "        cx = labels[..., 0] * self.box_variance[0] * anchor_w + anchor_x\n",
    "        cy = labels[..., 1] * self.box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(labels[..., 2] * self.box_variance[2]) * anchor_w\n",
    "        height = tf.exp(labels[..., 3] * self.box_variance[3]) * anchor_h\n",
    "\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        x_max = x_min + width\n",
    "        y_max = y_min + height\n",
    "\n",
    "        decoded_boxes = tf.stack([x_min, y_min, x_max, y_max], axis=-1)\n",
    "        return decoded_boxes\n",
    "\n",
    "    def iou(self, y_true, y_pred):\n",
    "        y_true = tf.expand_dims(y_true, axis=0)\n",
    "        y_pred = tf.expand_dims(y_pred, axis=1)\n",
    "\n",
    "        x1 = tf.maximum(y_true[..., 0:1], y_pred[..., 0:1])\n",
    "        y1 = tf.maximum(y_true[..., 1:2], y_pred[..., 1:2])\n",
    "        x2 = tf.minimum(y_true[..., 2:3], y_pred[..., 2:3])\n",
    "        y2 = tf.minimum(y_true[..., 3:4], y_pred[..., 3:4])\n",
    "\n",
    "        intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        area_true = (y_true[..., 2:3] - y_true[..., 0:1]) * (y_true[..., 3:4] - y_true[..., 1:2])\n",
    "        area_pred = (y_pred[..., 2:3] - y_pred[..., 0:1]) * (y_pred[..., 3:4] - y_pred[..., 1:2])\n",
    "        union = area_true + area_pred - intersection\n",
    "\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0002\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "initial_learning_rate = 0.0005\n",
    "decay_steps = 5\n",
    "decay_rate = 0.5\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.metrics import Precision, Recall\n",
    "# import tfr\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "model = DetectionModel(num_classes)\n",
    "loss_fn = Loss(num_classes=1)\n",
    "# optimizer = tf.optimizers.Adam(clipnorm = 1.0)\n",
    "\n",
    "\n",
    "# map_metric = MeanAveragePrecision(num_classes=num_classes, anchors=anchors)\n",
    "# iou_metric = IntersectionOverUnion(num_classes=num_classes, anchors=anchors)\n",
    "\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)\n",
    "# iou_metric = MultiBoxIoUMetric(anchors=anchors)\n",
    "\n",
    "\n",
    "\n",
    "# model.compile(optimizer=optimizer, \n",
    "#               loss=[loss_fn],\n",
    "#               metrics=[Precision()])\n",
    "\n",
    "# mAP(num_classes = num_classes, anchors = anchors),  \n",
    "model.compile(optimizer='adam', \n",
    "              loss=[loss_fn],\n",
    "              metrics=['accuracy', F1Score(), Precision(), Recall()]) # Precision(), Recall()]) # # mAP(num_classes = num_classes, anchors = anchors), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_batch_size = 12\n",
    "\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     print(f\"Images shape: {images.shape}\")\n",
    "#     print(f\"Labels shape: {labels.shape}\")\n",
    "#     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "#     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "# # for images, labels in val_dataset.take(1):\n",
    "# #     print(f\"Images shape: {images.shape}\")\n",
    "# #     print(f\"Labels shape: {labels.shape}\")\n",
    "# #     print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "# #     print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "\n",
    "\n",
    "# val = 0\n",
    "# for _, _ in val_dataset:\n",
    "#     val += 1\n",
    "# print(val)\n",
    "\n",
    "\n",
    "# train = 0\n",
    "# for _, _ in train_dataset:\n",
    "#     train += 1\n",
    "# print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data = val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=lr_callback,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 51: LearningRateScheduler setting learning rate to 3.125e-06.\n",
    "# Epoch 51/100\n",
    "# 249/473 [==============>...............] - ETA: 6s - loss: 6.8215 - accuracy: 0.7611 - F1Score: 0.6611 - Precision: 0.7209 - Recall: 0.6104\n",
    "\n",
    "\n",
    "# Epoch 17: LearningRateScheduler setting learning rate to 0.00025.\n",
    "# Epoch 17/100\n",
    "# 131/473 [=======>......................] - ETA: 10s - loss: 7.7444 - accuracy: 0.7838 - F1Score: 0.6975 - Precision: 0.7270 - Recall: 0.6702\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2): \n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.5, top_n=20):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "\n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "\n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i = scores.pop(0)\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "\n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        # text = f'{class_name}: {score / 4:.2f}'\n",
    "        text = f'{class_name}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, in val_dataset.take(30):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
