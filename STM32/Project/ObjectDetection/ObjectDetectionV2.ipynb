{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "RES_HEIGHT = 24\n",
    "RES_WIDTH = 32\n",
    "NUM_CLASS = 1\n",
    "N_BATCH = 3\n",
    "N_EPOCH = 200\n",
    "LR = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현제 바운딩박스는 xmin, ymin, xmax, ymax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "datasets = np.load('dataset/ObjectDetection.npz', allow_pickle=True)\n",
    "images, numbers, bboxes = datasets['images'], datasets['numbers'], datasets['bboxes']\n",
    "\n",
    "max_label_length = 4\n",
    "labels = []\n",
    "for num in numbers:\n",
    "    cls = [1] * num if num != 0 else [0]\n",
    "    cls += [0] * (max_label_length - len(cls))\n",
    "    labels.append(cls)\n",
    "\n",
    "# labels = np.array(labels)\n",
    "\n",
    "# non_zero_indices = np.where(numbers != 0)[0]\n",
    "non_zero_indices = np.where(numbers > 1)[0]\n",
    "\n",
    "# numbers가 0이 아닌 항목만 유지\n",
    "images_filtered = images[non_zero_indices]\n",
    "bboxes_filtered = bboxes[non_zero_indices]\n",
    "labels_filtered = np.array(labels)[non_zero_indices]\n",
    "\n",
    "print(images.shape, numbers.shape, bboxes.shape, len(labels))\n",
    "\n",
    "print(images.max(), images.min())\n",
    "\n",
    "dataset = {\n",
    "    'images' : images_filtered,\n",
    "    'bboxes' : bboxes_filtered,\n",
    "    'class' : labels_filtered\n",
    "}\n",
    "\n",
    "print(dataset['images'].shape)\n",
    "print(dataset['bboxes'].shape)\n",
    "print(len(dataset['class']))\n",
    "print(dataset['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset['images'][0])\n",
    "print(dataset['bboxes'][0])\n",
    "print(dataset['images'].max(), dataset['images'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "\n",
    "boxes = bboxes\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.axis('off')\n",
    "image = images\n",
    "print(image[0].shape)\n",
    "print(image[0].shape[0])\n",
    "print(image[0].shape[1])\n",
    "plt.imshow(image[0])\n",
    "ax = plt.gca()\n",
    "boxes = boxes[0]\n",
    "boxes = tf.stack([\n",
    "\t(boxes[:, 0] ), \n",
    "\t(boxes[:, 1] ),\n",
    "\t(boxes[:, 2] ),\n",
    "\t(boxes[:, 3] )], axis = -1\n",
    ")\n",
    "print(\"bbox: \", boxes)\n",
    "# 각 바운딩 박스에 대해 반복하여 그리기\n",
    "for box in boxes:\n",
    "    xmin, ymin, xmax, ymax = box \n",
    "    w, h = xmax - xmin, ymax - ymin\n",
    "    patch = plt.Rectangle(\n",
    "        [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "    )\n",
    "    ax.add_patch(patch)\n",
    "plt.show()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.max(), images.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE_WIDTH = images.shape[2]\n",
    "IMG_SIZE_HEIGHT = images.shape[1]\n",
    "N_DATA = images.shape[0]\n",
    "N_VAL = int(images.shape[0] * 0.2)\n",
    "N_TRAIN = int(images.shape[0] - N_VAL)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "tfr_dir = os.path.join(cur_dir, 'test/tfrecord/')\n",
    "os.makedirs(tfr_dir, exist_ok=True)\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "print(\"IMG_SIZE_WIDTH:  \", IMG_SIZE_WIDTH)\n",
    "print(\"IMG_SIZE_HEIGHT: \", IMG_SIZE_HEIGHT)\n",
    "print(\"N_DATA:          \", N_DATA)\n",
    "print(\"N_TRAIN:         \", N_TRAIN)\n",
    "print(\"N_VAL:           \", N_VAL)\n",
    "\n",
    "shuffle_list = list(range(N_DATA))\n",
    "random.shuffle(shuffle_list)\n",
    "\n",
    "train_idx_list = shuffle_list[:N_TRAIN]\n",
    "val_idx_list = shuffle_list[N_TRAIN:]\n",
    "\n",
    "tfr_train_dir = os.path.join(tfr_dir, 'od_train.tfr')\n",
    "tfr_val_dir = os.path.join(tfr_dir, 'od_val.tfr')\n",
    "\n",
    "writer_train = tf.io.TFRecordWriter(tfr_train_dir)\n",
    "writer_val = tf.io.TFRecordWriter(tfr_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list = tf.train.BytesList(value = [value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list = tf.train.FloatList(value = value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int32_list = tf.train.Int64List(value = [value]))\n",
    "\n",
    "\n",
    "def _bytes_feature_list(value_list):\n",
    "    \"\"\"value_list가 리스트일 때, 이를 serialize하여 bytes list로 변환하는 함수.\"\"\"\n",
    "    value_list = [tf.io.serialize_tensor(tf.constant(v)).numpy() for v in value_list]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['images'] = dataset['images']\n",
    "dataset['bboxes'] = dataset['bboxes']\n",
    "dataset['class'] = np.array(dataset['class'])\n",
    "images = dataset['images']\n",
    "bboxes = dataset['bboxes']\n",
    "cls = dataset['class']\n",
    "print(images.shape)\n",
    "print(bboxes.shape)\n",
    "print(cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in train_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "\n",
    "    number = numbers[idx]\n",
    "    class_id = cls[idx]\n",
    "    # print(len(cls))\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_train.write(example.SerializeToString())\n",
    "writer_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in val_idx_list:\n",
    "    bbox = bboxes[idx]\n",
    "    xmin, ymin, xmax, ymax = bbox[:, 0] / RES_WIDTH, bbox[:, 1] / RES_HEIGHT, bbox[:, 2] / RES_WIDTH, bbox[:, 3] / RES_HEIGHT\n",
    "    bbox = np.stack([xmin, ymin, xmax, ymax], axis=-1).flatten()\n",
    "\n",
    "    image = images[idx]\n",
    "    bimage = image.tobytes()\n",
    "\n",
    "    number = numbers[idx]\n",
    "    class_id = cls[idx]\n",
    "    # print(len(cls))\n",
    "    serialized_cls = tf.io.serialize_tensor(tf.constant(class_id)).numpy()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image': _bytes_feature(bimage),\n",
    "        'bbox': _float_feature(bbox),\n",
    "        'label': _bytes_feature(serialized_cls),\n",
    "        # 'number': _int64_feature(number)\n",
    "    }))\n",
    "    \n",
    "    writer_val.write(example.SerializeToString())\n",
    "writer_val.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "# LR = 0.0005\n",
    "\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        # 'number': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    # image = image / tf.reduce_max(image)\n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    # num_boxes = tf.shape(bbox)[0] // 4\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    # number = tf.cast(parsed_features['number'], tf.int64)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset(tfr_train_dir)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "N_BATCH = 1\n",
    "# LR = 0.0005\n",
    "\n",
    "\n",
    "def _parse_function(tfrecord_serialized):\n",
    "    features = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'bbox': tf.io.VarLenFeature(tf.float32),  \n",
    "        'label': tf.io.FixedLenFeature([], tf.string),\n",
    "        # 'number': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord_serialized, features)\n",
    "\n",
    "    image = tf.io.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    image = tf.reshape(image, [RES_HEIGHT, RES_WIDTH, 1])\n",
    "    image = tf.cast(image, tf.float32) \n",
    "    # image = image / tf.reduce_max(image)\n",
    "\n",
    "    bbox = tf.sparse.to_dense(parsed_features['bbox']) \n",
    "    bbox = tf.cast(bbox, tf.float32)\n",
    "    # num_boxes = tf.shape(bbox)[0] // 4\n",
    "    bbox = tf.reshape(bbox, [-1, 4])\n",
    "\n",
    "    serialized_cls = parsed_features['label']\n",
    "    label = tf.io.parse_tensor(serialized_cls, out_type=tf.int64)\n",
    "    \n",
    "    # number = tf.cast(parsed_features['number'], tf.int64)\n",
    "    return image, bbox, label\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(tfr_val_dir)\n",
    "val_dataset = val_dataset.map(_parse_function, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=N_TRAIN).prefetch(AUTOTUNE).batch(N_BATCH, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, bbox, label in val_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image = image[idx]\n",
    "    bbox = bbox[idx]\n",
    "    label = label[idx]\n",
    "    image = image.numpy()\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()  \n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    print(bbox)\n",
    "    boxes = tf.stack(\n",
    "    \t[\n",
    "    \t bbox[:,0] * RES_WIDTH,\n",
    "    \t bbox[:,1] * RES_HEIGHT,\n",
    "    \t bbox[:,2] * RES_WIDTH,\n",
    "    \t bbox[:,3] * RES_HEIGHT\n",
    "    \t], axis = -1\n",
    "    )\n",
    "    for box in boxes:\n",
    "        xmin, ymin = box[:2]\n",
    "        w, h = box[2:] - box[:2]\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin, ymin], w, h, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xywh(boxes):\n",
    "    return tf.concat(\n",
    "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "def convert_to_corners(boxes):\n",
    "    return tf.concat(\n",
    "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
    "        axis=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, gt_boxes, cls_ids):\n",
    "    bbox = convert_to_xywh(gt_boxes)\n",
    "    return image, bbox, cls_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, bbox, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    anchor_img = np.zeros((*image.shape[:3], 3), dtype=np.uint8)\n",
    "    anchor_img = anchor_img[idx]\n",
    "\n",
    "    strides = [2, 4, 8]\n",
    "    colors = {\n",
    "        2: [0, 255, 0],  # 초록색\n",
    "        4: [0, 0, 255],  # 파란색\n",
    "        8: [255, 0, 0],   # 빨간색\n",
    "    }\n",
    "\n",
    "    for stride in strides:\n",
    "        color = colors[stride]\n",
    "        for y in range(0, anchor_img.shape[0], stride):\n",
    "            for x in range(0, anchor_img.shape[1], stride):\n",
    "                anchor_img[y, x, :] = color\n",
    "\n",
    "    # 이미지 표시\n",
    "    plt.imshow(image[idx], alpha=1)  \n",
    "    plt.imshow(anchor_img, alpha=0.5) \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in val_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    image, bbox, label = preprocess_data(image, bbox, label)\n",
    "    img = image[idx]\n",
    "    box = bbox[idx]\n",
    "    label = label[idx]\n",
    "    print(img.shape)\n",
    "    print(box)\n",
    "    print(label)\n",
    "    print(tf.reduce_max(image), tf.reduce_min(image))\n",
    "    # 이미지 시각화\n",
    "    plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    print(\"width: \", width)\n",
    "    print(\"height: \", height)\n",
    "    boxes = tf.stack(\n",
    "        [\n",
    "            (box[:, 0] - 0.5 * box[:, 2]),  # xmin = x_center - width/2\n",
    "            (box[:, 1] - 0.5 * box[:, 3]),  # ymin = y_center - height/2\n",
    "            box[:, 2],\n",
    "            box[:, 3],\n",
    "            \n",
    "        ], axis=-1\n",
    "    )\n",
    "    print(\"bbox: \", boxes)\n",
    "    # 각 바운딩 박스에 대해 반복하여 그리기\n",
    "    for box in boxes:\n",
    "        xmin, ymin, w, h = box\n",
    "        print(box)\n",
    "        patch = plt.Rectangle(\n",
    "            [xmin * RES_WIDTH, ymin * RES_HEIGHT], w * RES_WIDTH, h * RES_HEIGHT, fill=False, edgecolor=[1, 0, 0], linewidth=2\n",
    "        )\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    print(label)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnchorBox:\n",
    "    def __init__(self):\n",
    "        self.aspect_ratios = [0.6, 1.1, 1.6]         # 이거랑 2268\n",
    "        self.scales = [2** x for x in [0, 1/3, 2/3]] # 이걸로 바운딩박스 갯수 조절가능\n",
    "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
    "        self._strides = [2 ** i for i in range(0, 3)]\n",
    "        self._areas = [x ** 2 for x in [5.5, 6.2, 6.8]]\n",
    "        self._anchor_dims = self._compute_dims()\n",
    "\n",
    "    def _compute_dims(self):\n",
    "        anchor_dims_all = []\n",
    "\n",
    "        for area in self._areas:\n",
    "            anchor_dims = []\n",
    "            for ratio in self.aspect_ratios: \n",
    "                anchor_height = tf.math.sqrt(area / ratio)\n",
    "                anchor_width = area / anchor_height\n",
    "                dims = tf.reshape(\n",
    "                    tf.stack([anchor_width, anchor_height], axis = -1), [1, 1, 2]\n",
    "                )\n",
    "                for scale in self.scales: \n",
    "                    anchor_dims.append(scale * dims) \n",
    "            anchor_dims_all.append(tf.stack(anchor_dims, axis = -2))\n",
    "        return anchor_dims_all \n",
    "    \n",
    "    def _get_anchors(self, feature_height, feature_width, level):\n",
    "        rx = tf.range(feature_width, dtype = tf.float32) + 0.5\n",
    "        ry = tf.range(feature_height, dtype = tf.float32) + 0.5\n",
    "\n",
    "        centers = tf.stack(tf.meshgrid(rx, ry), axis = -1) * self._strides[level - 0] # stride시작점에 따라 바꿔야함 \n",
    "        centers = tf.expand_dims(centers, axis = -2)\n",
    "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
    "\n",
    "        dims = tf.tile(\n",
    "            self._anchor_dims[level - 0], [feature_height, feature_width, 1, 1] \n",
    "        )\n",
    "\n",
    "        anchors = tf.concat([centers, dims], axis=-1) \n",
    "\n",
    "        return tf.reshape(\n",
    "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, image_height, image_width):\n",
    "        anchors = [\n",
    "            self._get_anchors(\n",
    "                tf.math.ceil(image_height / 2 ** i), # 올림\n",
    "                tf.math.ceil(image_width / 2 ** i),\n",
    "                i\n",
    "            )\n",
    "            for i in range(0, 3)\n",
    "        ]\n",
    "\n",
    "        return tf.concat(anchors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = AnchorBox()\n",
    "anchor = anchors.get_anchors(24, 32)\n",
    "\n",
    "# 앵커 박스 정규화\n",
    "xmin = anchor[:, 0] / RES_WIDTH\n",
    "ymin = anchor[:, 1] / RES_HEIGHT\n",
    "xmax = anchor[:, 2] / RES_WIDTH\n",
    "ymax = anchor[:, 3] / RES_HEIGHT\n",
    "\n",
    "# 정규화된 좌표를 스택으로 결합\n",
    "normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "\n",
    "has_negative_values = tf.reduce_any(tf.less(anchor, 0))\n",
    "print(\"Anchor 음수 값:\", has_negative_values.numpy())\n",
    "\n",
    "print(anchor)\n",
    "print(anchor.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_bounding_boxes(data, num_samples):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.imshow(img)\n",
    "    print(img.shape)\n",
    "    data_np = data.numpy()\n",
    "\n",
    "    if len(data) > num_samples:\n",
    "        sampled_indices = np.random.choice(len(data), num_samples, replace=False)\n",
    "        sample_data = data_np[sampled_indices]\n",
    "    else : \n",
    "        sample_data = data_np\n",
    "    print(sample_data)\n",
    "    for center_x, center_y, width, height in sample_data:\n",
    "        top_left_x = center_x - width / 2\n",
    "        top_left_y = center_y - height / 2\n",
    "\n",
    "        rect = patches.Rectangle((top_left_x * RES_WIDTH, top_left_y * RES_HEIGHT), width * RES_WIDTH, height * RES_HEIGHT, linewidth=0.8, edgecolor='white', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "draw_bounding_boxes(normalized_anchor, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_corners = convert_to_corners(boxes1)\n",
    "    boxes2_corners = convert_to_corners(boxes2)\n",
    "    print(boxes1_corners.shape)\n",
    "    print(boxes2_corners.shape)\n",
    "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
    "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])  \n",
    "    \n",
    "    intersection = tf.maximum(rd - lu, 0.0)\n",
    "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
    "    boxes1_area = (boxes1_corners[:, 2] - boxes1_corners[:, 0]) * (boxes1_corners[:, 3] - boxes1_corners[:, 1])\n",
    "    boxes2_area = (boxes2_corners[:, 2] - boxes2_corners[:, 0]) * (boxes2_corners[:, 3] - boxes2_corners[:, 1])\n",
    "    union_area = tf.maximum(boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8)\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA = np.array([[50, 30, 70, 60], [50, 30, 70, 60]])  # 예: [xmin, ymin, xmax, ymax]\n",
    "GT = np.array([[50, 30, 70, 60], [35, 45, 55, 75]])  # 예: [xmin, ymin, xmax, ymax]\n",
    "\n",
    "print(\"GA.shape:\", GA.shape)\n",
    "print(\"GT.shape:\", GT.shape)\n",
    "\n",
    "GA_xywh = convert_to_xywh(GA)\n",
    "print(\"GA (XYWH):\", GA_xywh)\n",
    "\n",
    "GT_xywh = convert_to_xywh(GT)\n",
    "print(\"GT (XYWH):\", GT_xywh)\n",
    "\n",
    "iou = compute_iou(GA_xywh, GT_xywh)\n",
    "print(\"IoU:\", iou)\n",
    "# GA = convert_to_corners(GA)\n",
    "# print(GA)\n",
    "# GT = convert_to_corners(GT)\n",
    "# print(GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 주어진 바운딩 박스 데이터\n",
    "box1 = [50, 30, 70, 60]  # [x_min, y_min, x_max, y_max]\n",
    "box2 = [35, 45, 55, 75]\n",
    "\n",
    "# 그림 생성\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 첫 번째 바운딩 박스 추가\n",
    "rect1 = patches.Rectangle((box1[0], box1[1]), box1[2] - box1[0], box1[3] - box1[1], \n",
    "                          linewidth=2, edgecolor='blue', facecolor='none')\n",
    "ax.add_patch(rect1)\n",
    "\n",
    "# 두 번째 바운딩 박스 추가\n",
    "rect2 = patches.Rectangle((box2[0], box2[1]), box2[2] - box2[0], box2[3] - box2[1], \n",
    "                          linewidth=2, edgecolor='red', facecolor='none')\n",
    "ax.add_patch(rect2)\n",
    "\n",
    "# 축 범위 설정\n",
    "ax.set_xlim(0, 90)\n",
    "ax.set_ylim(0, 90)\n",
    "\n",
    "# 그림 표시\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_anchor_boxes(anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        print(\"iou_matrix:  \", iou_matrix)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        print(\"max_iou:  \", max_iou)\n",
    "\n",
    "\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "    \n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        print(\"negative_mask:  \", negative_mask)\n",
    "\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        print(\"ignore_mask:  \", ignore_mask)\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype = tf.float32),\n",
    "            tf.cast(ignore_mask, dtype = tf.float32),\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = np.array([\n",
    "                    [27.,  18.5,  8.,   7.],\n",
    "                    [18.5, 15.5, 11.,   7.],\n",
    "                    [ 6.,   4.,   8.,   6.],\n",
    "                    [ 0.,   0.,   0.,   0.],\n",
    "                    [ 1., 1., 4.242641, 8.485281 ],\n",
    "                    [ 1.,         1.,         5.3453927, 10.690784 ],\n",
    "                    [ 1.,         1.,         6.7347727, 13.469543 ],\n",
    "                    [30.,        22.,         9.899496,   4.949747 ]])\n",
    "\n",
    "gt_boxes = np.array([[27.,  18.5,  8.,   7., ],\n",
    "                     [18.5, 15.5, 11.,   7. ],\n",
    "                     [ 6.,   4.,   8.,   6. ],\n",
    "                     [ 0.,   0.,   0.,   0. ]])\n",
    "# print(gt_boxes.shape)\n",
    "a, b, c = match_anchor_boxes(tf.cast(anchor, tf.float32), tf.cast(gt_boxes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    def __init__(self):\n",
    "        self._anchor_box = AnchorBox()\n",
    "        self._box_variance = tf.convert_to_tensor(\n",
    "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32)\n",
    "    \n",
    "    def _match_anchor_boxes(self, anchor_boxes, gt_boxes, match_iou = 0.5, ignore_iou = 0.4):\n",
    "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
    "        print(\"iou_matrix:  \", iou_matrix.shape)\n",
    "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
    "        print(\"max_iou:  \", max_iou.shape)\n",
    "\n",
    "        matched_gt_idx = tf.argmax(iou_matrix, axis = 1)\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "        print(\"max_iou:\", max_iou)\n",
    "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        negative_mask = tf.less(max_iou, ignore_iou)\n",
    "        print(\"negative_mask:  \", negative_mask.shape)\n",
    "\n",
    "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
    "        print(\"ignore_mask:  \", ignore_mask.shape)\n",
    "        return (\n",
    "            matched_gt_idx,\n",
    "            tf.cast(positive_mask, dtype = tf.float32),\n",
    "            tf.cast(ignore_mask, dtype = tf.float32),\n",
    "        )\n",
    "    \n",
    "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
    "        print(\"_compute_box_target anchor_boxes: \", anchor_boxes)\n",
    "        print(\"_compute_box_target matched_gt_boxes : \", matched_gt_boxes)\n",
    "        box_target = tf.concat(\n",
    "            [\n",
    "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
    "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:])\n",
    "            ],\n",
    "            axis = -1,\n",
    "        )\n",
    "        print(\"box_target:  \", box_target)\n",
    "        box_target = box_target / self._box_variance\n",
    "        print(\"box_target:  \", box_target)\n",
    "        return box_target\n",
    "    \n",
    "\n",
    "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):        \n",
    "        print(\"image_shape:\", image_shape.shape)\n",
    "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
    "        # 앵커 박스 정규화\n",
    "        xmin = anchor_boxes[:, 0] / RES_WIDTH\n",
    "        ymin = anchor_boxes[:, 1] / RES_HEIGHT\n",
    "        xmax = anchor_boxes[:, 2] / RES_WIDTH\n",
    "        ymax = anchor_boxes[:, 3] / RES_HEIGHT\n",
    "\n",
    "        # 정규화된 좌표를 스택으로 결합\n",
    "        normalized_anchor = tf.stack([xmin, ymin, xmax, ymax], axis=-1)\n",
    "        \n",
    "        print(\"anchor_boxes  : \", normalized_anchor)\n",
    "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
    "        print(\"cls_ids\", cls_ids)\n",
    "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
    "            normalized_anchor, gt_boxes\n",
    "        )\n",
    "        print(\"matched_gt_idx:  \", matched_gt_idx)\n",
    "        print(\"positive_mask:  \", positive_mask)\n",
    "        print(\"ignore_mask:  \", ignore_mask)\n",
    "\n",
    "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
    "\n",
    "        print(\"matched_gt_boxes:  \", matched_gt_boxes)\n",
    "        \n",
    "        box_target = self._compute_box_target(normalized_anchor, matched_gt_boxes)\n",
    "        print(\"box_target:  \", box_target)\n",
    "\n",
    "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
    "        print(\"matched_gt_cls_ids:  \", matched_gt_cls_ids)\n",
    "        \n",
    "        cls_target = tf.where(tf.cast(positive_mask, tf.bool), matched_gt_cls_ids, -1.0)\n",
    "        cls_target = tf.where(tf.cast(ignore_mask, tf.bool), -2.0, cls_target)\n",
    "\n",
    "        print(\"cls_target:  \", cls_target)\n",
    "\n",
    "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
    "        print(\"cls_target:  \", cls_target)\n",
    "        num_ones = tf.math.count_nonzero(tf.equal(cls_target, 1.0))\n",
    "        print(\"Number of 1.0 values in cls_target:\", num_ones)\n",
    "\n",
    "\n",
    "        label = tf.concat([box_target, cls_target], axis=-1)\n",
    "        print(\"label:  \", label)\n",
    "        return label\n",
    "\n",
    "    def encode_batch(self, batch_images, gt_boxes, cls_ids):       \n",
    "        images_shape = tf.shape(batch_images)\n",
    "        print(\"images_shape:  \", images_shape)\n",
    "        batch_size = images_shape[0]\n",
    "        print(\"batch_size:  \", batch_size)\n",
    "\n",
    "        print(\"gt_boxes: \", gt_boxes)\n",
    "\n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        print(\"labels:  \", labels)\n",
    "        # batch_size_val = batch_size.numpy()\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
    "            print(\"label:  \", label)\n",
    "            labels = labels.write(i, label)\n",
    "        return batch_images, labels.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eager execution: \", tf.executing_eagerly())\n",
    "if not tf.executing_eagerly():\n",
    "    tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for image, bbox, label in train_dataset.take(1):\n",
    "    img, box, label = preprocess_data(image, bbox, label)\n",
    "    print(img.shape, box.shape, label.shape)\n",
    "\n",
    "    label_encoder.encode_batch(img, box, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "autotune = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, bbox, label in train_dataset.take(1):\n",
    "    print(img.shape)\n",
    "    print(bbox.shape)\n",
    "    print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count = []\n",
    "negative_count = []\n",
    "ignore_count = []\n",
    "for batch in train_dataset.take(3):\n",
    "    images, labels = batch\n",
    "    print(np.array(images).max(), np.array(images).min())\n",
    "    print(labels.shape)\n",
    "\n",
    "    # labels 텐서에서 positive, negative, ignore 값의 개수를 계산\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[0, :, 4], -2.0), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "    decoded_boxes = []\n",
    "    label_idx = 0\n",
    "    for label in labels:\n",
    "        # if label[4] == 1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        # elif label[4] == -1.0:\n",
    "        #     print(\"label:\", label)\n",
    "        dx, dy, dw, dh = label[:4]\n",
    "        anchor = anchors[label_idx]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, width, height]\n",
    "        # print(np.array(decoded_box))\n",
    "        if label[4] == 1.0:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "        label_idx += 1\n",
    "        # if len(np.array(decoded_boxes)) > 1: \n",
    "            # break\n",
    "    print(\"Positive\",len(np.array(decoded_boxes)))\n",
    "    return decoded_boxes    \n",
    "    # print(np.array(decoded_boxes))\n",
    "    \n",
    "\n",
    "# 바운딩 박스 그리기 함수\n",
    "def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    # print(len(decoded_boxes))\n",
    "    i = 0\n",
    "    for box in decoded_boxes:\n",
    "        i+=1\n",
    "        # print(box)\n",
    "        x_min, y_min, width, height = box\n",
    "        rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    # print(i)\n",
    "    plt.show()\n",
    "\n",
    "# 앵커 박스 생성\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "# train_dataset에서 첫 번째 배치를 가져오고, 바운딩 박스 그리기\n",
    "for batch in train_dataset.take(1):\n",
    "    image = batch[0][0].numpy()\n",
    "    labels = batch[1][0].numpy()  # 여기서 labels는 [오프셋x, 오프셋y, 스케일w, 스케일h, 클래스, 앵커 박스 인덱스]를 포함한다고 가정\n",
    "    # print(labels)\n",
    "    positive_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], 1.0), tf.int32))\n",
    "    negative_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -1.0), tf.int32))\n",
    "    ignore_count = tf.reduce_sum(tf.cast(tf.equal(labels[:, 4], -2.0), tf.int32))\n",
    "\n",
    "    print(\"Positive 개수:\", positive_count.numpy())\n",
    "    print(\"Negative 개수:\", negative_count.numpy())\n",
    "    print(\"Ignore 개수:\", ignore_count.numpy())\n",
    "\n",
    "    # 오프셋 디코딩 및 바운딩 박스 그리기\n",
    "    decoded_boxes = decode_predictions(labels, anchors)\n",
    "    draw_positive_bounding_boxes(image, decoded_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = layers.DepthwiseConv2D(kernel_size=kernel_size, padding='same' if padding else 'valid', depth_multiplier=1, strides=stride, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.pointwise = layers.Conv2D(out_channels, kernel_size=1, strides=1, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "class DepthwiseConv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseConv, self).__init__()\n",
    "        self.depthwise = DepthwiseSeparableConv(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.silu = layers.Activation('silu')\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.silu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(layers.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, strides=stride, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.silu = layers.Activation('silu')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batch_norm(x)\n",
    "        return self.silu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(layers.Layer):\n",
    "    def __init__(self, in_out_channels, mid_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv_0 = Conv(in_out_channels, mid_channels, kernel_size=1, stride=stride, padding=0)\n",
    "        self.conv_1 = Conv(mid_channels, mid_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.conv_3 = Conv(mid_channels, in_out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "\n",
    "    def call(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_0(x)\n",
    "        out = self.conv_1(out)\n",
    "        out = self.conv_3(out)\n",
    "        out += identity\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSPDenseLayer(layers.Layer):\n",
    "    def __init__(self, in_out_channels, bottleneck_mid_channels, out_channels):\n",
    "        super(CSPDenseLayer, self).__init__()\n",
    "        self.conv_0 = Conv(in_out_channels // 2, in_out_channels, kernel_size=3, stride=1)\n",
    "        self.conv_1 = Conv(in_out_channels // 2, in_out_channels, kernel_size=3, stride=1)\n",
    "        self.bottleneck = Bottleneck(in_out_channels, bottleneck_mid_channels)\n",
    "        self.conv_3 = Conv(in_out_channels * 2, out_channels, kernel_size=3, stride=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1, x2 = tf.split(x, num_or_size_splits=2, axis=-1)\n",
    "        x1 = self.conv_0(x1)\n",
    "        x2 = self.conv_1(x2)\n",
    "        out = self.bottleneck(x1)\n",
    "        out = tf.concat([out, x2], axis=-1)\n",
    "        out = self.conv_3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(layers.Layer):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        pooled_features = []\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                pooled = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "            elif pool_type == 'max':\n",
    "                pooled = tf.reduce_max(x, axis=[1, 2], keepdims=True)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        concat = tf.concat(pooled_features, axis=-1)\n",
    "        attention = self.conv(concat)\n",
    "        attention = self.sigmoid(attention)\n",
    "        return x * attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(layers.Layer):\n",
    "    def __init__(self, kernel_size=3):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = layers.Conv2D(1, kernel_size=kernel_size, strides=1, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.sigmoid = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        avg_out = tf.reduce_mean(x, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(x, axis=-1, keepdims=True)\n",
    "        x = tf.concat([avg_out, max_out], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(layers.Layer):\n",
    "    def __init__(self, in_channels, reduction_ratio=16, pool_types=['avg', 'max'], kernel_size=3):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction_ratio, pool_types, kernel_size)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x) * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3, stride=1, padding='SAME'):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv = layers.Conv2D(filters=out_channels, kernel_size=kernel_size, strides=stride, padding=padding, kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.maxpool = layers.MaxPooling2D(pool_size=2, strides=1, padding='SAME')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        \n",
    "        pool1 = self.maxpool(x)\n",
    "        pool2 = self.maxpool(pool1)\n",
    "        # pool3 = self.maxpool(pool2)\n",
    "        \n",
    "        concatenated = tf.concat([x, pool1, pool2], axis=-1)\n",
    "        return concatenated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(layers.Layer):\n",
    "    def __init__(self, size, interpolation = 'bilinear'):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.upsample = layers.UpSampling2D(size=size, interpolation = interpolation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.upsample(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# class BackBone(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(BackBone, self).__init__()\n",
    "#         self.upsample = Upsample(size=(4, 4), interpolation='bilinear')\n",
    "\n",
    "#         self.conv1 = Conv(in_channels=1, out_channels=4, kernel_size=6, stride=2, padding=2)\n",
    "        \n",
    "#         self.conv2 = Conv(in_channels=4, out_channels=8, kernel_size=3, stride=2)\n",
    "#         self.csp1 = CSPDenseLayer(8, 4, 8)\n",
    "#         self.cbam1 = CBAM(16)\n",
    "        \n",
    "#         self.conv3 = Conv(in_channels=8, out_channels=16, kernel_size=3, stride=2)\n",
    "#         self.csp2 = CSPDenseLayer(16, 8, 16)\n",
    "#         self.cbam2 = CBAM(32)\n",
    "        \n",
    "#         self.conv4 = Conv(in_channels=16, out_channels=32, kernel_size=3, stride=2)\n",
    "#         self.csp3 = CSPDenseLayer(32, 16, 32)\n",
    "#         self.cbam3 = CBAM(32)\n",
    "#         self.sppf = SPPF(out_channels=32, kernel_size=3, stride=1)\n",
    "#         self.conv5 = Conv(in_channels = 32, out_channels = 32, kernel_size=3, stride=1)\n",
    "\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         x = self.upsample(inputs)\n",
    "#         x = self.conv1(x)   \n",
    "#         x = self.conv2(x)   # 24, 32\n",
    "#         p3 = self.csp1(x)   # 24, 32\n",
    "#         p3 = self.cbam1(p3) # 24, 32\n",
    "\n",
    "#         x = self.conv3(p3) # 6, 8\n",
    "#         p4 = self.csp2(x)  # 12, 16\n",
    "#         p4 = self.cbam2(p4)\n",
    "\n",
    "#         x = self.conv4(p4) \n",
    "#         p5 = self.csp3(x)  \n",
    "#         p5 = self.cbam3(p5)\n",
    "#         p5 = self.sppf(p5)\n",
    "#         p5 = self.conv5(p5) # 6, 8\n",
    "        \n",
    "#         return p3, p4, p5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeckLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(NeckLayer, self).__init__()\n",
    "#         self.conv_c10 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "#         self.upsample1 = layers.Conv2DTranspose(filters = 32, kernel_size = 1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "#         self.csp = CSPDenseLayer(32, 16, 32)\n",
    "#         self.conv_c14 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "#         self.upsample2 = layers.Conv2DTranspose(filters = 32, kernel_size = 1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "#     def call(self, p3, p4, p5):\n",
    "#         c10 = self.conv_c10(p5) # 15, 20 \n",
    "#         x = self.upsample1(c10) # 30, 40\n",
    "#         x = layers.concatenate([x, p4])\n",
    "#         x = self.csp(x) \n",
    "#         c14 = self.conv_c14(x) \n",
    "#         x = self.upsample2(c14) # 60, 80\n",
    "#         x = layers.concatenate([x, p3])\n",
    "#         return x, c14, c10\n",
    "    \n",
    "# # • x=tf.Tensor(shape=(None, 48, 64, 16), dtype=float32)\n",
    "# # • c14=tf.Tensor(shape=(None, 24, 32, 25), dtype=float32)\n",
    "# # • c10=tf.Tensor(shape=(None, 12, 16, 128), dtype=float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HeadLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super(HeadLayer, self).__init__()\n",
    "#         self.csp_dense1 = CSPDenseLayer(64, 32, 64)\n",
    "#         self.conv1 = layers.Conv2D(64, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "#         self.cbam1 = CBAM(64)\n",
    "#         self.csp_dense2 = CSPDenseLayer(64, 32, 64)\n",
    "#         self.conv2 = layers.Conv2D(64, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "#         self.cbam2 = CBAM(64)\n",
    "#         self.csp_dense3 = CSPDenseLayer(64, 32, 64)\n",
    "\n",
    "#         # self.channel_adjust1 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False) \n",
    "#         # self.channel_adjust2 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False) \n",
    "#         # self.channel_adjust3 = tf.keras.layers.Conv2D(64, 1, padding='same', use_bias=False) \n",
    "        \n",
    "#     def call(self, x, c14, c10):\n",
    "#         x = self.cbam1(x)\n",
    "#         out1 = self.csp_dense1(x)\n",
    "#         # out1_adj = self.channel_adjust1(out1)\n",
    "#         x = self.conv1(out1)\n",
    "#         x = layers.concatenate([x, c14])\n",
    "#         x = self.cbam2(x)\n",
    "#         out2 = self.csp_dense2(x)\n",
    "#         # out2_adj = self.channel_adjust2(out2)\n",
    "#         x = self.conv2(out2)\n",
    "#         x = layers.concatenate([x, c10])\n",
    "#         out3 = self.csp_dense3(x)\n",
    "#         # out3_adj = self.channel_adjust3(out3)\n",
    "#         return out1, out2, out3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomModel(tf.keras.Model):\n",
    "#     def __init__(self, num_classes=1, num_anchors_per_location=9):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.backbone = BackBone()\n",
    "#         self.neck = NeckLayer()\n",
    "#         self.head = HeadLayer()\n",
    "#         self.backbone.trainable = True\n",
    "#         self.neck.trainable = True\n",
    "#         self.head.trainable = True\n",
    "\n",
    "#         self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#         # 각 위치(픽셀)에서 예측해야 하는 앵커 박스의 수\n",
    "#         self.num_anchors_per_location = num_anchors_per_location\n",
    "\n",
    "#         self.classification_conv1 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         self.classification_conv2 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "     \n",
    "#         self.regression_conv1 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         self.regression_conv2 = layers.Conv2D(128, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "    \n",
    "    \n",
    "#         # 분류 헤드\n",
    "#         self.classification_head = tf.keras.Sequential([\n",
    "#             self.classification_conv1,\n",
    "#             self.classification_conv2,\n",
    "#             layers.Conv2D(self.num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         ])\n",
    "\n",
    "#         # 회귀 헤드\n",
    "#         self.regression_head = tf.keras.Sequential([\n",
    "#             self.regression_conv1,\n",
    "#             self.regression_conv2,\n",
    "#             layers.Conv2D(self.num_anchors_per_location * 4, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer = self.prior_probability)\n",
    "#         ])\n",
    "\n",
    "#         self.classification_head.trainable = True\n",
    "#         self.regression_head.trainable = True\n",
    "        \n",
    "#     def call(self, inputs):\n",
    "#         p3, p4, p5 = self.backbone(inputs)\n",
    "#         x, c14, c10 = self.neck(p3, p4, p5)\n",
    "#         out1, out2, out3 = self.head(x, c14, c10)\n",
    "\n",
    "#         cls_outputs = []\n",
    "#         reg_outputs = []\n",
    "#         N = tf.shape(inputs)[0]\n",
    "#         for feature in [out1, out2, out3]:\n",
    "#             # print(feature.shape)\n",
    "#             # 첫 번째 feature 맵 (None, 12, 16, 32)의 경우: 12x16 위치 각각에 9개의 앵커 박스 = 12x16x9 = 1728\n",
    "#             # 두 번째 feature 맵 (None, 6, 8, 32)의 경우: 6x8 위치 각각에 9개의 앵커 박스 = 6x8x9 = 432\n",
    "#             # 세 번째 feature 맵 (None, 3, 4, 32)의 경우: 3x4 위치 각각에 9개의 앵커 박스 = 3x4x9 = 108\n",
    "#             cls_output = self.classification_head(feature)\n",
    "#             reg_output = self.regression_head(feature)\n",
    "#             reg_output = tf.reshape(reg_output, [N, -1, 4])\n",
    "            \n",
    "#             cls_output = tf.reshape(cls_output, [N, -1, self.num_classes])\n",
    "#             cls_outputs.append(cls_output)\n",
    "#             reg_outputs.append(reg_output)\n",
    "\n",
    "#         # 결과 결합\n",
    "#         reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "#         cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "#         # 최종 출력\n",
    "#         final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "#         # print(final_output.shape)\n",
    "#         return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        self.conv1 = Conv(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.csp1 = CSPDenseLayer(8, 4, 8)\n",
    "        self.cbam1 = CBAM(8)\n",
    "        self.conv2 = Conv(in_channels=8, out_channels=16, kernel_size=3, stride=2)\n",
    "        self.csp2 = CSPDenseLayer(16, 8, 16)\n",
    "        self.cbam2 = CBAM(16)\n",
    "        self.conv3 = Conv(in_channels=16, out_channels=32, kernel_size=3, stride=2)\n",
    "        self.csp3 = CSPDenseLayer(32, 16, 32)\n",
    "        self.cbam3 = CBAM(32)\n",
    "        self.sppf = SPPF(out_channels=32, kernel_size=3, stride=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        p1 = self.csp1(x)  # 24, 32\n",
    "        p1 = self.cbam1(p1)\n",
    "        x = self.conv2(p1)  # 12, 16\n",
    "        p2 = self.csp2(x)\n",
    "        p2 = self.cbam2(p2)\n",
    "        x = self.conv3(p2)  # 6, 8\n",
    "        p3 = self.csp3(x)\n",
    "        p3 = self.cbam3(p3)\n",
    "        p3 = self.sppf(p3)\n",
    "        return p1, p2, p3\n",
    "\n",
    "class NeckLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(NeckLayer, self).__init__()\n",
    "        self.conv_c3 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.upsample1 = layers.Conv2DTranspose(filters=32, kernel_size=1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.csp = CSPDenseLayer(32, 16, 32)\n",
    "        self.conv_c2 = Conv(in_channels=32, out_channels=64, kernel_size=1, stride=1)\n",
    "        self.upsample2 = layers.Conv2DTranspose(filters=16, kernel_size=1, strides=(2, 2), padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "\n",
    "    def call(self, p1, p2, p3):\n",
    "        c3 = self.conv_c3(p3)  #6, 8\n",
    "        x = self.upsample1(c3) #12, 16\n",
    "        x = layers.concatenate([x, p2])\n",
    "        x = self.csp(x)\n",
    "        c2 = self.conv_c2(x)\n",
    "        x = self.upsample2(c2) # 24, 32\n",
    "        x = layers.concatenate([x, p1])\n",
    "        return x, c2, c3\n",
    "\n",
    "class HeadLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(HeadLayer, self).__init__()\n",
    "        self.csp_dense1 = CSPDenseLayer(16, 8, 32)\n",
    "        self.conv1 = layers.Conv2D(16, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.cbam1 = CBAM(32)\n",
    "        self.csp_dense2 = CSPDenseLayer(32, 16, 32)\n",
    "        self.conv2 = layers.Conv2D(32, 1, strides=2, padding='same', kernel_initializer=tf.keras.initializers.HeNormal())\n",
    "        self.cbam2 = CBAM(64)\n",
    "        self.csp_dense3 = CSPDenseLayer(64, 32, 32)\n",
    "\n",
    "    def call(self, x, c2, c3):\n",
    "        out1 = self.csp_dense1(x) # 24, 32\n",
    "        x = self.conv1(out1)  \n",
    "        x = layers.concatenate([x, c2]) \n",
    "        x = self.cbam1(x)\n",
    "        out2 = self.csp_dense2(x)\n",
    "        x = self.conv2(out2)\n",
    "        x = layers.concatenate([x, c3])\n",
    "        x = self.cbam2(x)\n",
    "        out3 = self.csp_dense3(x)\n",
    "        return out1, out2, out3\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=1, num_anchors_per_location=9):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.backbone = BackBone()\n",
    "        self.neck = NeckLayer()\n",
    "        self.head = HeadLayer()\n",
    "\n",
    "        self.batch_norm_chead = layers.BatchNormalization()\n",
    "        self.batch_norm_rhead = layers.BatchNormalization()\n",
    "\n",
    "        self.prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors_per_location = num_anchors_per_location\n",
    "        \n",
    "        self.classification_head = tf.keras.Sequential([\n",
    "            # self.batch_norm_chead,\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer=self.prior_probability),\n",
    "            layers.Conv2D(64, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer=self.prior_probability),\n",
    "            layers.Conv2D(self.num_anchors_per_location * num_classes, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer=self.prior_probability)\n",
    "        ])\n",
    "        \n",
    "        self.regression_head = tf.keras.Sequential([\n",
    "            # self.batch_norm_rhead,\n",
    "            layers.Conv2D(32, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer=self.prior_probability),\n",
    "            layers.Conv2D(64, 1, strides=1, padding='same', kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer=self.prior_probability),\n",
    "            layers.Conv2D(self.num_anchors_per_location * 4, 3, padding=\"same\", kernel_initializer=tf.keras.initializers.HeNormal(), bias_initializer=self.prior_probability)\n",
    "        ])\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        p1, p2, p3 = self.backbone(inputs)\n",
    "        x, c2, c3 = self.neck(p1, p2, p3)\n",
    "        out1, out2, out3 = self.head(x, c2, c3)\n",
    "\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        N = tf.shape(inputs)[0]\n",
    "\n",
    "        for _, feature in enumerate([out1, out2, out3]):\n",
    "            cls_output = self.classification_head(feature)\n",
    "            reg_output = self.regression_head(feature)\n",
    "            \n",
    "            H, W = feature.shape[1], feature.shape[2]\n",
    "            num_anchors = H * W * self.num_anchors_per_location\n",
    "\n",
    "            reg_output = tf.reshape(reg_output, [N, num_anchors, 4])\n",
    "            cls_output = tf.reshape(cls_output, [N, num_anchors, self.num_classes])\n",
    "\n",
    "            cls_outputs.append(cls_output)\n",
    "            reg_outputs.append(reg_output)\n",
    "\n",
    "        reg_outputs = tf.concat(reg_outputs, axis=1)\n",
    "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
    "        final_output = tf.concat([reg_outputs, cls_outputs], axis=-1)\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel(num_classes=1)\n",
    "model.trainable = True\n",
    "model.build(input_shape=(None, 24, 32, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BoxLoss(tf.losses.Loss):  \n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(\n",
    "#             reduction=\"none\", name=\"BoxLoss\"\n",
    "#         )\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         difference = y_true - y_pred\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less_equal(absolute_difference, self._delta),  # 여기를 수정\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5\n",
    "#         )\n",
    "\n",
    "#         return tf.reduce_sum(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ClassificationLoss(tf.losses.Loss):   \n",
    "#     def __init__(self, alpha, gamma):\n",
    "#         super(ClassificationLoss, self).__init__(\n",
    "#             reduction=\"none\", name=\"ClassificationLoss\"\n",
    "#         )\n",
    "#         self._alpha = alpha\n",
    "#         self._gamma = gamma\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "#             labels=y_true, logits=y_pred)\n",
    "        \n",
    "#         probs = tf.nn.sigmoid(y_pred)\n",
    "#         alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
    "#         pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
    "        \n",
    "#         loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
    "\n",
    "#         return tf.reduce_sum(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Loss(tf.losses.Loss):    \n",
    "#     def __init__(self, num_classes=1, alpha=0.75, gamma=2.0, delta=1.0):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._cls_loss = ClassificationLoss(alpha, gamma)\n",
    "#         self._box_loss = BoxLoss(delta)\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "#         print(y_pred.shape)\n",
    "#         # 바운딩 박스 레이블과 예측값\n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "#         # 클래스 레이블과 예측값\n",
    "#         # cls_labels = tf.one_hot(\n",
    "#         #     tf.cast(y_true[:, :, 4], dtype=tf.int32),\n",
    "#         #     depth=self._num_classes,\n",
    "#         #     dtype=tf.float32,\n",
    "#         # )\n",
    "#         # print(cls_labels)\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "#         # print(cls_predictions)\n",
    "#         # cls_true = y_true[:, :, 4:]\n",
    "#         # positive와 ignore 마스크\n",
    "#         positive_mask = tf.cast(tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "#         ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "\n",
    "#         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "#         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "\n",
    "#         # Positive 예시에 대한 추가 가중치 적용\n",
    "#         # positive_weight_multiplier = 10.0\n",
    "#         # cls_loss = tf.where(tf.equal(positive_mask, 1.0), cls_loss * positive_weight_multiplier, cls_loss)\n",
    "\n",
    "#         # Ignore 예시에 대한 손실 0으로 설정\n",
    "#         cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n",
    "#         box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "\n",
    "#         # 손실 정규화\n",
    "#         normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
    "#         cls_loss = tf.math.divide_no_nan(tf.reduce_sum(cls_loss, axis=-1), normalizer)\n",
    "#         box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
    "        \n",
    "#         # 최종 손실 계산\n",
    "#         loss = cls_loss + box_loss\n",
    "#         return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxLoss(tf.losses.Loss):\n",
    "    def __init__(self, delta):\n",
    "        super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "        self._delta = delta\n",
    "\n",
    "    # def call(self, y_true, y_pred):\n",
    "    #     difference = y_true - y_pred\n",
    "    #     absolute_difference = tf.abs(difference)\n",
    "    #     squared_difference = difference ** 2\n",
    "    #     loss = tf.keras.backend.switch(\n",
    "    #         tf.less_equal(absolute_difference, self._delta),\n",
    "    #         0.5 * squared_difference,\n",
    "    #         absolute_difference - 0.5 * self._delta\n",
    "    #     )\n",
    "    #     return tf.reduce_sum(loss, axis=-1)\n",
    "    def call(self, y_true, y_pred):\n",
    "        difference = y_true - y_pred\n",
    "        absolute_difference = tf.abs(difference)\n",
    "        squared_difference = difference ** 2\n",
    "        loss = tf.where(\n",
    "            tf.less_equal(absolute_difference, self._delta),\n",
    "            0.5 * squared_difference,\n",
    "            absolute_difference - 0.5 * self._delta\n",
    "        )\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class ClassificationLoss(tf.losses.Loss):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super(ClassificationLoss, self).__init__(reduction=\"none\", name=\"ClassificationLoss\")\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "\n",
    "    # def call(self, y_true, y_pred):\n",
    "    #     cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    #     probs = tf.nn.sigmoid(y_pred)\n",
    "    #     alpha = tf.keras.backend.switch(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
    "    #     pt = tf.keras.backend.switch(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
    "    #     loss = alpha * tf.math.pow(1.0 - pt + 1e-6, self._gamma) * cross_entropy\n",
    "    #     return tf.reduce_sum(loss, axis=-1)\n",
    "    def call(self, y_true, y_pred):\n",
    "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "        probs = tf.nn.sigmoid(y_pred)\n",
    "        alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
    "        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
    "        loss = alpha * tf.math.pow(1.0 - pt + 1e-6, self._gamma) * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "\n",
    "class Loss(tf.losses.Loss):\n",
    "    def __init__(self, num_classes=1, alpha=0.5, gamma=3.0, delta=2.0):\n",
    "        super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "        self._cls_loss = ClassificationLoss(alpha, gamma)\n",
    "        self._box_loss = BoxLoss(delta)\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        \n",
    "        box_labels = y_true[:, :, :4]\n",
    "        box_predictions = y_pred[:, :, :4]\n",
    "\n",
    "        cls_labels = y_true[:, :, 4:]\n",
    "        cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "        positive_mask = tf.cast(tf.math.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "        ignore_mask = tf.cast(tf.math.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "\n",
    "        cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "        box_loss = self._box_loss(box_labels, box_predictions)\n",
    "\n",
    "        cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n",
    "        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "\n",
    "        normalizer = tf.reduce_sum(positive_mask, axis=-1) + 1e-6\n",
    "        cls_loss = tf.math.divide_no_nan(tf.reduce_sum(cls_loss, axis=-1), normalizer)\n",
    "        box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
    "\n",
    "        cls_weight = 1.5\n",
    "        box_weight = 1.0\n",
    "        loss = cls_weight * cls_loss + box_weight * box_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BoxLoss(tf.losses.Loss):\n",
    "#     def __init__(self, delta):\n",
    "#         super(BoxLoss, self).__init__(reduction=\"none\", name=\"BoxLoss\")\n",
    "#         self._delta = delta\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         difference = y_true - y_pred\n",
    "#         absolute_difference = tf.abs(difference)\n",
    "#         squared_difference = difference ** 2\n",
    "#         loss = tf.where(\n",
    "#             tf.less(absolute_difference, self._delta),\n",
    "#             0.5 * squared_difference,\n",
    "#             absolute_difference - 0.5 * self._delta\n",
    "#         )\n",
    "#         return tf.reduce_sum(loss, axis=-1)\n",
    "\n",
    "# class ClassificationLoss(tf.losses.Loss):\n",
    "#     def __init__(self, alpha, gamma):\n",
    "#         super(ClassificationLoss, self).__init__(reduction=\"none\", name=\"ClassificationLoss\")\n",
    "#         self._alpha = alpha\n",
    "#         self._gamma = gamma\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "#         probs = tf.nn.sigmoid(y_pred)\n",
    "#         alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
    "#         pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
    "#         focal_loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
    "#         return tf.reduce_sum(focal_loss, axis=-1)\n",
    "\n",
    "# class Loss(tf.losses.Loss):\n",
    "#     def __init__(self, num_classes=1, alpha=0.25, gamma=2.0, delta=1.0):\n",
    "#         super(Loss, self).__init__(reduction=\"auto\", name=\"Loss\")\n",
    "#         self._cls_loss = ClassificationLoss(alpha, gamma)\n",
    "#         self._box_loss = BoxLoss(delta)\n",
    "#         self._num_classes = num_classes\n",
    "\n",
    "#     def call(self, y_true, y_pred):\n",
    "#         y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "#         box_labels = y_true[:, :, :4]\n",
    "#         box_predictions = y_pred[:, :, :4]\n",
    "#         cls_labels = y_true[:, :, 4:]\n",
    "#         cls_predictions = y_pred[:, :, 4:]\n",
    "\n",
    "#         positive_mask = tf.cast(tf.math.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
    "#         ignore_mask = tf.cast(tf.math.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
    "\n",
    "#         cls_loss = self._cls_loss(cls_labels, cls_predictions)\n",
    "#         box_loss = self._box_loss(box_labels, box_predictions)\n",
    "\n",
    "#         cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n",
    "#         box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
    "\n",
    "#         normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
    "#         cls_loss = tf.math.divide_no_nan(tf.reduce_sum(cls_loss, axis=-1), normalizer)\n",
    "#         box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
    "        \n",
    "#         loss = cls_loss + box_loss\n",
    "#         return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class MeanAveragePrecision(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, anchors, iou_threshold=0.5, **kwargs):\n",
    "        super(MeanAveragePrecision, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros', shape=(num_classes,))\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            true_boxes = y_true[:, :, i * 4:(i + 1) * 4]\n",
    "            pred_offsets = y_pred[:, :, i * 4:(i + 1) * 4]\n",
    "            \n",
    "            pred_boxes = self.decode_predictions(pred_offsets, self.anchors)\n",
    "\n",
    "            iou = self.calculate_iou(true_boxes, pred_boxes)\n",
    "            mask = tf.expand_dims(tf.greater_equal(iou, self.iou_threshold), -1)\n",
    "\n",
    "            true_positives = tf.reduce_sum(tf.cast(mask, tf.float32))\n",
    "            false_positives = tf.reduce_sum(tf.cast(tf.logical_and(tf.logical_not(mask), tf.greater(pred_boxes, 0)), tf.float32))\n",
    "            false_negatives = tf.reduce_sum(tf.cast(tf.logical_and(tf.logical_not(mask), tf.greater(true_boxes, 0)), tf.float32))\n",
    "\n",
    "            self.true_positives.assign(tf.tensor_scatter_nd_add(self.true_positives, [[i]], [true_positives]))\n",
    "            self.false_positives.assign(tf.tensor_scatter_nd_add(self.false_positives, [[i]], [false_positives]))\n",
    "            self.false_negatives.assign(tf.tensor_scatter_nd_add(self.false_negatives, [[i]], [false_negatives]))\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def decode_predictions(self, labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "        def decode_fn(labels, anchors):\n",
    "            decoded_boxes = []\n",
    "            label_idx = 0\n",
    "            for label in labels:\n",
    "                dx, dy, dw, dh = label[:4]\n",
    "                anchor = anchors[label_idx]\n",
    "                anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "                cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "                cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "                width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "                height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "                x_min = cx - width / 2\n",
    "                y_min = cy - height / 2\n",
    "                decoded_box = [x_min, y_min, width, height]\n",
    "                if label[4] == 1.0:\n",
    "                    decoded_boxes.append(decoded_box)\n",
    "                label_idx += 1\n",
    "            return np.array(decoded_boxes)\n",
    "    \n",
    "        decoded_boxes = tf.numpy_function(decode_fn, [labels, anchors], tf.float32)\n",
    "        return decoded_boxes\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        precision = tf.math.divide_no_nan(self.true_positives, self.true_positives + self.false_positives)\n",
    "        recall = tf.math.divide_no_nan(self.true_positives, self.true_positives + self.false_negatives)\n",
    "        average_precision = tf.reduce_mean(precision)\n",
    "        return average_precision\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(tf.zeros_like(self.true_positives))\n",
    "        self.false_positives.assign(tf.zeros_like(self.false_positives))\n",
    "        self.false_negatives.assign(tf.zeros_like(self.false_negatives))\n",
    "\n",
    "    def calculate_iou(self, true_boxes, pred_boxes):\n",
    "        true_boxes = tf.reshape(true_boxes, [-1, 4])\n",
    "        pred_boxes = tf.reshape(pred_boxes, [-1, 4])\n",
    "\n",
    "        x1 = tf.maximum(true_boxes[:, 0], pred_boxes[:, 0])\n",
    "        y1 = tf.maximum(true_boxes[:, 1], pred_boxes[:, 1])\n",
    "        x2 = tf.minimum(true_boxes[:, 2], pred_boxes[:, 2])\n",
    "        y2 = tf.minimum(true_boxes[:, 3], pred_boxes[:, 3])\n",
    "\n",
    "        intersection_area = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        true_area = (true_boxes[:, 2] - true_boxes[:, 0]) * (true_boxes[:, 3] - true_boxes[:, 1])\n",
    "        pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])\n",
    "        union_area = true_area + pred_area - intersection_area\n",
    "\n",
    "        iou = intersection_area / (union_area + tf.keras.backend.epsilon())\n",
    "        return iou\n",
    "\n",
    "\n",
    "class IntersectionOverUnion(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, anchors, **kwargs):\n",
    "        super(IntersectionOverUnion, self).__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.intersection_over_union = self.add_weight(name='iou', initializer='zeros', shape=(num_classes,))\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            true_boxes = y_true[:, :, i * 4:(i + 1) * 4]\n",
    "            pred_offsets = y_pred[:, :, i * 4:(i + 1) * 4]\n",
    "            \n",
    "            pred_boxes = self.decode_predictions(pred_offsets, self.anchors)\n",
    "\n",
    "            iou = self.calculate_iou(true_boxes, pred_boxes)\n",
    "            self.intersection_over_union[i].assign(tf.reduce_mean(iou))\n",
    "\n",
    "    def decode_predictions(self, labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "        labels = tf.reshape(labels, [-1, 5])  # labels의 모양을 (num_boxes, 5)로 변경\n",
    "        offsets = labels[:, :4]  # 오프셋 추출\n",
    "        class_labels = labels[:, 4:]  # 클래스 레이블 추출\n",
    "    \n",
    "        anchor_x = anchors[:, 0]\n",
    "        anchor_y = anchors[:, 1]\n",
    "        anchor_w = anchors[:, 2]\n",
    "        anchor_h = anchors[:, 3]\n",
    "    \n",
    "        cx = offsets[:, 0] * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = offsets[:, 1] * box_variance[1] * anchor_h + anchor_y\n",
    "        width = tf.exp(offsets[:, 2] * box_variance[2]) * anchor_w\n",
    "        height = tf.exp(offsets[:, 3] * box_variance[3]) * anchor_h\n",
    "    \n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "    \n",
    "        decoded_boxes = tf.stack([x_min, y_min, width, height], axis=-1)\n",
    "        positive_mask = tf.cast(tf.equal(class_labels, 1.0), tf.bool)\n",
    "        decoded_boxes = tf.boolean_mask(decoded_boxes, positive_mask)\n",
    "    \n",
    "        return decoded_boxes\n",
    "\n",
    "    def result(self):\n",
    "        return self.intersection_over_union\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.intersection_over_union.assign(tf.zeros_like(self.intersection_over_union))\n",
    "\n",
    "    def calculate_iou(self, true_boxes, pred_boxes):\n",
    "        true_boxes = tf.reshape(true_boxes, [-1, 4])\n",
    "        pred_boxes = tf.reshape(pred_boxes, [-1, 4])\n",
    "\n",
    "        x1 = tf.maximum(true_boxes[:, 0], pred_boxes[:, 0])\n",
    "        y1 = tf.maximum(true_boxes[:, 1], pred_boxes[:, 1])\n",
    "        x2 = tf.minimum(true_boxes[:, 2], pred_boxes[:, 2])\n",
    "        y2 = tf.minimum(true_boxes[:, 3], pred_boxes[:, 3])\n",
    "\n",
    "        intersection_area = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
    "        true_area = (true_boxes[:, 2] - true_boxes[:, 0]) * (true_boxes[:, 3] - true_boxes[:, 1])\n",
    "        pred_area = (pred_boxes[:, 2] - pred_boxes[:, 0]) * (pred_boxes[:, 3] - pred_boxes[:, 1])\n",
    "        union_area = true_area + pred_area - intersection_area\n",
    "\n",
    "        iou = intersection_area / (union_area + tf.keras.backend.epsilon())\n",
    "        return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_learning_rate = 0.0002\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=initial_learning_rate,\n",
    "#     decay_steps=1000,\n",
    "#     decay_rate=0.96,\n",
    "#     staircase=True)\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 10\n",
    "decay_rate = 0.96\n",
    "staircase = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return initial_learning_rate * (decay_rate ** (epoch // decay_steps))\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "model = CustomModel(num_classes)\n",
    "loss_fn = Loss(num_classes = 1)\n",
    "# optimizer = tf.optimizers.Adam(learning_rate = lr_schedule)\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)\n",
    "\n",
    "# map_metric = MeanAveragePrecision(num_classes=num_classes, anchors=anchors)\n",
    "# iou_metric = IntersectionOverUnion(num_classes=num_classes, anchors=anchors)\n",
    "\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)\n",
    "# iou_metric = MultiBoxIoUMetric(anchors=anchors)\n",
    "# 모델 컴파일\n",
    "# model.compile(optimizer=optimizer, \n",
    "#               loss=[loss_fn],\n",
    "#               metrics=['accuracy', iou_metric])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss=[loss_fn],\n",
    "              metrics=[Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가정: train_dataset은 이미 tf.data.Dataset 객체로 생성되어 있음\n",
    "new_batch_size = 9\n",
    "\n",
    "# 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "train_dataset = train_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "train_dataset = train_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")\n",
    "    # print(\"labels[:, :, :4]: \", labels[:, :, :4])\n",
    "    print(\"Labels shape:\", labels[:, :, :4].shape)\n",
    "    # print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "model.fit(\n",
    "    # image, label,\n",
    "    train_dataset,\n",
    "    # batch_size= 12,\n",
    "    epochs=epochs,\n",
    "    callbacks=lr_callback,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, label in val_dataset.take(10):\n",
    "#     # predictions = inference_model.predict(tf.expand_dims(img[0], axis=0))  # img에 첫 번째 차원을 추가\n",
    "#     predictions = model.predict(tf.expand_dims(img[0], axis=0))  # img에 첫 번째 차원을 추가\n",
    "#     print(predictions[0, :10, :])\n",
    "#     # positive_count = tf.reduce_sum(tf.cast(tf.equal(predictions[:, :, 4], 1.0), tf.int32))\n",
    "#     positive_count = tf.reduce_sum(tf.cast(tf.greater(predictions[:, :, 4], -1.0), tf.int32))\n",
    "#     # ignore_count = tf.reduce_sum(tf.cast(tf.less(predictions[:, :, 4], -2.0), tf.int32))\n",
    "\n",
    "#     print(\"Positive 개수:\", positive_count.numpy())\n",
    "#     # print(\"Negative 개수:\", negative_count.numpy())\n",
    "#     # print(\"Ignore 개수:\", ignore_count.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # decode_predictions 함수 정의\n",
    "# def decode_predictions(labels, anchors, box_variance=[0.1, 0.1, 0.2, 0.2]):\n",
    "#     decoded_boxes = []\n",
    "#     for label_idx, label in enumerate(labels):\n",
    "#         if label[4] > -1.0:  # 양성 레이블 조건 확인\n",
    "#             dx, dy, dw, dh = label[:4]\n",
    "#             anchor = anchors[label_idx]\n",
    "#             anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "#             cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "#             cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "#             width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "#             height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "#             x_min = cx - width / 2\n",
    "#             y_min = cy - height / 2\n",
    "#             decoded_box = [x_min, y_min, width, height]\n",
    "#             decoded_boxes.append(decoded_box)\n",
    "#     return decoded_boxes\n",
    "\n",
    "# # draw_positive_bounding_boxes 함수 정의\n",
    "# def draw_positive_bounding_boxes(image, decoded_boxes):\n",
    "#     plt.imshow(image)\n",
    "#     ax = plt.gca()\n",
    "#     for box in decoded_boxes:\n",
    "#         x_min, y_min, width, height = box\n",
    "#         rect = patches.Rectangle((x_min, y_min), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#     plt.show()\n",
    "\n",
    "# # 앵커 박스 및 디코딩 로직 사용 예시\n",
    "# # 주의: AnchorBox 클래스의 구현과 train_dataset의 정의가 필요합니다.\n",
    "\n",
    "# # 예를 들어, 앵커 박스 생성 및 train_dataset에서의 사용 예제는 다음과 같습니다:\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시, 실제 사용 시에는 해당 구현에 맞게 조정 필요\n",
    "\n",
    "# for batch in train_dataset.take(1):\n",
    "#     image = batch[0][0].numpy()\n",
    "#     labels = batch[1][0].numpy()\n",
    "#     decoded_boxes = decode_predictions(labels, anchors)\n",
    "#     draw_positive_bounding_boxes(image, decoded_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가정: train_dataset은 이미 tf.data.Dataset 객체로 생성되어 있음\n",
    "# new_batch_size = 9\n",
    "\n",
    "# # 기존 데이터셋에서 배치 사이즈를 새로운 값으로 변경\n",
    "# val_dataset = val_dataset.unbatch()  # 먼저, 기존 배치를 해제\n",
    "# val_dataset = val_dataset.batch(new_batch_size, drop_remainder=True)  # 새로운 배치 사이즈로 재배치\n",
    "\n",
    "# 배치 사이즈 변경 후 데이터셋을 확인하기 위한 코드\n",
    "for images, _, _ in val_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Images max: {tf.reduce_max(images)}\")\n",
    "    print(f\"Images min: {tf.reduce_min(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "\n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "\n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.7, top_n=100):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "\n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "\n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "\n",
    "    # NMS 적용\n",
    "    while scores:\n",
    "        score, i = scores.pop(0)\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height, score]\n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box[:4], other_box[:4]) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "\n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, class_names):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')  # 이미지가 grayscale인 경우 cmap='gray'를 추가합니다.\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max, score = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # 박스 위에 클래스 이름과 확률 표시\n",
    "        class_name = class_names[0]  # 예시로 'person' 클래스를 사용합니다.\n",
    "        text = f'{class_name}: {score:.2f}'\n",
    "        ax.text(x_min, y_min, text, fontsize=10, bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "class_names = ['person']  # 클래스 이름 리스트\n",
    "\n",
    "for img, _, _ in val_dataset.take(30):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, class_names)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def iou(box1, box2):\n",
    "#     x1, y1, x2, y2 = box1\n",
    "#     x3, y3, x4, y4 = box2\n",
    "    \n",
    "#     x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "#     y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    \n",
    "#     intersection = x_overlap * y_overlap\n",
    "#     area1 = (x2 - x1) * (y2 - y1)\n",
    "#     area2 = (x4 - x3) * (y4 - y3)\n",
    "#     union = area1 + area2 - intersection\n",
    "    \n",
    "#     return intersection / union\n",
    "\n",
    "# def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.9, top_n=9000):\n",
    "#     decoded_boxes = []\n",
    "#     scores = []\n",
    "    \n",
    "#     for i, prediction in enumerate(predictions):\n",
    "#         score = prediction[-1]\n",
    "#         if score > score_threshold:\n",
    "#             scores.append((score, i))\n",
    "    \n",
    "#     # 점수에 따라 내림차순 정렬\n",
    "#     scores.sort(reverse=True)\n",
    "    \n",
    "#     # 상위 N개 선택\n",
    "#     scores = scores[:top_n]\n",
    "    \n",
    "#     # NMS 적용\n",
    "#     for score, i in scores:\n",
    "#         prediction = predictions[i]\n",
    "#         dx, dy, dw, dh = prediction[:4]\n",
    "#         anchor = anchors[i]\n",
    "#         anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        \n",
    "#         cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "#         cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "#         width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "#         height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        \n",
    "#         x_min = cx - width / 2\n",
    "#         y_min = cy - height / 2\n",
    "#         decoded_box = [x_min, y_min, x_min + width, y_min + height]\n",
    "        \n",
    "#         keep = True\n",
    "#         for other_box in decoded_boxes:\n",
    "#             if iou(decoded_box, other_box) >= iou_threshold:\n",
    "#                 keep = False\n",
    "#                 break\n",
    "        \n",
    "#         if keep:\n",
    "#             decoded_boxes.append(decoded_box)\n",
    "    \n",
    "#     return decoded_boxes\n",
    "\n",
    "# def draw_bounding_boxes(image, boxes):\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "#     plt.imshow(image)\n",
    "#     ax = plt.gca()\n",
    "#     for box in boxes:\n",
    "#         x_min, y_min, x_max, y_max = box\n",
    "#         rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "#         ax.add_patch(rect)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "# # AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "\n",
    "# anchor_box = AnchorBox()\n",
    "# anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "# for img, _, _ in val_dataset:    \n",
    "#     predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "#     decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "#     draw_bounding_boxes(img[0].numpy(), decoded_boxes)  # 디코딩된 바운딩 박스를 이미지에 그리기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    \n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    \n",
    "    intersection = x_overlap * y_overlap\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "def decode_predictions(predictions, anchors, box_variance=[0.1, 0.1, 0.2, 0.2], iou_threshold=0.5, score_threshold=0.9, top_n=9000):\n",
    "    decoded_boxes = []\n",
    "    scores = []\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        score = prediction[-1]\n",
    "        if score > score_threshold:\n",
    "            scores.append((score, i))\n",
    "    \n",
    "    # 점수에 따라 내림차순 정렬\n",
    "    scores.sort(reverse=True)\n",
    "    \n",
    "    # 상위 N개 선택\n",
    "    scores = scores[:top_n]\n",
    "    \n",
    "    # NMS 적용\n",
    "    for score, i in scores:\n",
    "        prediction = predictions[i]\n",
    "        dx, dy, dw, dh = prediction[:4]\n",
    "        anchor = anchors[i]\n",
    "        anchor_x, anchor_y, anchor_w, anchor_h = anchor\n",
    "        \n",
    "        cx = dx * box_variance[0] * anchor_w + anchor_x\n",
    "        cy = dy * box_variance[1] * anchor_h + anchor_y\n",
    "        width = np.exp(dw * box_variance[2]) * anchor_w\n",
    "        height = np.exp(dh * box_variance[3]) * anchor_h\n",
    "        \n",
    "        x_min = cx - width / 2\n",
    "        y_min = cy - height / 2\n",
    "        decoded_box = [x_min, y_min, x_min + width, y_min + height]\n",
    "        \n",
    "        keep = True\n",
    "        for other_box in decoded_boxes:\n",
    "            if iou(decoded_box, other_box) >= iou_threshold:\n",
    "                keep = False\n",
    "                break\n",
    "        \n",
    "        if keep:\n",
    "            decoded_boxes.append(decoded_box)\n",
    "    \n",
    "    return decoded_boxes\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, save_path=None):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# AnchorBox 클래스와 get_anchors 함수가 필요합니다.\n",
    "\n",
    "anchor_box = AnchorBox()\n",
    "anchors = anchor_box.get_anchors(24, 32)  # 앵커 박스 생성 예시\n",
    "\n",
    "for i, (img, _, _) in enumerate(val_dataset):    \n",
    "    predictions = model.predict(tf.expand_dims(img[0], axis=0))[0]  # 첫 번째 이미지에 대한 예측 결과\n",
    "    decoded_boxes = decode_predictions(predictions, anchors)  # 예측된 바운딩 박스 디코딩\n",
    "    save_path = f\"prediction_img/output_{i}.png\"  # 이미지 저장 경로 지정\n",
    "    draw_bounding_boxes(img[0].numpy(), decoded_boxes, save_path=save_path)  # 디코딩된 바운딩 박스를 이미지에 그리고 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
