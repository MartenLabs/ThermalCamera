{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV3 -> SSD -> GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from skimage import color\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "from IPython.display import Image\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13276, 24, 32)\n",
      "(13276, 24, 32)\n",
      "(13276,)\n",
      "(13276, 4, 8)\n"
     ]
    }
   ],
   "source": [
    "dataset1_origin = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset1_origin.npz', allow_pickle=True)\n",
    "dataset1_horizon = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset1_horizon.npz', allow_pickle=True)\n",
    "dataset1_vertical = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset1_vertical.npz', allow_pickle=True)\n",
    "dataset1_vh = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset1_vh.npz', allow_pickle=True)\n",
    "dataset2_origin = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset2_origin.npz', allow_pickle=True)\n",
    "dataset2_horizon = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset2_horizon.npz', allow_pickle=True)\n",
    "dataset2_vertical = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset2_vertical.npz', allow_pickle=True)\n",
    "dataset2_vh = np.load('/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/npz/dataset2_vh.npz', allow_pickle=True)\n",
    "\n",
    "d1o_origin_images, d1o_target_images, d1o_number_labels, d1o_coordinates = dataset1_origin['images'], dataset1_origin['filters'], dataset1_origin['numbers'],  dataset1_origin['coordinates']\n",
    "d1h_origin_images, d1h_target_images, d1h_number_labels, d1h_coordinates = dataset1_horizon['images'], dataset1_horizon['filters'], dataset1_horizon['numbers'],  dataset1_horizon['coordinates']\n",
    "d1v_origin_images, d1v_target_images, d1v_number_labels, d1v_coordinates = dataset1_vertical['images'], dataset1_vertical['filters'], dataset1_vertical['numbers'],  dataset1_vertical['coordinates']\n",
    "d1vh_origin_images, d1vh_target_images, d1vh_number_labels, d1vh_coordinates = dataset1_vh['images'], dataset1_vh['filters'], dataset1_vh['numbers'],  dataset1_vh['coordinates']\n",
    "d2o_origin_images, d2o_target_images, d2o_number_labels, d2o_coordinates = dataset2_origin['images'], dataset2_origin['filters'], dataset2_origin['numbers'],  dataset2_origin['coordinates']\n",
    "d2h_origin_images, d2h_target_images, d2h_number_labels, d2h_coordinates = dataset2_horizon['images'], dataset2_horizon['filters'], dataset2_horizon['numbers'],  dataset2_horizon['coordinates']\n",
    "d2v_origin_images, d2v_target_images, d2v_number_labels, d2v_coordinates = dataset2_vertical['images'], dataset2_vertical['filters'], dataset2_vertical['numbers'],  dataset2_vertical['coordinates']\n",
    "d2vh_origin_images, d2vh_target_images, d2vh_number_labels, d2vh_coordinates = dataset2_vh['images'], dataset2_vh['filters'], dataset2_vh['numbers'],  dataset2_vh['coordinates']\n",
    "\n",
    "origin_images = np.concatenate([d1o_origin_images, d2o_origin_images, d1h_origin_images, d2h_origin_images, d1v_origin_images, d2v_origin_images, d1vh_origin_images, d2vh_origin_images], axis = 0)\n",
    "target_images = np.concatenate([d1o_target_images, d2o_target_images, d1h_target_images, d2h_target_images, d1v_target_images, d2v_target_images, d1vh_target_images, d2vh_target_images], axis = 0)\n",
    "numbers_labels = np.concatenate([d1o_number_labels, d2o_number_labels, d1h_number_labels, d2h_number_labels, d1v_number_labels, d2v_number_labels, d1vh_number_labels, d2vh_number_labels], axis = 0)\n",
    "coordinates = np.concatenate([d1o_coordinates, d2o_coordinates, d1h_coordinates, d2h_coordinates, d1v_coordinates, d2v_coordinates, d1vh_coordinates, d2vh_coordinates], axis = 0)\n",
    "\n",
    "print(origin_images.shape)\n",
    "print(target_images.shape)\n",
    "print(numbers_labels.shape)\n",
    "print(coordinates.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13276, 24, 32, 1)\n",
      "(13276, 24, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "origin_images = origin_images.reshape(13276, 24, 32, 1)\n",
    "target_images = target_images.reshape(13276, 24, 32, 1)\n",
    "print(origin_images.shape)\n",
    "print(target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 0\n",
      "255 0\n",
      "1.0 0.0\n",
      "1.0 0.0\n",
      "(13276, 24, 32, 1)\n",
      "(13276, 24, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(origin_images.max(), origin_images.min())\n",
    "print(target_images.max(), target_images.min())\n",
    "\n",
    "origin_images = origin_images / origin_images.max()\n",
    "target_images = target_images / target_images.max()\n",
    "\n",
    "print(origin_images.max(), origin_images.min())\n",
    "print(target_images.max(), target_images.min())\n",
    "\n",
    "print(origin_images.shape)\n",
    "print(target_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(coords, width=32, height=24):\n",
    "    # Check the shape of the input coordinates\n",
    "    if coords.shape[-1] != 8:\n",
    "        raise ValueError(\"The last dimension of the input coordinates should be 8.\")\n",
    "\n",
    "    # Create a normalization array\n",
    "    normalization_factors = np.array([width, height, width, height, width, height, width, height])\n",
    "\n",
    "    # Normalize the coordinates\n",
    "    normalized_coords = coords / normalization_factors\n",
    "\n",
    "    return normalized_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13276, 4, 8)\n",
      "(13276, 5)\n"
     ]
    }
   ],
   "source": [
    "norm_location = normalize_coordinates(coordinates)\n",
    "print(norm_location.shape)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "number_labels = to_categorical(numbers_labels, num_classes=5)\n",
    "print(number_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data_list = []\n",
    "\n",
    "for i in range(norm_location.shape[0]):\n",
    "    xmin = norm_location[i, :, 0::2].min(axis=1)\n",
    "    ymin = norm_location[i, :, 1::2].min(axis=1)\n",
    "    xmax = norm_location[i, :, 0::2].max(axis=1)\n",
    "    ymax = norm_location[i, :, 1::2].max(axis=1)\n",
    "    bounding_box = np.array([xmin, ymin, xmax, ymax]).T.reshape(1, -1)\n",
    "    transformed_data_list.append(bounding_box)\n",
    "\n",
    "norm_location = np.array(transformed_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25       0.625      0.46875    1.         0.         0.\n",
      "  0.25       0.33333333 0.46875    0.54166667 0.71875    0.95833333\n",
      "  0.8125     0.66666667 1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(norm_location[9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_boxes_on_normalized_coords(image, normalized_coords, width=32, height=24):\n",
    "    \"\"\"\n",
    "    정규화된 좌표를 사용하여 이미지 위에 바운딩 박스를 그리는 함수.\n",
    "    image: 대상 이미지.\n",
    "    normalized_coords: 정규화된 좌표.\n",
    "    width: 이미지의 너비.\n",
    "    height: 이미지의 높이.\n",
    "    \"\"\"\n",
    "    # Remove the first dimension from normalized_coords\n",
    "    normalized_coords = normalized_coords.squeeze()\n",
    "\n",
    "    # Denormalize the coordinates\n",
    "    denormalization_factors = np.tile([width, height], 8)  # 형태를 (16,)으로 조정\n",
    "    denormalized_coords = normalized_coords * denormalization_factors\n",
    "\n",
    "    # 이미지가 4차원 배열인 경우 첫 번째 이미지만 사용\n",
    "    if image.ndim == 4:\n",
    "        image = image[0]\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    # Loop over each set of coordinates and draw the bounding box\n",
    "    for i in range(0, len(denormalized_coords), 4):\n",
    "        xmin, ymin, xmax, ymax = denormalized_coords[i:i+4]\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        \n",
    "        # Add the patch to the axis\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_boxes_on_normalized_coords(origin_images[9000:9001], norm_location[9000:9001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)       [(None, None, None, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 320, 240, 1)          0         ['input_29[0][0]']            \n",
      "                                                                                                  \n",
      " MobilenetV3small (Function  (None, 10, 8, 576)           938832    ['lambda_2[0][0]']            \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)          (None, 10, 8, 512)           2654720   ['MobilenetV3small[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)          (None, 5, 4, 256)            1179904   ['conv2d_88[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)          (None, 3, 2, 128)            295040    ['conv2d_89[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)          (None, 10, 8, 16)            73744     ['conv2d_88[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)          (None, 5, 4, 16)             36880     ['conv2d_89[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)          (None, 3, 2, 16)             18448     ['conv2d_90[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3  (None, 16)                   0         ['conv2d_91[0][0]']           \n",
      " 0 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3  (None, 16)                   0         ['conv2d_92[0][0]']           \n",
      " 1 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3  (None, 16)                   0         ['conv2d_93[0][0]']           \n",
      " 2 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenat  (None, 48)                   0         ['global_average_pooling2d_30[\n",
      " e)                                                                 0][0]',                       \n",
      "                                                                     'global_average_pooling2d_31[\n",
      "                                                                    0][0]',                       \n",
      "                                                                     'global_average_pooling2d_32[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " reshape_14 (Reshape)        (None, 1, 48)                0         ['concatenate_14[0][0]']      \n",
      "                                                                                                  \n",
      " gru_10 (GRU)                (None, 128)                  68352     ['reshape_14[0][0]']          \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 16)                   2064      ['gru_10[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5267984 (20.10 MB)\n",
      "Trainable params: 5255872 (20.05 MB)\n",
      "Non-trainable params: 12112 (47.31 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Reshape, GRU, TimeDistributed, Flatten, Dense, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# def add_ssd_layers(base_model_output):\n",
    "#     # 여러 SSD 레이어 추가\n",
    "#     x1 = Conv2D(512, (3, 3), activation='relu', padding='same')(base_model_output)\n",
    "#     x2 = Conv2D(256, (3, 3), activation='relu', padding='same', strides=(2, 2))(x1)\n",
    "#     x3 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(x2)\n",
    "\n",
    "#     # 각 레이어에서 바운딩 박스 예측\n",
    "#     detections1 = Conv2D(4 * 4, (3, 3), padding='same')(x1)  # 4개 바운딩 박스 오프셋\n",
    "#     detections2 = Conv2D(4 * 4, (3, 3), padding='same')(x2)\n",
    "#     detections3 = Conv2D(4 * 4, (3, 3), padding='same')(x3)\n",
    "\n",
    "#     # 각 레이어의 출력을 플래튼하고 하나로 결합\n",
    "#     flattened1 = Flatten()(detections1)\n",
    "#     flattened2 = Flatten()(detections2)\n",
    "#     flattened3 = Flatten()(detections3)\n",
    "#     combined_detections = tf.keras.layers.Concatenate(axis=-1)([flattened1, flattened2, flattened3])\n",
    "\n",
    "#     return combined_detections\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "def add_ssd_layers(base_model_output):\n",
    "    # 여러 SSD 레이어 추가\n",
    "    x1 = Conv2D(512, (3, 3), activation='relu', padding='same')(base_model_output)\n",
    "    x2 = Conv2D(256, (3, 3), activation='relu', padding='same', strides=(2, 2))(x1)\n",
    "    x3 = Conv2D(128, (3, 3), activation='relu', padding='same', strides=(2, 2))(x2)\n",
    "\n",
    "    # 각 레이어에서 바운딩 박스 예측\n",
    "    detections1 = Conv2D(4 * 4, (3, 3), padding='same')(x1)\n",
    "    detections2 = Conv2D(4 * 4, (3, 3), padding='same')(x2)\n",
    "    detections3 = Conv2D(4 * 4, (3, 3), padding='same')(x3)\n",
    "\n",
    "    # 각 레이어의 출력을 전역 평균 풀링을 통해 처리\n",
    "    pooled1 = Flatten()(detections1)\n",
    "    pooled2 = Flatten()(detections2)\n",
    "    pooled3 = Flatten()(detections3)\n",
    "    combined_detections = tf.keras.layers.Concatenate(axis=-1)([pooled1, pooled2, pooled3])\n",
    "\n",
    "    return combined_detections\n",
    "\n",
    "def resize_images(image):\n",
    "    # TensorFlow 함수를 사용하여 이미지 크기 조정\n",
    "    return tf.image.resize(image, [320, 240])\n",
    "\n",
    "def Main():\n",
    "    input_layer = tf.keras.Input(shape=(None, None, 1))\n",
    "\n",
    "    resized_input = Lambda(resize_images)(input_layer)\n",
    "    \n",
    "    # 기능 추출을 위한 기본 모델 정의\n",
    "    base_model = tf.keras.applications.MobileNetV3Small(include_top=False, weights=None, input_shape=(320, 240, 1))\n",
    "\n",
    "    mobile_net_output = base_model(resized_input)\n",
    "\n",
    "    processed_detections = add_ssd_layers(mobile_net_output)\n",
    "    reshaped_detections = Reshape((1, -1))(processed_detections)\n",
    "    \n",
    "    # GRU 레이어 추가\n",
    "    gru_output = GRU(128, return_sequences=False)(reshaped_detections)\n",
    "\n",
    "    # 최종 탐지 레이어\n",
    "    final_detections = Dense(4 * 4, activation='sigmoid')(gru_output)  # 이미지 당 최대 4개 바운딩 박스 예측\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Model(inputs=input_layer, outputs=final_detections)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = Main()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def smooth_l1_loss(y_true, y_pred, delta=1.0):\n",
    "    abs_diff = tf.abs(y_true - y_pred)\n",
    "    loss = tf.where(tf.less(abs_diff, delta), 0.5 * tf.square(abs_diff), delta * (abs_diff - 0.5 * delta))\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    TensorFlow를 사용하여 IoU를 계산하는 함수.\n",
    "    y_true: 실제 바운딩 박스 좌표, 형태는 [batch, num_boxes, 4] (여기서 4는 xmin, ymin, xmax, ymax)\n",
    "    y_pred: 예측된 바운딩 박스 좌표, 형태는 [batch, num_boxes, 4]\n",
    "    \"\"\"\n",
    "    # 좌표를 분리\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    true_xmin, true_ymin, true_xmax, true_ymax = tf.split(y_true, 4, axis=-1)\n",
    "    pred_xmin, pred_ymin, pred_xmax, pred_ymax = tf.split(y_pred, 4, axis=-1)\n",
    "\n",
    "    # 교차 영역의 좌표 계산\n",
    "    intersect_xmin = tf.maximum(true_xmin, pred_xmin)\n",
    "    intersect_ymin = tf.maximum(true_ymin, pred_ymin)\n",
    "    intersect_xmax = tf.minimum(true_xmax, pred_xmax)\n",
    "    intersect_ymax = tf.minimum(true_ymax, pred_ymax)\n",
    "\n",
    "    # 교차 영역의 넓이와 높이\n",
    "    intersect_width = tf.maximum(0., intersect_xmax - intersect_xmin)\n",
    "    intersect_height = tf.maximum(0., intersect_ymax - intersect_ymin)\n",
    "\n",
    "    # 교차 영역의 면적\n",
    "    intersect_area = intersect_width * intersect_height\n",
    "\n",
    "    # 각 바운딩 박스의 면적\n",
    "    true_area = (true_xmax - true_xmin) * (true_ymax - true_ymin)\n",
    "    pred_area = (pred_xmax - pred_xmin) * (pred_ymax - pred_ymin)\n",
    "\n",
    "    # 합집합 영역의 면적\n",
    "    union_area = true_area + pred_area - intersect_area\n",
    "\n",
    "    # IoU 계산\n",
    "    iou = intersect_area / tf.maximum(union_area, tf.keras.backend.epsilon())\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "N_TRAIN = 13276\n",
    "N_BATCH = 32\n",
    "N_EPOCHS = 100\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
    "                                                          decay_steps = N_TRAIN / N_BATCH * 10,\n",
    "                                                          decay_rate = 0.5,\n",
    "                                                          staircase = True)\n",
    "\n",
    "model.compile(\n",
    "    keras.optimizers.ADAM(lr_schedule), \n",
    "    loss = smooth_l1_loss,\n",
    "    metrics=[iou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb 셀 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     origin_images, norm_location, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m N_BATCH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,  \u001b[39m# 사용자 정의 콜백 추가\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    origin_images, norm_location, \n",
    "    epochs=100,\n",
    "    batch_size= N_BATCH,\n",
    "    verbose=1,  # 사용자 정의 콜백 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
