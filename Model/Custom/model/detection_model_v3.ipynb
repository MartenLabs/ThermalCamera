{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetV3 -> SSD -> GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 22:21:44.284141: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-11-12 22:21:44.284167: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-11-12 22:21:44.284172: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-11-12 22:21:44.284257: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-12 22:21:44.284470: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' Conv/kernel:0': Shape mismatch.The variable shape (3, 3, 1, 16), and the assigned value shape (16, 3, 3, 3) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb ì…€ 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Define the base model for feature extraction\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m base_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mapplications\u001b[39m.\u001b[39;49mMobileNetV3Small(include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m300\u001b[39;49m, \u001b[39m300\u001b[39;49m, \u001b[39m1\u001b[39;49m))  \u001b[39m# Grayscale input\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Add SSD layers for detection on top of the base model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_ssd_layers\u001b[39m(base_model_output):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Assume x is the output of the base model. Add additional layers for SSD here.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/Custom/model/detection_model_v3.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# For simplicity, only one additional layer is added here. You can add more layers as required.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/api/lib/python3.8/site-packages/keras/src/applications/mobilenet_v3.py:468\u001b[0m, in \u001b[0;36mMobileNetV3Small\u001b[0;34m(input_shape, alpha, minimalistic, include_top, weights, input_tensor, classes, pooling, dropout_rate, classifier_activation, include_preprocessing)\u001b[0m\n\u001b[1;32m    463\u001b[0m     x \u001b[39m=\u001b[39m _inverted_res_block(\n\u001b[1;32m    464\u001b[0m         x, \u001b[39m6\u001b[39m, depth(\u001b[39m96\u001b[39m), kernel, \u001b[39m1\u001b[39m, se_ratio, activation, \u001b[39m10\u001b[39m\n\u001b[1;32m    465\u001b[0m     )\n\u001b[1;32m    466\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m--> 468\u001b[0m \u001b[39mreturn\u001b[39;00m MobileNetV3(\n\u001b[1;32m    469\u001b[0m     stack_fn,\n\u001b[1;32m    470\u001b[0m     \u001b[39m1024\u001b[39;49m,\n\u001b[1;32m    471\u001b[0m     input_shape,\n\u001b[1;32m    472\u001b[0m     alpha,\n\u001b[1;32m    473\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39msmall\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    474\u001b[0m     minimalistic,\n\u001b[1;32m    475\u001b[0m     include_top,\n\u001b[1;32m    476\u001b[0m     weights,\n\u001b[1;32m    477\u001b[0m     input_tensor,\n\u001b[1;32m    478\u001b[0m     classes,\n\u001b[1;32m    479\u001b[0m     pooling,\n\u001b[1;32m    480\u001b[0m     dropout_rate,\n\u001b[1;32m    481\u001b[0m     classifier_activation,\n\u001b[1;32m    482\u001b[0m     include_preprocessing,\n\u001b[1;32m    483\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/api/lib/python3.8/site-packages/keras/src/applications/mobilenet_v3.py:414\u001b[0m, in \u001b[0;36mMobileNetV3\u001b[0;34m(stack_fn, last_point_ch, input_shape, alpha, model_type, minimalistic, include_top, weights, input_tensor, classes, pooling, dropout_rate, classifier_activation, include_preprocessing)\u001b[0m\n\u001b[1;32m    407\u001b[0m         file_hash \u001b[39m=\u001b[39m WEIGHTS_HASHES[model_name][\u001b[39m1\u001b[39m]\n\u001b[1;32m    408\u001b[0m     weights_path \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39mget_file(\n\u001b[1;32m    409\u001b[0m         file_name,\n\u001b[1;32m    410\u001b[0m         BASE_WEIGHT_PATH \u001b[39m+\u001b[39m file_name,\n\u001b[1;32m    411\u001b[0m         cache_subdir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m         file_hash\u001b[39m=\u001b[39mfile_hash,\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     model\u001b[39m.\u001b[39;49mload_weights(weights_path)\n\u001b[1;32m    415\u001b[0m \u001b[39melif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     model\u001b[39m.\u001b[39mload_weights(weights)\n",
      "File \u001b[0;32m~/anaconda3/envs/api/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/api/lib/python3.8/site-packages/keras/src/backend.py:4361\u001b[0m, in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4358\u001b[0m     variable\u001b[39m.\u001b[39massign(d_value)\n\u001b[1;32m   4359\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4360\u001b[0m     \u001b[39m# For the normal tf.Variable assign\u001b[39;00m\n\u001b[0;32m-> 4361\u001b[0m     variable\u001b[39m.\u001b[39;49massign(value)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign value to variable ' Conv/kernel:0': Shape mismatch.The variable shape (3, 3, 1, 16), and the assigned value shape (16, 3, 3, 3) are incompatible."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Reshape, GRU, TimeDistributed, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the base model for feature extraction\n",
    "base_model = tf.keras.applications.MobileNetV3Small(include_top=False, input_shape=(300, 300, 1))  # Grayscale input\n",
    "\n",
    "# Add SSD layers for detection on top of the base model\n",
    "def add_ssd_layers(base_model_output):\n",
    "    # Assume x is the output of the base model. Add additional layers for SSD here.\n",
    "    # For simplicity, only one additional layer is added here. You can add more layers as required.\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(base_model_output)\n",
    "    # More SSD layers can be added here\n",
    "    \n",
    "    # Each feature layer can be used for detection\n",
    "    detections = Conv2D(4 * 4, (3, 3), activation='relu', padding='same')(x)  # 4 bounding box offsets for each of 4 anchors\n",
    "    detections = Reshape((-1, 4))(detections)  # Reshape to (batch, num_boxes, box_params)\n",
    "    return detections\n",
    "\n",
    "detections = add_ssd_layers(base_model.output)\n",
    "\n",
    "# TimeDistributed wrapper allows applying the same layers to every timestep of a sequence\n",
    "detections = TimeDistributed(Flatten())(detections)\n",
    "\n",
    "# GRU layers for temporal information processing\n",
    "gru = GRU(128, return_sequences=True)(detections)\n",
    "gru = GRU(128, return_sequences=False)(gru)  # Only return the last output\n",
    "\n",
    "# Final detections layer\n",
    "final_detections = Dense(4 * 4, activation='sigmoid')(gru)  # Assuming 4 detections per image\n",
    "\n",
    "# The model\n",
    "model = Model(inputs=base_model.input, outputs=final_detections)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Note: This is a simplified model for demonstration purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
