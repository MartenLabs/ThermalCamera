{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.data_decoders import tf_example_decoder\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Reshape, Concatenate\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the data paths\n",
    "train_tfrecord_dir = 'ThermalCamera_MLX90640.v3i.tfrecord/train/'\n",
    "valid_tfrecord_dir = 'ThermalCamera_MLX90640.v3i.tfrecord/valid/'\n",
    "train_label_map_path = os.path.join(train_tfrecord_dir, 'person_label_map.pbtxt')\n",
    "valid_label_map_path = os.path.join(valid_tfrecord_dir, 'person_label_map.pbtxt')\n",
    "\n",
    "# Load the label map\n",
    "label_map = label_map_util.load_labelmap(train_label_map_path)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map)\n",
    "\n",
    "# Get the list of TFRecord files\n",
    "train_tfrecord_files = tf.io.gfile.glob(os.path.join(train_tfrecord_dir, '*.tfrecord'))\n",
    "valid_tfrecord_files = tf.io.gfile.glob(os.path.join(valid_tfrecord_dir, '*.tfrecord'))\n",
    "\n",
    "# Define the data loading function\n",
    "def load_dataset(tfrecord_files, batch_size=32, shuffle_buffer_size=1000):\n",
    "    \"\"\"Loads a TFRecord dataset.\"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_files)\n",
    "    dataset = dataset.map(\n",
    "        tf_example_decoder.TfExampleDecoder().decode, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = load_dataset(train_tfrecord_files)\n",
    "valid_dataset = load_dataset(valid_tfrecord_files)\n",
    "\n",
    "\n",
    "# for record in tf.data.TFRecordDataset(train_tfrecord_files):\n",
    "#     decoded_record = tf_example_decoder.TfExampleDecoder().decode(record)\n",
    "#     print(decoded_record)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'image/encoded': bytes_list {\n",
      "  value: \"\\377\\330\\377\\340\\000\\020JFIF\\000\\001\\001\\000\\000\\001\\000\\001\\000\\000\\377\\333\\000C\\000\\010\\006\\006\\007\\006\\005\\010\\007\\007\\007\\t\\t\\010\\n\\014\\024\\r\\014\\013\\013\\014\\031\\022\\023\\017\\024\\035\\032\\037\\036\\035\\032\\034\\034 $.\\' \\\",#\\034\\034(7),01444\\037\\'9=82<.342\\377\\333\\000C\\001\\t\\t\\t\\014\\013\\014\\030\\r\\r\\0302!\\034!22222222222222222222222222222222222222222222222222\\377\\300\\000\\021\\010\\000\\010\\000\\004\\003\\001\\\"\\000\\002\\021\\001\\003\\021\\001\\377\\304\\000\\037\\000\\000\\001\\005\\001\\001\\001\\001\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\001\\002\\003\\004\\005\\006\\007\\010\\t\\n\\013\\377\\304\\000\\265\\020\\000\\002\\001\\003\\003\\002\\004\\003\\005\\005\\004\\004\\000\\000\\001}\\001\\002\\003\\000\\004\\021\\005\\022!1A\\006\\023Qa\\007\\\"q\\0242\\201\\221\\241\\010#B\\261\\301\\025R\\321\\360$3br\\202\\t\\n\\026\\027\\030\\031\\032%&\\'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\203\\204\\205\\206\\207\\210\\211\\212\\222\\223\\224\\225\\226\\227\\230\\231\\232\\242\\243\\244\\245\\246\\247\\250\\251\\252\\262\\263\\264\\265\\266\\267\\270\\271\\272\\302\\303\\304\\305\\306\\307\\310\\311\\312\\322\\323\\324\\325\\326\\327\\330\\331\\332\\341\\342\\343\\344\\345\\346\\347\\350\\351\\352\\361\\362\\363\\364\\365\\366\\367\\370\\371\\372\\377\\304\\000\\037\\001\\000\\003\\001\\001\\001\\001\\001\\001\\001\\001\\001\\000\\000\\000\\000\\000\\000\\001\\002\\003\\004\\005\\006\\007\\010\\t\\n\\013\\377\\304\\000\\265\\021\\000\\002\\001\\002\\004\\004\\003\\004\\007\\005\\004\\004\\000\\001\\002w\\000\\001\\002\\003\\021\\004\\005!1\\006\\022AQ\\007aq\\023\\\"2\\201\\010\\024B\\221\\241\\261\\301\\t#3R\\360\\025br\\321\\n\\026$4\\341%\\361\\027\\030\\031\\032&\\'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\202\\203\\204\\205\\206\\207\\210\\211\\212\\222\\223\\224\\225\\226\\227\\230\\231\\232\\242\\243\\244\\245\\246\\247\\250\\251\\252\\262\\263\\264\\265\\266\\267\\270\\271\\272\\302\\303\\304\\305\\306\\307\\310\\311\\312\\322\\323\\324\\325\\326\\327\\330\\331\\332\\342\\343\\344\\345\\346\\347\\350\\351\\352\\362\\363\\364\\365\\366\\367\\370\\371\\372\\377\\332\\000\\014\\003\\001\\000\\002\\021\\003\\021\\000?\\000\\347\\364\\357\\212\\326P\\3053\\\\\\332]\\te\\235\\345a\\020VPX\\347\\000\\2223\\371QE\\024\\204\\177\\377\\331\"\n",
      "}\n",
      ", 'image/filename': bytes_list {\n",
      "  value: \"2023-09-14-03-49-26-mp4_121_png.rf.00054ae4f92c2b01506e2f66d383d0f8.jpg\"\n",
      "}\n",
      ", 'image/format': bytes_list {\n",
      "  value: \"jpeg\"\n",
      "}\n",
      ", 'image/height': int64_list {\n",
      "  value: 8\n",
      "}\n",
      ", 'image/object/bbox/xmax': float_list {\n",
      "  value: 0.25\n",
      "}\n",
      ", 'image/object/bbox/xmin': float_list {\n",
      "  value: 0.0\n",
      "}\n",
      ", 'image/object/bbox/ymax': float_list {\n",
      "  value: 0.625\n",
      "}\n",
      ", 'image/object/bbox/ymin': float_list {\n",
      "  value: 0.0\n",
      "}\n",
      ", 'image/object/class/label': int64_list {\n",
      "  value: 1\n",
      "}\n",
      ", 'image/object/class/text': bytes_list {\n",
      "  value: \"person\"\n",
      "}\n",
      ", 'image/width': int64_list {\n",
      "  value: 4\n",
      "}\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the first record file.\n",
    "record_file = train_tfrecord_files[0]\n",
    "\n",
    "# Create a dataset from the record file.\n",
    "dataset = tf.data.TFRecordDataset(record_file)\n",
    "\n",
    "# Decode the first example.\n",
    "for raw_record in dataset.take(1):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    \n",
    "    # Print the keys in this example.\n",
    "    print(example.features.feature.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "Exception encountered when calling layer \"preprocess_input_layer_35\" (type PreprocessInputLayer).\n\nin user code:\n\n    File \"/var/folders/g2/t0zgyy0d1tl_58849t9hfg5c0000gn/T/ipykernel_15622/2037928495.py\", line 10, in call  *\n        height, width = tf.cast(tf.shape(inputs)[1:3], tf.float32)\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n\n\nCall arguments received by layer \"preprocess_input_layer_35\" (type PreprocessInputLayer):\n  • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb 셀 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m inputs_gray_scale_32x32x1_input_shape\u001b[39m=\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m input_tensor_gray_scale_32x32x1\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minputs_gray_scale_32x32x1_input_shape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m preprocess_input_layer \u001b[39m=\u001b[39m PreprocessInputLayer()(input_tensor_gray_scale_32x32x1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m outputs_ssd_mobilenetv2\u001b[39m=\u001b[39mmodel_ssd_mobilenetv2_gray_scale_input(preprocess_input_layer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m model \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39minput_tensor_gray_scale_32x32x1, outputs\u001b[39m=\u001b[39moutputs_ssd_mobilenetv2)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m     53\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: Exception encountered when calling layer \"preprocess_input_layer_35\" (type PreprocessInputLayer).\n\nin user code:\n\n    File \"/var/folders/g2/t0zgyy0d1tl_58849t9hfg5c0000gn/T/ipykernel_15622/2037928495.py\", line 10, in call  *\n        height, width = tf.cast(tf.shape(inputs)[1:3], tf.float32)\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n\n\nCall arguments received by layer \"preprocess_input_layer_35\" (type PreprocessInputLayer):\n  • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "def create_ssd_mobilenetv2(num_classes):\n",
    "    # PreprocessInputLayer 정의\n",
    "    class PreprocessInputLayer(tf.keras.layers.Layer):\n",
    "        def call(self, inputs):\n",
    "            # 이미지를 3채널로 복제\n",
    "            inputs = tf.concat([inputs, inputs, inputs], axis=-1)\n",
    "            return inputs\n",
    "\n",
    "    base_model = MobileNetV2(input_shape=(32, 32, 3), include_top=False, weights=None)\n",
    "\n",
    "    # Feature Extractor 부분: 여기서는 base_model의 중간 레이어들의 출력을 사용합니다.\n",
    "    feature_layers = ['block_6_expand_relu', 'block_13_expand_relu', 'out_relu']\n",
    "\n",
    "    features = [base_model.get_layer(layer).output for layer in feature_layers]\n",
    "    \n",
    "    # SSD Header 부분: 여기서는 각 feature map에 대해 Convolution과 Reshape을 적용합니다.\n",
    "    headers = []\n",
    "    \n",
    "    for feature in features:\n",
    "        header = Conv2D(6 * (num_classes + 4), kernel_size=3,\n",
    "                        padding='same')(feature)\n",
    "        header = Reshape((-1 ,num_classes + 4))(header)\n",
    "        headers.append(header)\n",
    "\n",
    "    # SSD Headers를 Concatenate합니다.\n",
    "    predictions = Concatenate(axis=1)(headers)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "     \n",
    "    return model\n",
    "\n",
    "# 클래스 개수 설정 및 모델 생성 \n",
    "num_classes = len(label_map.item) + 1 \n",
    "model_ssd_mobilenetv2_gray_scale_input = create_ssd_mobilenetv2(num_classes=num_classes)\n",
    "\n",
    "# Input shape 변경 및 Preprocessing Layer 추가 \n",
    "inputs_gray_scale_32x32x1_input_shape=(32, 32, 1)\n",
    "input_tensor_gray_scale_32x32x1=tf.keras.layers.Input(shape=inputs_gray_scale_32x32x1_input_shape)\n",
    "preprocess_input_layer = PreprocessInputLayer()(input_tensor_gray_scale_32x32x1)\n",
    "outputs_ssd_mobilenetv2=model_ssd_mobilenetv2_gray_scale_input(preprocess_input_layer)\n",
    "\n",
    "model = Model(inputs=input_tensor_gray_scale_32x32x1, outputs=outputs_ssd_mobilenetv2)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"input_73\". You passed a data dictionary with keys ['input_71']. Expected the following keys: ['input_73']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb 셀 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# 학습\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mac/Dev/Project/ThermalCamera/Model/ssdMobileNetV2/ssdMobileNetV2.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/g2/t0zgyy0d1tl_58849t9hfg5c0000gn/T/__autograph_generated_filemg7fjvhr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/mac/anaconda3/envs/tf2/lib/python3.8/site-packages/keras/src/engine/input_spec.py\", line 197, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Missing data for input \"input_73\". You passed a data dictionary with keys ['input_71']. Expected the following keys: ['input_73']\n"
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# 학습\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 로드\n",
    "test_tfrecord_dir = 'ThermalCamera_MLX90640.v1i.tfrecord/test/'\n",
    "test_tfrecord_files = tf.io.gfile.glob(os.path.join(test_tfrecord_dir, '*.tfrecord'))\n",
    "test_dataset = load_dataset(test_tfrecord_files)\n",
    "\n",
    "# 모델 평가\n",
    "eval_result = model.evaluate(test_dataset)\n",
    "\n",
    "# 평가 결과 출력\n",
    "print(\"Test Loss:\", eval_result[0])\n",
    "print(\"Test Accuracy:\", eval_result[1])\n",
    "\n",
    "# 모델 예측\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# 예측 결과 확인\n",
    "# (여기에서 예측 결과를 사용하여 바운딩 박스와 클래스 레이블을 추출하고 시각화할 수 있습니다)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
